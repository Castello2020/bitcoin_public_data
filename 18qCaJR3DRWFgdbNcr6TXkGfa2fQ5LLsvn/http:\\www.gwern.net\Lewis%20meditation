http://www.gwern.net/Lewis%20meditation
HTTP/1.1 200 OK
Server: cloudflare-nginx
Date: Sat, 26 Jul 2014 19:13:13 GMT
Content-Type: text/html; charset=utf-8
Connection: close
Set-Cookie: __cfduid=d49d1286df420cb577b0cb7525eb832211406401993308; expires=Mon, 23-Dec-2019 23:50:00 GMT; path=/; domain=.gwern.net; HttpOnly
x-amz-id-2: iHzcJUAZ808ULYAZ4cEQByEdSoDaVA7FjEnLvcHobi1sHMR63wA8N1ubOyS5LXOU
x-amz-request-id: 802792DB516831BE
x-amz-meta-s3cmd-attrs: uid:1000/gname:gwern/uname:gwern/gid:1000/mode:33152/mtime:1406390358/atime:1406390357/ctime:1406390358
Cache-Control: max-age=604800, public
Last-Modified: Sat, 26 Jul 2014 16:12:55 GMT
CF-RAY: 1502e9ca218a0097-IAD
Content-Encoding: gzip

<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8"/>
<meta name="generator" content="hakyll"/>
<meta name="google-site-verification" content="BOhOQI1uMfsqu_DopVApovk1mJD5ZBLfan0s9go3phk"/>
<meta name="author" content="gwern"/>
<meta name="description" content="Multilevel modeling of effect of small group's meditation on math errors"/>
<meta name="dc.date.issued" content="12 July 2013"/>
<meta name="dcterms.modified" content="26 Aug 2013"/>
<title>2013 Lewis meditation results - Gwern.net</title>
<link rel="stylesheet" type="text/css" href="./static/css/default.css"/>
<link href="./atom.xml" type="application/atom+xml" rel="alternate" title="Sitewide ATOM/RSS Feed"/>
<link rel="shortcut icon" type="image/x-icon" href="./static/img/favicon.ico"/>
</head>
<body>
 
<div class="indent_class1"></div>
<div id="main">
<div id="sidebar">
<div id="logo"><img alt="Logo: a Gothic/Fraktur blackletter capital G/ùï≤" height="36" src="./images/logo.png" width="32"/></div>
<div id="sidebar-links">
<p>
<a href="./index" title="index: categorized list of articles">Home</a>
<a href="./About" title="Site ideals, source, content, traffic, examples, license">Site</a>
<a href="./Links" title="Who am I online, what have I done, what am I like? Contact information; sites I use; things I've worked on">Me</a>
</p>
<hr/>
<div id="sidebar-news">
<p>
<a href="./Changelog" title="What's new or updated">New:</a>
<a href="./atom.xml" type="application/atom+xml" rel="alternate" title="Sitewide ATOM/RSS Feed">RSS</a>
<a href="http://eepurl.com/Kc155" title="Monthly mailing list: signup form">MAIL</a>
</p>
<hr/>
</div>
<div id="cse-sitesearch">
<script>
            (function() {
            var cx = '009114923999563836576:dv0a4ndtmly';
            var gcse = document.createElement('script'); gcse.type = 'text/javascript'; gcse.async = true;
            gcse.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//www.google.com/cse/cse.js?cx=' + cx;
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(gcse, s);
            })();
          </script>
<div style="width:0px;overflow:hidden;height:0px;">
<gcse:search></gcse:search>
</div>
<form id="searchbox_009114923999563836576:dv0a4ndtmly">
<input value="009114923999563836576:dv0a4ndtmly" name="cx" type="hidden"/>
<input value="FORID:11" name="cof" type="hidden"/>
<input id="q" style name="q" size="5" type="text" placeholder="search"/>
</form>
</div>
</div>
<hr/>
<div id="metadata">
<div id="abstract"><em>Multilevel modeling of effect of small group's meditation on math errors</em></div>
<br/>
<div id="tags"><i><a href="./tags/psychology">psychology</a>, <a href="./tags/experiments">experiments</a>, <a href="./tags/statistics">statistics</a></i></div>
<br/>
<div id="page-created">created:
<br/>
<i>12 July 2013</i></div>
<div id="last-modified">modified:
<br/>
<i>26 Aug 2013</i></div>
<br/>
<div id="version">status:
<br/>
<i>in progress</i></div>
<br/>
<div id="epistemological-status"><a href="./About#belief-tags" title="Explanation of 'belief' metadata">belief:</a>
<br/>
<i>unlikely</i>
</div>
<hr/>
</div>
<div id="donations">
<div id="bitcoin-donation-address">
<a href="http://en.wikipedia.org/wiki/Bitcoin">‡∏ø</a>: 18qCaJR3DRWFgdbNcr6TXkGfa2fQ5LLsvn
</div>
<div id="paypal">
<form style="display: inline" action="https://www.paypal.com/cgi-bin/webscr" method="post" onClick="_gaq.push(['_trackEvent', 'Click', 'PayPalClicked', '']);">
<div class="form-type">
<input type="hidden" name="cmd" value="_s-xclick"/>
<input type="hidden" name="hosted_button_id" value="8GSLCWGCC6AF8"/>
<input type="image" src="http://www.paypalobjects.com/en_US/i/btn/btn_donate_SM.gif" name="submit" alt="Help support my writings!"/>
</div>
</form>
</div>
<div id="Gittip">
<script data-gittip-username="gwern" data-gittip-widget="button" src="//gttp.co/v1.js"></script>
</div>
</div>
</div>
 
<div id="adsense">
<a href="http://41j.com/ads/ad.html"><img alt="Advertisement for 'HTerm, The Graphical Terminal'" src="http://41j.com/ads/ad.png" height="90" width="728"></a>
</div>
<div id="header">
<h1>2013 Lewis meditation results</h1>
</div>
<div id="content">
<div id="TOC"><ul>
<li><a href="#data">Data</a></li>
<li><a href="#analysis">Analysis</a><ul>
<li><a href="#descriptive">Descriptive</a></li>
<li><a href="#goals">Goals</a></li>
<li><a href="#multilevel-models">Multilevel models</a><ul>
<li><a href="#time-of-day">Time of day</a></li>
<li><a href="#significance">Significance</a></li>
</ul></li>
<li><a href="#power-for-a-followup-study">Power for a followup study?</a></li>
</ul></li>
<li><a href="#conclusion">Conclusion</a></li>
<li><a href="#see-also">See also</a></li>
</ul></div>
<blockquote>
<p>A small group of Quantified Selfers tested themselves daily on arithmetic and engaged in a month of meditation. I analyze their scores with a multilevel model with per-subject grouping, and find the expect result: a small decrease in arithmetic errors which is not statistically-significant, with practice &amp; time-of-day effects (but not day-of-week or weekend effects). This suggests a longer experiment by twice as many experimenters in order to detect this effect.</p>
</blockquote>
<p><a href="http://en.wikipedia.org/wiki/Quantified%20Self" title="Wikipedia: Quantified Self">Quantified Self</a> hobbyist <a href="http://plewis.info/">Peter Lewis</a> in April 2013 began a self-experiment with 11 other hobbyists (with the <a href="http://blog.sethroberts.net/2013/07/08/journal-of-personal-science-effect-of-meditation-on-math-speed/">results posted on Seth Robert‚Äôs blog</a>): they used a cellphone app ‚ÄúMath Workout‚Äù to do timed simple arithmetic problems (eg. ‚Äú3.7 + 7.3, 93 + 18, 14 * 7, and 12¬≤ + ‚àö9‚Äù) in an ABA experimental design, where B was practicing <a href="http://en.wikipedia.org/wiki/Mindfulness-based%20stress%20reduction" title="Wikipedia: Mindfulness-based stress reduction">mindfulness meditation</a>. This was motivated in part by the observation that, while there is a ton of scientific <a href="http://en.wikipedia.org/wiki/research%20on%20meditation" title="Wikipedia: research on meditation">research on meditation</a>, the studies are often of doubtful quality (he cited a remarkable <a href="http://archive.ahrq.gov/downloads/pub/evidence/pdf/meditation/medit.pdf" title="'Evidence Report/Technology Assessment Number 155: Meditation Practices for Health: State of the Research', Ospina et al 2007">2007 collection of meditation meta-analyses</a>).</p>
<p>Lewis thought the results were positive inasmuch as his timings &amp; error rate fell during the meditation period and the falls seemed visually clear when graphed, but some of the participants dropped out and others had graphs that were not so positive.</p>
<p>The interpretation of the data from a statistical point of view was not terribly clear. Lewis &amp; Roberts did not do the analysis. Reading the post, I thought that it was a perfect dataset to try out <a href="http://en.wikipedia.org/wiki/multilevel%20model" title="Wikipedia: multilevel model">multilevel model</a>s on, as this sort of psychology setup (multiple groups of data per subject, and multiple subjects) is a standard use-case.</p>
<section id="data" class="level1">
<h1>Data</h1>
<p>The original data was provided by Lewis in an <a href="http://plewis.info/med_data.xlsx">Excel spreadsheet</a>, but formatted in a way I couldn‚Äôt make use of. I extracted the data, turned it into a ‚Äòlong‚Äô row-by-row format, added IDs for each subject, transformed the dates into R format, and added a variable for each score whether it was on a meditation day. The result was a <a href="./docs/2013-peterlewis-meditation.csv">CSV</a>:</p>
<pre class="sourceCode R"><code class="sourceCode r">mdtt &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;http://www.gwern.net/docs/2013-peterlewis-meditation.csv&quot;</span>,
                    <span class="dt">colClasses=</span><span class="kw">c</span>(<span class="st">&quot;factor&quot;</span>,<span class="st">&quot;Date&quot;</span>,<span class="st">&quot;character&quot;</span>,<span class="st">&quot;integer&quot;</span>,<span class="st">&quot;numeric&quot;</span>,<span class="st">&quot;logical&quot;</span>))
    Subject         Date             TimeOfDay           ErrorCount     TestDuration
 <span class="dv">00</span>     :<span class="dv">173</span>   Min.   :<span class="dv">2013-04-11</span>   Length:<span class="dv">886</span>         Min.   :<span class="st"> </span><span class="fl">0.00</span>   Min.   :<span class="st">  </span><span class="fl">61.2</span>
 <span class="dv">03</span>     :<span class="dv">126</span>   1st Qu.:<span class="dv">2013-04-16</span>   Class :character   1st Qu.:<span class="st"> </span><span class="fl">1.00</span>   1st Qu.:<span class="st">  </span><span class="fl">95.3</span>
 <span class="dv">01</span>     :<span class="dv">107</span>   Median :<span class="dv">2013-04-21</span>   Mode  :character   Median :<span class="st"> </span><span class="fl">2.00</span>   Median :<span class="st"> </span><span class="fl">119.1</span>
 <span class="dv">04</span>     :<span class="dv">106</span>   Mean   :<span class="dv">2013-04-21</span>                      Mean   :<span class="st"> </span><span class="fl">3.04</span>   Mean   :<span class="st"> </span><span class="fl">126.1</span>
 <span class="dv">06</span>     :<span class="st"> </span><span class="dv">99</span>   3rd Qu.:<span class="dv">2013-04-27</span>                      3rd Qu.:<span class="st"> </span><span class="fl">4.00</span>   3rd Qu.:<span class="st"> </span><span class="fl">143.0</span>
 <span class="dv">05</span>     :<span class="st"> </span><span class="dv">95</span>   Max.   :<span class="dv">2013-05-05</span>                      Max.   :<span class="fl">25.00</span>   Max.   :<span class="fl">2185.7</span>
 (Other):<span class="dv">180</span>                                           NA<span class="st">'s   :68      NA'</span>s   :<span class="dv">69</span>
 Meditated
 Mode :logical
 <span class="ot">FALSE</span>:<span class="dv">502</span>
 <span class="ot">TRUE</span> :<span class="dv">316</span>
 NA<span class="st">'s :68</span>
<span class="st">mdtt &lt;- mdtt[!is.na(mdtt$Subject),]</span>
<span class="st">mdtt &lt;- mdtt[mdtt$TestDuration&lt;400,]</span>
<span class="st">mdtt$ErrorCount &lt;- ifelse(mdtt$ErrorCount&lt;16, mdtt$ErrorCount, c(16))</span></code></pre>
<p>The <code>TestDuration</code> variable jumps out as bizarre: it goes from 143 seconds to 2185.7 seconds? A closer look shows that the last two entries are 368.42, and then 2185.66. This is a bizarre outlier, so I deleted it. The errors also jump from 4 to 25, and a closer look shows a similar jump from 16 to the maximum value 25, which will distort plots later on, so I chose to make 16 the ceiling. We also don‚Äôt want the dummy rows which indicate a meditation session, they‚Äôre redundant once the <code>Meditated</code> variable has been created. Now that the data is cleaned up and coded, we can look at it. For example, all error scores colored by subject:</p>
</section>
<section id="analysis" class="level1">
<h1>Analysis</h1>
<section id="descriptive" class="level2">
<h2>Descriptive</h2>
<p>We have two response variables, number of errors &amp; how long it took to finish the set of 50 arithmetic problems:</p>
<figure>
<img alt="library(ggplot2); qplot(Date, jitter(ErrorCount, factor=1.5), color=Subject, data=mdtt, ylab=&quot;Number of errors out of 50 problems&quot;)" height="599" src="./images/lewis-meditation/errorsovertime.png" width="1085"/><figcaption><code>library(ggplot2); qplot(Date, jitter(ErrorCount, factor=1.5), color=Subject, data=mdtt, ylab=&quot;Number of errors out of 50 problems&quot;)</code></figcaption>
</figure>
<figure>
<img alt="qplot(Date, TestDuration, color=Subject, data=mdtt, ylab=&quot;Time taken to answer 50 problems (lower=better)&quot;)" height="599" src="./images/lewis-meditation/testdurationovertime.png" width="1085"/><figcaption><code>qplot(Date, TestDuration, color=Subject, data=mdtt, ylab=&quot;Time taken to answer 50 problems (lower=better)&quot;)</code></figcaption>
</figure>
<p>We can clearly see a <a href="http://en.wikipedia.org/wiki/practice%20effect" title="Wikipedia: practice effect">practice effect</a> in both test duration &amp; number of errors, where subjects are gradually getting better over time. We will need to remember to control for that.</p>
<p>Splitting by subject instead and looking at <a href="http://en.wikipedia.org/wiki/small%20multiples" title="Wikipedia: small multiples">small multiples</a> for any ABA patterns (we delete 3 of the attrited subjects to free up vertical space):</p>
<pre class="sourceCode R"><code class="sourceCode r">mdtt2 &lt;-<span class="st"> </span>mdtt[<span class="kw">as.integer</span>(mdtt$Subject) &lt;<span class="st"> </span><span class="dv">9</span>,]
<span class="kw">qplot</span>(Date, ErrorCount, <span class="dt">color=</span>Meditated, <span class="dt">facets=</span>Subject~., <span class="dt">data=</span>mdtt2)
<span class="kw">qplot</span>(Date, TestDuration, <span class="dt">color=</span>Meditated, <span class="dt">facets=</span>Subject~., <span class="dt">data=</span>mdtt2)</code></pre>
<p><img alt="Errors in each phase of ABA, stratified by subject" height="609" src="./images/lewis-meditation/errorsbymeditationandsubject.png" width="1081"/> <img alt="Test time required in each phase, by subject" height="609" src="./images/lewis-meditation/testingtimebymeditationandsubject.png" width="1082"/></p>
<p>Overall, these are looking equivocal. There might be something going on, there might not be - <code>ErrorCount</code> looks better than <code>TestDuration</code>, but in both cases, the clear practice effect makes comparison hard.</p>
</section>
<section id="goals" class="level2">
<h2>Goals</h2>
<p>Roberts comments:</p>
<blockquote>
<p>Another way to improve this experiment would be to do statistical tests that generate <em>p</em> values; this would give a better indication of the strength of the evidence. Because this experiment didn‚Äôt reach steady states, the best tests are complicated (e.g., comparison of slopes of fitted lines). With steady-state data, these tests are simple (e.g., comparison of means).</p>
<p>If you are sophisticated at statistics, you could look for a time-of-day effect (are tests later in the day faster?), a day-of-week effect, and so on. If these effects exist, their removal would make the experiment more sensitive. In my brain-function experiments, I use a small number of problems so that I can adjust for problem difficulty. That isn‚Äôt possible here.</p>
</blockquote>
<p><em>p</em>-values are standard in psychology, of course, despite their <a href="http://lesswrong.com/lw/g13/against_nhst/">conceptual &amp; practical problems</a> which help contribute to <a href="DNB%20FAQ#flaws-in-mainstream-science-and-psychology">systematic problems in science</a>, so we‚Äôll calculate one.</p>
<p>But we know in advance what the result will be: greater than 0.05, or non-statistically-significant. A <em>p</em>-value is mostly a function of how much data you have and how large the <a href="http://en.wikipedia.org/wiki/effect%20size" title="Wikipedia: effect size">effect size</a> is - we know <em>a priori</em> that this is a small experiment, and we also know that the effect of meditation on arithmetic scores cannot be <em>huge</em> because otherwise we would have heard of the groundbreaking research &amp; society would make kids meditate before standardized exams &amp; the subjects didn‚Äôt do much meditation &amp; they were inexperienced etc. A small experiment on a small effect is guaranteed to not turn in a statistically-significant result, even when there genuinely is an effect, because the experiment doesn‚Äôt have much <a href="http://en.wikipedia.org/wiki/statistical%20power" title="Wikipedia: statistical power">statistical power</a>. In fact, a decrease in errors large enough to reach a statistical-significance of <em>p</em>&lt;0.05 would be so bizarre &amp; unexpected that it would be grounds for throwing out the data entirely, as someone must be lying or have screwed something up or something have gone terribly wrong somewhere.</p>
<p>So the best we can hope for is to show that there was a benefit at all, rather than a penalty - it‚Äôs not clear, visually, that we‚Äôll see better scores once we take into account a practice effect of time. Having shown this, then we can ask additional questions like, ‚Äúhow large an experiment <em>would</em> we need to reach statistical-significance, anyway?‚Äù</p>
</section>
<section id="multilevel-models" class="level2">
<h2>Multilevel models</h2>
<p>So, we‚Äôll set up a few models in <a href="http://lme4.r-forge.r-project.org/"><code>lme4</code></a> and compare them. The first model is the simplest: each subject has a different level of base accuracy (intercept), but are influenced the same way by meditation (meditation is a fixed effect):</p>
<pre class="sourceCode R"><code class="sourceCode r"><span class="kw">library</span>(lme4)
mlm1 &lt;-<span class="st"> </span><span class="kw">lmer</span>(ErrorCount ~<span class="st"> </span>Meditated +<span class="st"> </span>(<span class="dv">1</span>|Subject), <span class="dt">data=</span>mdtt); mlm1

...
  AIC  BIC logLik deviance REMLdev
 <span class="dv">3793</span> <span class="dv">3812</span>  -<span class="dv">1893</span>     <span class="dv">3784</span>    <span class="dv">3785</span>
Random effects:
<span class="st"> </span>Groups   Name        Variance Std.Dev.
 <span class="kw">Subject</span>  (Intercept) <span class="fl">1.37</span>     <span class="fl">1.17</span>
 Residual             <span class="fl">5.77</span>     <span class="fl">2.40</span>
Number of obs:<span class="st"> </span><span class="dv">818</span>, groups:<span class="st"> </span>Subject, <span class="dv">12</span>

Fixed effects:
<span class="st">              </span>Estimate Std. Error t value
(Intercept)      <span class="fl">2.892</span>      <span class="fl">0.368</span>    <span class="fl">7.87</span>
MeditatedTRUE   -<span class="fl">0.213</span>      <span class="fl">0.179</span>   -<span class="fl">1.19</span>

Correlation of Fixed Effects:
<span class="st">            </span>(Intr)
MedittdTRUE -<span class="fl">0.139</span></code></pre>
<p>(This is with a normal distribution family; using a <a href="http://en.wikipedia.org/wiki/Poisson%20distribution" title="Wikipedia: Poisson distribution">Poisson distribution</a> with <code>family=poisson</code> would give a more accurate model but I am not yet comfortable using or interpreting Poissons.) We get a fixed effect of -0.2 or 1/5 of an error less on meditation days. Not a big effect. The next step is to imagine that besides having differing natural levels of accuracy, meditation may affect some subjects more or less:</p>
<pre class="sourceCode R"><code class="sourceCode r">mlm2 &lt;-<span class="st"> </span><span class="kw">lmer</span>(ErrorCount ~<span class="st"> </span>Meditated +<span class="st"> </span>(<span class="dv">1</span>+Meditated|Subject), <span class="dt">data=</span>mdtt); mlm2

...
 AIC  BIC logLik deviance REMLdev
 <span class="dv">3794</span> <span class="dv">3822</span>  -<span class="dv">1891</span>     <span class="dv">3780</span>    <span class="dv">3782</span>
Random effects:
<span class="st"> </span>Groups   Name          Variance Std.Dev. Corr
 <span class="kw">Subject</span>  (Intercept)   <span class="fl">1.6378</span>   <span class="fl">1.280</span>
          MeditatedTRUE <span class="fl">0.0913</span>   <span class="fl">0.302</span>    -<span class="fl">1.000</span>
 Residual               <span class="fl">5.7472</span>   <span class="fl">2.397</span>
Number of obs:<span class="st"> </span><span class="dv">818</span>, groups:<span class="st"> </span>Subject, <span class="dv">12</span>

Fixed effects:
<span class="st">              </span>Estimate Std. Error t value
(Intercept)      <span class="fl">2.881</span>      <span class="fl">0.398</span>    <span class="fl">7.23</span>
MeditatedTRUE   -<span class="fl">0.144</span>      <span class="fl">0.196</span>   -<span class="fl">0.74</span>

Correlation of Fixed Effects:
<span class="st">            </span>(Intr)
MedittdTRUE -<span class="fl">0.568</span></code></pre>
<p>In this view of things, there‚Äôs a weaker effect of meditation: 1/7th of an error less (rather than 1/5th).</p>
<p>But of course, what about the practice effect? The date should matter! Let‚Äôs re-run those two models with the date:</p>
<pre class="sourceCode R"><code class="sourceCode r">mlm1<span class="fl">.2</span> &lt;-<span class="st"> </span><span class="kw">lmer</span>(ErrorCount ~<span class="st"> </span>Meditated +<span class="st"> </span>Date +<span class="st"> </span>(<span class="dv">1</span>|Subject), <span class="dt">data=</span>mdtt); mlm1<span class="fl">.2</span>

...  AIC  BIC logLik deviance REMLdev
 <span class="dv">3791</span> <span class="dv">3814</span>  -<span class="dv">1890</span>     <span class="dv">3772</span>    <span class="dv">3781</span>
Random effects:
<span class="st"> </span>Groups   Name        Variance Std.Dev.
 <span class="kw">Subject</span>  (Intercept) <span class="fl">1.58</span>     <span class="fl">1.26</span>
 Residual             <span class="fl">5.69</span>     <span class="fl">2.39</span>
Number of obs:<span class="st"> </span><span class="dv">818</span>, groups:<span class="st"> </span>Subject, <span class="dv">12</span>

Fixed effects:
<span class="st">              </span>Estimate Std. Error t value
(Intercept)   <span class="fl">698.5757</span>   <span class="fl">203.2720</span>    <span class="fl">3.44</span>
MeditatedTRUE  -<span class="fl">0.1978</span>     <span class="fl">0.1777</span>   -<span class="fl">1.11</span>
Date           -<span class="fl">0.0440</span>     <span class="fl">0.0129</span>   -<span class="fl">3.42</span>
...
R&gt;<span class="st"> </span>mlm2<span class="fl">.2</span> &lt;-<span class="st"> </span><span class="kw">lmer</span>(ErrorCount ~<span class="st"> </span>Meditated +<span class="st"> </span>Date +<span class="st"> </span>(<span class="dv">1</span>+Meditated|Subject), <span class="dt">data=</span>mdtt); mlm2<span class="fl">.2</span>
...
  AIC  BIC logLik deviance REMLdev
 <span class="dv">3791</span> <span class="dv">3824</span>  -<span class="dv">1889</span>     <span class="dv">3769</span>    <span class="dv">3777</span>
Random effects:
<span class="st"> </span>Groups   Name          Variance Std.Dev. Corr
 <span class="kw">Subject</span>  (Intercept)   <span class="fl">1.867</span>    <span class="fl">1.37</span>
          MeditatedTRUE <span class="fl">0.109</span>    <span class="fl">0.33</span>     -<span class="fl">1.000</span>
 Residual               <span class="fl">5.662</span>    <span class="fl">2.38</span>
Number of obs:<span class="st"> </span><span class="dv">818</span>, groups:<span class="st"> </span>Subject, <span class="dv">12</span>

Fixed effects:
<span class="st">              </span>Estimate Std. Error t value
(Intercept)   <span class="fl">706.2475</span>   <span class="fl">203.3645</span>    <span class="fl">3.47</span>
MeditatedTRUE  -<span class="fl">0.0928</span>     <span class="fl">0.1987</span>   -<span class="fl">0.47</span>
Date           -<span class="fl">0.0445</span>     <span class="fl">0.0129</span>   -<span class="fl">3.46</span>
...
R&gt;<span class="st"> </span><span class="co"># what do the per-subject meditation estimates look like?</span>
R&gt;<span class="st"> </span><span class="co"># this is similar to what we would see if we did separate regressions on each subject:</span>
R&gt;<span class="st"> </span><span class="kw">ranef</span>(mlm2<span class="fl">.2</span>)
$Subject
   (Intercept) MeditatedTRUE
<span class="dv">00</span>    -<span class="fl">0.50140</span>       <span class="fl">0.11975</span>
<span class="dv">01</span>    -<span class="fl">1.32272</span>       <span class="fl">0.31590</span>
<span class="dv">02</span>    -<span class="fl">0.12651</span>       <span class="fl">0.03021</span>
<span class="dv">03</span>     <span class="fl">2.99856</span>      -<span class="fl">0.71614</span>
<span class="dv">04</span>     <span class="fl">0.96203</span>      -<span class="fl">0.22976</span>
<span class="dv">05</span>     <span class="fl">1.33934</span>      -<span class="fl">0.31987</span>
<span class="dv">06</span>    -<span class="fl">0.09078</span>       <span class="fl">0.02168</span>
<span class="dv">07</span>     <span class="fl">0.04431</span>      -<span class="fl">0.01058</span>
<span class="dv">08</span>    -<span class="fl">0.69278</span>       <span class="fl">0.16546</span>
<span class="dv">09</span>    -<span class="fl">0.64673</span>       <span class="fl">0.15446</span>
<span class="dv">10</span>    -<span class="fl">0.12256</span>       <span class="fl">0.02927</span>
<span class="dv">11</span>    -<span class="fl">1.84076</span>       <span class="fl">0.43963</span>
R&gt;<span class="st"> </span><span class="co"># 4/11 have negative meditation estimates</span></code></pre>
<p>Both agree that there is definitely a practice effect, it‚Äôs probably statistically-significant with such large t-values, and the effect size is cumulatively large - at -0.045 errors per day, we‚Äôd expect our error rate to decrease by 1.4 errors a month - which is a lot when we remember that the total average errors per session was 3.1!</p>
<section id="time-of-day" class="level3">
<h3>Time of day</h3>
<p>So, that‚Äôs the practice effect verified. What else? Roberts suggested ‚Äútime-of-day effect (are tests later in the day faster?)‚Äù and ‚Äúday-of-week effect‚Äù. First we‚Äôll convert the times to hours and regress on that:</p>
<pre class="sourceCode R"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="ot">NULL</span>
for (i in <span class="dv">1</span>:<span class="kw">nrow</span>(mdtt)) { y &lt;-<span class="st"> </span><span class="kw">strsplit</span>(mdtt$TimeOfDay[i], <span class="st">&quot;:&quot;</span>)[[<span class="dv">1</span>]];
                          x[i] &lt;-<span class="st"> </span><span class="kw">as.integer</span>(y[[<span class="dv">1</span>]])*<span class="dv">60</span> +<span class="st"> </span><span class="kw">as.integer</span>(y[[<span class="dv">2</span>]]); }
mdtt$Hours &lt;-<span class="st"> </span>(x/<span class="dv">60</span>)

mlm3 &lt;-<span class="st"> </span><span class="kw">lmer</span>(ErrorCount ~<span class="st"> </span>Meditated +<span class="st"> </span>Date +<span class="st"> </span>Hours +<span class="st"> </span>(<span class="dv">1</span>|Subject), <span class="dt">data=</span>mdtt); mlm3
...
  AIC  BIC logLik deviance REMLdev
 <span class="dv">3789</span> <span class="dv">3817</span>  -<span class="dv">1888</span>     <span class="dv">3762</span>    <span class="dv">3777</span>
Random effects:
<span class="st"> </span>Groups   Name        Variance Std.Dev.
 <span class="kw">Subject</span>  (Intercept) <span class="fl">1.52</span>     <span class="fl">1.23</span>
 Residual             <span class="fl">5.63</span>     <span class="fl">2.37</span>
Number of obs:<span class="st"> </span><span class="dv">818</span>, groups:<span class="st"> </span>Subject, <span class="dv">12</span>

Fixed effects:
<span class="st">              </span>Estimate Std. Error t value
(Intercept)   <span class="fl">690.4037</span>   <span class="fl">202.0927</span>    <span class="fl">3.42</span>
MeditatedTRUE  -<span class="fl">0.1875</span>     <span class="fl">0.1767</span>   -<span class="fl">1.06</span>
Date           -<span class="fl">0.0434</span>     <span class="fl">0.0128</span>   -<span class="fl">3.40</span>
Hours          -<span class="fl">0.0526</span>     <span class="fl">0.0162</span>   -<span class="fl">3.25</span></code></pre>
<p>To my surprise, there really is a time-of-day effect. (I expected that there wouldn‚Äôt be enough data to see one, or that it would be a complex squiggle corresponding to circadian rhythms.) And it‚Äôs a simple linear one, too, which jumps out when one plots errors against hour:</p>
<figure>
<img alt="qplot(Hours, ErrorCount, color=Meditated, data=mdtt)" height="598" src="./images/lewis-meditation/hoursvserrors.png" width="1081"/><figcaption><code>qplot(Hours, ErrorCount, color=Meditated, data=mdtt)</code></figcaption>
</figure>
<p>The lesson here is that doing arithmetic at 7AM is not a good idea. (Would that American high schools could realize this‚Ä¶) But moving on: I really don‚Äôt think there‚Äôs enough data to get a day-of-week effect as Roberts suggests, so I‚Äôll also do a simpler split on weekends.</p>
<pre class="sourceCode R"><code class="sourceCode r">mdtt$Day &lt;-<span class="st"> </span><span class="kw">weekdays.Date</span>(mdtt$Date)
mdtt$WeekEnd &lt;-<span class="st"> </span>mdtt$Day==<span class="st">&quot;Sunday&quot;</span> |<span class="st"> </span>mdtt$Day==<span class="st">&quot;Saturday&quot;</span>

mlm4 &lt;-<span class="st"> </span><span class="kw">lmer</span>(ErrorCount ~<span class="st"> </span>Meditated +<span class="st"> </span>Date +<span class="st"> </span>Hours +<span class="st"> </span>Day +<span class="st"> </span>(<span class="dv">1</span>|Subject), <span class="dt">data=</span>mdtt); mlm4
...
  AIC  BIC logLik deviance REMLdev
 <span class="dv">3801</span> <span class="dv">3858</span>  -<span class="dv">1889</span>     <span class="dv">3757</span>    <span class="dv">3777</span>
Random effects:
<span class="st"> </span>Groups   Name        Variance Std.Dev.
 <span class="kw">Subject</span>  (Intercept) <span class="fl">1.47</span>     <span class="fl">1.21</span>
 Residual             <span class="fl">5.64</span>     <span class="fl">2.37</span>
Number of obs:<span class="st"> </span><span class="dv">818</span>, groups:<span class="st"> </span>Subject, <span class="dv">12</span>

Fixed effects:
<span class="st">              </span>Estimate Std. Error t value
(Intercept)   <span class="fl">715.0345</span>   <span class="fl">204.1072</span>    <span class="fl">3.50</span>
MeditatedTRUE  -<span class="fl">0.1610</span>     <span class="fl">0.1803</span>   -<span class="fl">0.89</span>
Date           -<span class="fl">0.0450</span>     <span class="fl">0.0129</span>   -<span class="fl">3.48</span>
Hours          -<span class="fl">0.0518</span>     <span class="fl">0.0163</span>   -<span class="fl">3.17</span>
DayMonday      -<span class="fl">0.4196</span>     <span class="fl">0.3138</span>   -<span class="fl">1.34</span>
DaySaturday    -<span class="fl">0.3912</span>     <span class="fl">0.2959</span>   -<span class="fl">1.32</span>
DaySunday      -<span class="fl">0.1379</span>     <span class="fl">0.3032</span>   -<span class="fl">0.45</span>
DayThursday    -<span class="fl">0.4688</span>     <span class="fl">0.2894</span>   -<span class="fl">1.62</span>
DayTuesday     -<span class="fl">0.3116</span>     <span class="fl">0.3164</span>   -<span class="fl">0.99</span>
DayWednesday   -<span class="fl">0.1052</span>     <span class="fl">0.3267</span>   -<span class="fl">0.32</span>
...
mlm5 &lt;-<span class="st"> </span><span class="kw">lmer</span>(ErrorCount ~<span class="st"> </span>Meditated +<span class="st"> </span>Date +<span class="st"> </span>Hours +<span class="st"> </span>WeekEnd +<span class="st"> </span>(<span class="dv">1</span>|Subject), <span class="dt">data=</span>mdtt); mlm5
...
  AIC  BIC logLik deviance REMLdev
 <span class="dv">3792</span> <span class="dv">3825</span>  -<span class="dv">1889</span>     <span class="dv">3762</span>    <span class="dv">3778</span>
Random effects:
<span class="st"> </span>Groups   Name        Variance Std.Dev.
 <span class="kw">Subject</span>  (Intercept) <span class="fl">1.52</span>     <span class="fl">1.23</span>
 Residual             <span class="fl">5.63</span>     <span class="fl">2.37</span>
Number of obs:<span class="st"> </span><span class="dv">818</span>, groups:<span class="st"> </span>Subject, <span class="dv">12</span>

Fixed effects:
<span class="st">               </span>Estimate Std. Error t value
(Intercept)   <span class="fl">690.57787</span>  <span class="fl">202.44963</span>    <span class="fl">3.41</span>
MeditatedTRUE  -<span class="fl">0.18743</span>    <span class="fl">0.17684</span>   -<span class="fl">1.06</span>
Date           -<span class="fl">0.04345</span>    <span class="fl">0.01280</span>   -<span class="fl">3.39</span>
Hours          -<span class="fl">0.05263</span>    <span class="fl">0.01623</span>   -<span class="fl">3.24</span>
WeekEndTRUE    -<span class="fl">0.00412</span>    <span class="fl">0.18231</span>   -<span class="fl">0.02</span>
...</code></pre>
<p>Neither one is impressive. The model using weekends is completely useless, while the model using days looks like it‚Äôs <a href="http://en.wikipedia.org/wiki/overfitting" title="Wikipedia: overfitting">overfitting</a> the data.</p>
<p>Which of the 5 models is better, overall and keeping in mind that simplicity is good (we don‚Äôt want to overfit the data by throwing in a huge number of random variables which might ‚Äúexplain‚Äù variation in error-scores)?</p>
<pre class="sourceCode R"><code class="sourceCode r"><span class="kw">anova</span>(mlm1, mlm2, mlm1<span class="fl">.2</span>, mlm2<span class="fl">.2</span>, mlm3, mlm4, mlm5)
...
       Df  AIC  BIC logLik Chisq Chi Df <span class="kw">Pr</span>(&gt;Chisq)
mlm1    <span class="dv">4</span> <span class="dv">3792</span> <span class="dv">3810</span>  -<span class="dv">1892</span>
mlm1<span class="fl">.2</span>  <span class="dv">5</span> <span class="dv">3782</span> <span class="dv">3806</span>  -<span class="dv">1886</span> <span class="fl">11.44</span>      <span class="dv">1</span>    <span class="fl">0.00072</span>
mlm2    <span class="dv">6</span> <span class="dv">3792</span> <span class="dv">3821</span>  -<span class="dv">1890</span>  <span class="fl">0.00</span>      <span class="dv">1</span>    <span class="fl">1.00000</span>
mlm3    <span class="dv">6</span> <span class="dv">3774</span> <span class="dv">3802</span>  -<span class="dv">1881</span> <span class="fl">18.75</span>      <span class="dv">0</span>    &lt;<span class="st"> </span><span class="fl">2e-16</span>
mlm2<span class="fl">.2</span>  <span class="dv">7</span> <span class="dv">3774</span> <span class="dv">3807</span>  -<span class="dv">1880</span>  <span class="fl">1.68</span>      <span class="dv">1</span>    <span class="fl">0.19554</span>
mlm5    <span class="dv">7</span> <span class="dv">3776</span> <span class="dv">3809</span>  -<span class="dv">1881</span>  <span class="fl">0.00</span>      <span class="dv">0</span>    <span class="fl">1.00000</span>
mlm4   <span class="dv">12</span> <span class="dv">3781</span> <span class="dv">3838</span>  -<span class="dv">1879</span>  <span class="fl">4.26</span>      <span class="dv">5</span>    <span class="fl">0.51227</span></code></pre>
<p>As we might have guessed, model 3 (<code>Meditated + Date + Hours + (1|Subject)</code>) wins because the practice effect &amp; time-of-day effect matter but apparently not day-of-week in the small dataset we have. (In a larger dataset, then the fancier models might do better.)</p>
</section>
<section id="significance" class="level3">
<h3>Significance</h3>
<p>So, in <code>mlm3</code> the meditation coefficient was -0.1875. How reliable is this meditation coefficient? We‚Äôd like a <em>p</em>-value, and the <em>t</em>-values aren‚Äôt clear: -1.106?</p>
<pre class="sourceCode R"><code class="sourceCode r"><span class="kw">library</span>(languageR)
mcmc &lt;-<span class="st"> </span><span class="kw">pvals.fnc</span>(mlm3)

mcmc$fixed
              Estimate MCMCmean HPD95lower HPD95upper  pMCMC <span class="kw">Pr</span>(&gt;<span class="er">|</span>t|)
(Intercept)   <span class="fl">690.4037</span> <span class="fl">679.5600</span>   <span class="fl">268.8057</span>  <span class="fl">1069.9631</span> <span class="fl">0.0018</span>   <span class="fl">0.0007</span>
MeditatedTRUE  -<span class="fl">0.1875</span>  -<span class="fl">0.1837</span>    -<span class="fl">0.5400</span>     <span class="fl">0.1511</span> <span class="fl">0.2948</span>   <span class="fl">0.2889</span>
Date           -<span class="fl">0.0434</span>  -<span class="fl">0.0427</span>    -<span class="fl">0.0679</span>    -<span class="fl">0.0172</span> <span class="fl">0.0018</span>   <span class="fl">0.0007</span>
Hours          -<span class="fl">0.0526</span>  -<span class="fl">0.0529</span>    -<span class="fl">0.0839</span>    -<span class="fl">0.0205</span> <span class="fl">0.0012</span>   <span class="fl">0.0012</span></code></pre>
<p>The practice &amp; time-of-day effects are pretty statistically-significant, but we get a <em>p</em>-value of 0.29 for meditation at -0.15 (-0.54-0.15). To put this in perspective: the dataset just isn‚Äôt a whole lot of data and the data is heavily loaded on non-meditation data - not such an issue for the date or time-of-day effects which get spread around and estimated evenly, but bad for the meditation data. Another check is by bootstrapping our model from the data and seeing how the meditation estimate varies - does it vary like it did above?</p>
<pre class="sourceCode R"><code class="sourceCode r"><span class="kw">library</span>(boot)
meditationEstimate &lt;-<span class="st"> </span>function(dt, indices) {
  d &lt;-<span class="st"> </span>dt[indices,] <span class="co"># allows boot to select subsample</span>
  mlm3 &lt;-<span class="st"> </span><span class="kw">lmer</span>(ErrorCount ~<span class="st"> </span>Meditated +<span class="st"> </span>Date +<span class="st"> </span>Hours +<span class="st"> </span>(<span class="dv">1</span>|Subject), <span class="dt">data=</span>d)
  <span class="kw">return</span>(<span class="kw">fixef</span>(mlm3)[<span class="dv">2</span>])
  }
bs &lt;-<span class="st"> </span><span class="kw">boot</span>(<span class="dt">data=</span>mdtt, <span class="dt">statistic=</span>meditationEstimate, <span class="dt">R=</span><span class="dv">200000</span>, <span class="dt">parallel=</span><span class="st">&quot;multicore&quot;</span>, <span class="dt">ncpus=</span><span class="dv">4</span>); bs
...
Bootstrap Statistics :
<span class="st">    </span>original    bias    std. error
t1*<span class="st">  </span>-<span class="fl">0.1656</span> -<span class="fl">0.002162</span>      <span class="fl">0.1741</span>

<span class="kw">boot.ci</span>(bs)
...
Intervals :
Level     Percentile
<span class="dv">95</span>%   (-<span class="fl">0.5108</span>,  <span class="fl">0.1735</span> )
Calculations and Intervals on Original Scale</code></pre>
<p>Very similar: -0.16 (-0.51-0.17).</p>
</section>
</section>
<section id="power-for-a-followup-study" class="level2">
<h2>Power for a followup study?</h2>
<p>Lewis viewed the collected data as a proto-study, and wants to do a followup experiment which will be better. Besides the obvious methodological improvements one could make like explicitly randomizing blocks of weeks &amp; using better controls (some other mental activity or alternate form of meditation like yoga), how big should the experiment be so that a meditation effect <em>could</em> reach a <em>p</em>&lt;0.05?</p>
<p>Taking the final effect estimate from my analysis of Lewis‚Äôs proto-study at face-value and assume it‚Äôs the true effect; how many comparisons of meditation/no-meditation would we have to make to have an 80% chance of detecting the true effect which could pass the 0.05 threshold if we ignored the possibility meditation worsened scores? Roughly estimating it, quite a few. A simple power calculation for the estimated effect of -0.187:</p>
<pre class="sourceCode R"><code class="sourceCode r">R&gt;<span class="st"> </span><span class="kw">power.t.test</span>(<span class="dt">delta =</span> <span class="fl">0.187</span>, <span class="dt">sd =</span> <span class="fl">2.682</span>, <span class="dt">alternative=</span><span class="st">&quot;one.sided&quot;</span>, <span class="dt">power=</span><span class="fl">0.8</span>)
...
              n =<span class="st"> </span><span class="dv">2544</span>
          delta =<span class="st"> </span><span class="fl">0.187</span>
             sd =<span class="st"> </span><span class="fl">2.682</span>
      sig.level =<span class="st"> </span><span class="fl">0.05</span>
          power =<span class="st"> </span><span class="fl">0.8</span>
    alternative =<span class="st"> </span>one.sided

NOTE:<span class="st"> </span>n is number in *each*<span class="st"> </span>group</code></pre>
<p>(A <em>t</em>-test calculation because I am not yet sure how to do power analysis for a MLM, and this at least will get us in the neighborhood.)</p>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>If I‚Äôm interpreting the power right, this is not as bad as it looks since each of those <em>n</em> is one math-game, but still. If you have 10 participants and each does 4 games a day, then you‚Äôll need each of your 10 participants to spend 64 days playing the game without meditation (<code>2544 / (10*4) = 64</code>) and another 50 days playing with the meditation. If you could get 20 participants then it‚Äôs a more reasonable 2 months total each.</p>
<p>But getting that many fully-compliant volunteers would be quite difficult, and one has to ask: why does one care? It‚Äôs not clear that this effect is worth caring about for several reasons:</p>
<ol type="1">
<li>the value of meditation is over-determined by all the existing research, which in aggregate covers probably hundreds of thousands of subjects. 10 or 30 QSers‚Äô data should not, for a rational person, override or noticeably affect one‚Äôs beliefs about the value or meditation. If the existing research says meditation is worthwhile, that is far more trustworthy than this; if it says meditation is not worthwhile, likewise.</li>
<li><p>the methodology here means that the small effect is not a causal effect of meditation alone, but an unknown melange of countless factors.</p>
<p>What the small decrease means or is caused by, I am agnostic about. I know a lot of people get annoyed when someone brings up methodological issues like expectancy or placebo effects, but with my own blinded self-experiments with nootropics I have felt first-hand placebo effects, and I have been deeply impressed by the results of my <a href="DNB%20meta-analysis">dual n-back meta-analysis</a> where simply switching from a passive to an active control group changes the IQ gain from 9.3 IQ points to 2.5.</p>
For me, things like that are the reality behind most self-experiments, and certainly ones with self-selected participants in an unrandomized unblinded experiment with attrition leading to a small effect easily explicable by simply trying a little bit harder.</li>
<li><p>the metric of arithmetic scores has no clear relation to anything of importance</p>
<p>No one actually cares about simple arithmetic scores. Many results in brain training studies follow a pattern where the training successfully increases scores on some psychological task like <a href="http://en.wikipedia.org/wiki/digit%20span" title="Wikipedia: digit span">digit span</a>, but when researchers look for ‚Äúfar transfer‚Äù to things like school grades, no effect can be found. Even if all the other issues could be dealt with and mindfulness meditation did improve arithmetic, what is it a valid proxy for?</p></li>
</ol>
</section>
<section id="see-also" class="level1">
<h1>See also</h1>
<ul>
<li><a href="Google%20Alerts">Does Google Alerts return fewer results each year? A statistical investigation</a></li>
</ul>
</section>
</div>
</div>
<div id="footer">
<p>Still bored? Then try my <a href="https://plus.google.com/103530621949492999968/posts" title="Google+ posts">Google+ news feed</a>.</p>
<a href="https://docs.google.com/spreadsheet/viewform?formkey=dE5GLWpfX3RhX1c2Q1phcEo3U3VDVEE6MQ">Send anonymous feedback</a>
<br/>
<div id="license">
<p xmlns:dct="http://purl.org/dc/terms/" xmlns:vcard="http://www.w3.org/2001/vcard-rdf/3.0#">
<a rel="license" href="http://creativecommons.org/publicdomain/zero/1.0/">
<img src="http://i.creativecommons.org/p/zero/1.0/88x31.png" style="border-style: none;" alt="CC0" height="31" width="88"/>
</a>
</p>
</div>
</div>
 
<script type="text/javascript" src="//ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js"></script>
 
<script type="text/javascript" src="./static/js/footnotes.js"></script>
 
<script type="text/javascript" src="./static/js/abalytics.js"></script>
<script type="text/javascript">
      window.onload = function() {
      ABalytics.applyHtml();
      };
    </script>
 
<script id="googleAnalytics" type="text/javascript">
      var _gaq = _gaq || [];
      _gaq.push(['_setAccount', 'UA-18912926-1']);

      ABalytics.init({
      indent: [
      {
      name: "none",
      "indent_class1": "<style>p + p { text-indent: 0.0em; margin-top: 0 }</style>"
      },
      {
      name: "indent0.1",
      "indent_class1": "<style>p + p { text-indent: 0.1em; margin-top: 0 }</style>"
      },
      {
      name: "indent0.5",
      "indent_class1": "<style>p + p { text-indent: 0.5em; margin-top: 0 }</style>"
      },
      {
      name: "indent1.0",
      "indent_class1": "<style>p + p { text-indent: 1.0em; margin-top: 0 }</style>"
      },
      {
      name: "indent1.5",
      "indent_class1": "<style>p + p { text-indent: 1.5em; margin-top: 0 }</style>"
      },
      {
      name: "indent2.0",
      "indent_class1": "<style>p + p { text-indent: 2.0em; margin-top: 0 }</style>"
      }
      ],
      }, _gaq);

      _gaq.push(['_trackPageview']);
      (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
      })();
    </script>
 
<script id="outboundLinkTracking" type="text/javascript">
      $(function() {
      $("a").on('click',function(e){
      var url = $(this).attr("href");
      if (e.currentTarget.host != window.location.host) {
      _gat._getTrackerByName()._trackEvent("Outbound Links", e.currentTarget.host.replace(':80',''), url, 0);
      if (e.metaKey || e.ctrlKey || (e.button == 1)) {
      var newtab = true;
      }
      if (!newtab) {
      e.preventDefault();
      setTimeout('document.location = "' + url + '"', 100);
      }
      }
      });
      });
    </script>
 
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
 
<script type="text/javascript" src="./static/js/footnotes.js"></script>
 
<script type="text/javascript" src="./static/js/tablesorter.js"></script>
<script type="text/javascript" id="tablesorter">
      $(document).ready(function() {
      $("table").tablesorter();
      }); </script>
 
<div id="disqus_thread"></div>
<script type="text/javascript">
      if (document.title != 'Essays') { <!-- avoid Disqus comments on front page -->
      (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://disqus.com/forums/gwern/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
      })();
      var disqus_shortname = 'gwern';
      (function () {
      var s = document.createElement('script'); s.async = true;
      s.src = 'http://disqus.com/forums/gwern/count.js';
      (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
      }());
      }</script>
<noscript><p>Enable JavaScript for Disqus comments</p></noscript>
</body>
</html>

