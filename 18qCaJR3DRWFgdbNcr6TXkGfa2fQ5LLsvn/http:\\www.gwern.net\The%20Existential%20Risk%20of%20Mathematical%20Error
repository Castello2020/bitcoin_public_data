http://www.gwern.net/The%20Existential%20Risk%20of%20Mathematical%20Error
HTTP/1.1 200 OK
Server: cloudflare-nginx
Date: Thu, 24 Jul 2014 06:24:07 GMT
Content-Type: text/html; charset=utf-8
Connection: close
Set-Cookie: __cfduid=dc44b4c3ed3ddc0445b5778e366184f1f1406183047571; expires=Mon, 23-Dec-2019 23:50:00 GMT; path=/; domain=.gwern.net; HttpOnly
x-amz-id-2: Mkx8hFiegO2HnNGSmtfM7MivCMbFZrTcL5G/jbY+Pz2Qbk7LRtOADQCBfToHjhwp
x-amz-request-id: A11B14A60788F018
x-amz-meta-s3cmd-attrs: uid:1000/gname:gwern/uname:gwern/gid:1000/mode:33152/mtime:1405188972/atime:1405188970/ctime:1405188972
Cache-Control: max-age=604800, public
Last-Modified: Sat, 12 Jul 2014 18:37:53 GMT
CF-RAY: 14ee086f52000097-IAD
Content-Encoding: gzip

<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8"/>
<meta name="generator" content="hakyll"/>
<meta name="google-site-verification" content="BOhOQI1uMfsqu_DopVApovk1mJD5ZBLfan0s9go3phk"/>
<meta name="author" content="gwern"/>
<meta name="description" content="Mathematical mistake or error-rates limit our understanding of rare risks"/>
<meta name="dc.date.issued" content="20 Jul 2012"/>
<meta name="dcterms.modified" content="03 Jul 2014"/>
<title>The Existential Risk of Mathematical Error</title>
<link rel="stylesheet" type="text/css" href="./static/css/default.css"/>
<link href="./atom.xml" type="application/atom+xml" rel="alternate" title="Sitewide ATOM/RSS Feed"/>
<link rel="shortcut icon" type="image/x-icon" href="./static/img/favicon.ico"/>
</head>
<body>
 
<div class="indent_class1"></div>
<div id="main">
<div id="sidebar">
<div id="logo"><img alt="Logo: a Gothic/Fraktur blackletter capital G/ùï≤" height="36" src="./images/logo.png" width="32"/></div>
<div id="sidebar-links">
<p>
<a href="./index" title="index: categorized list of articles">Home</a>
<a href="./About" title="Site ideals, source, content, traffic, examples, license">Site</a>
<a href="./Links" title="Who am I online, what have I done, what am I like? Contact information; sites I use; things I've worked on">Me</a>
</p>
<hr/>
<div id="sidebar-news">
<p>
<a href="./Changelog" title="What's new or updated">New:</a>
<a href="./atom.xml" type="application/atom+xml" rel="alternate" title="Sitewide ATOM/RSS Feed">RSS</a>
<a href="http://eepurl.com/Kc155" title="Monthly mailing list: signup form">MAIL</a>
</p>
<hr/>
</div>
<div id="cse-sitesearch">
<script>
            (function() {
            var cx = '009114923999563836576:dv0a4ndtmly';
            var gcse = document.createElement('script'); gcse.type = 'text/javascript'; gcse.async = true;
            gcse.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//www.google.com/cse/cse.js?cx=' + cx;
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(gcse, s);
            })();
          </script>
<div style="width:0px;overflow:hidden;height:0px;">
<gcse:search></gcse:search>
</div>
<form id="searchbox_009114923999563836576:dv0a4ndtmly">
<input value="009114923999563836576:dv0a4ndtmly" name="cx" type="hidden"/>
<input value="FORID:11" name="cof" type="hidden"/>
<input id="q" style name="q" size="5" type="text" placeholder="search"/>
</form>
</div>
</div>
<hr/>
<div id="metadata">
<div id="abstract"><em>Mathematical mistake or error-rates limit our understanding of rare risks</em></div>
<br/>
<div id="tags"><i><a href="./tags/philosophy">philosophy</a>, <a href="./tags/transhumanism">transhumanism</a>, <a href="./tags/statistics">statistics</a></i></div>
<br/>
<div id="page-created">created:
<br/>
<i>20 Jul 2012</i></div>
<div id="last-modified">modified:
<br/>
<i>03 Jul 2014</i></div>
<br/>
<div id="version">status:
<br/>
<i>draft</i></div>
<br/>
<div id="epistemological-status"><a href="./About#belief-tags" title="Explanation of 'belief' metadata">belief:</a>
<br/>
<i>likely</i>
</div>
<hr/>
</div>
<div id="donations">
<div id="bitcoin-donation-address">
<a href="http://en.wikipedia.org/wiki/Bitcoin">‡∏ø</a>: 18qCaJR3DRWFgdbNcr6TXkGfa2fQ5LLsvn
</div>
<div id="paypal">
<form style="display: inline" action="https://www.paypal.com/cgi-bin/webscr" method="post" onClick="_gaq.push(['_trackEvent', 'Click', 'PayPalClicked', '']);">
<div class="form-type">
<input type="hidden" name="cmd" value="_s-xclick"/>
<input type="hidden" name="hosted_button_id" value="8GSLCWGCC6AF8"/>
<input type="image" src="http://www.paypalobjects.com/en_US/i/btn/btn_donate_SM.gif" name="submit" alt="Help support my writings!"/>
</div>
</form>
</div>
<div id="Gittip">
<script data-gittip-username="gwern" data-gittip-widget="button" src="//gttp.co/v1.js"></script>
</div>
</div>
</div>
 
<div id="adsense">
<a href="http://41j.com/ads/ad.html"><img alt="Advertisement for 'HTerm, The Graphical Terminal'" src="http://41j.com/ads/ad.png" height="90" width="728"></a>
</div>
<div id="header">
<h1>The Existential Risk of Mathematical Error</h1>
</div>
<div id="content">
<div id="TOC"><ul>
<li><a href="#untrustworthy-proofs">Untrustworthy proofs</a></li>
<li><a href="#error-distribution">Error distribution</a><ul>
<li><a href="#type-i-type-ii">Type I &gt; Type II?</a></li>
</ul></li>
<li><a href="#heuristics">Heuristics</a><ul>
<li><a href="#type-i-vs-type-ii">Type I vs Type II</a></li>
</ul></li>
<li><a href="#future-implications">Future implications</a></li>
<li><a href="#external-links">External links</a></li>
</ul></div>
<blockquote>
<p>See also <a href="http://lesswrong.com/lw/3be/confidence_levels_inside_and_outside_an_argument/">‚ÄúConfidence levels inside and outside an argument‚Äù</a></p>
</blockquote>
<p>Mathematical error has been rarely examined except as a possibility and motivating reason for research into formal methods; <a href="http://www.columbia.edu/~hg17/synthese-paper-as-published.pdf" title="Reasoning With Limited Resources And Assigning Probabilities to Arithmetical Statements">Gaifman 2004</a> claims</p>
<blockquote>
<p>An agent might even have beliefs that logically contradict each other. Mersenne believed that 2<sup>67</sup>-1 is a prime number, which was proved false in 1903, cf.¬†Bell (1951). [The factorization, discovered by Cole, is: 193,707,721 √ó 761,838,257,287.]‚Ä¶Now, there is no shortage of deductive errors and of false mathematical beliefs. Mersenne‚Äôs is one of the most known in a rich history of mathematical errors, involving very prominent figures (cf.¬†De Millo et al. 1979, 269-270). The explosion in the number of mathematical publications and research reports has been accompanied by a similar explosion in erroneous claims; on the whole, errors are noted by small groups of experts in the area, and many go unheeded. There is nothing philosophically interesting that can be said about such failures.<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a></p>
</blockquote>
<section id="untrustworthy-proofs" class="level1">
<h1>Untrustworthy proofs</h1>
<blockquote>
<p>‚ÄúBeware of bugs in the above code; I have only proved it correct, not tried it.‚Äù ‚Äì<a href="http://www-cs-faculty.stanford.edu/~uno/faq.html">Donald Knuth</a></p>
</blockquote>
<p>In some respects, there is nothing to be said; in other respects, there is much to be said. <a href="http://arxiv.org/abs/0810.5515">‚ÄúProbing the Improbable: Methodological Challenges for Risks with Low Probabilities and High Stakes‚Äù</a> discusses a basic issue with <a href="http://en.wikipedia.org/wiki/existential%20threats" title="Wikipedia: existential threats">existential threats</a>: any useful discussion will be rigorous, hopefully with physics and math proofs; but proofs themselves are empirically unreliable. Given that proofs are the most reliable form of epistemology humans know, this sets a basic upper bound on how much confidence we can put on <em>any</em> belief. (There are other rare risks, from mental diseases<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a> to how to deal with contradictions<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a>, but we‚Äôll look at mathematical error.)</p>
<blockquote>
<p>‚ÄúWhen you have eliminated the impossible, whatever remains is often more improbable than your having made a mistake in one of your impossibility proofs.‚Äù ‚Äì<a href="http://lesswrong.com/lw/3m/rationalist_fiction/2p6#body_t1_2p6">Steven Kaas</a></p>
</blockquote>
</section>
<section id="error-distribution" class="level1">
<h1>Error distribution</h1>
<p>This upper bound on our certainty may force us to disregard certain rare risks because the effect of error on our estimates of existential risks is <em>asymmetric</em>: an error will usually reduce the risk, not increase it. The errors are not distributed in any kind of symmetrical around a mean: an existential risk is, by definition, bumping up against the upper bound on possible damage. If we were trying to estimate, say, average human height, and errors were distributed like a bell curve, then we could ignore them. But if we are calculating the risk of a super-asteroid impact which will kill all of humanity, an error which means the super-asteroid will actually kill humanity twice over is irrelevant because it‚Äôs the same thing (we can‚Äôt die twice); however, the mirror error - the super-asteroid actually killing half of humanity - matters a great deal!</p>
<p>How big is this upper bound? Mathematicians have <em>often</em> made errors in proofs. But <a href="http://mathoverflow.net/questions/35468/widely-accepted-mathematical-results-that-were-later-shown-wrong">it‚Äôs</a> <a href="http://en.wikipedia.org/wiki/List%20of%20disproved%20mathematical%20ideas" title="Wikipedia: List of disproved mathematical ideas">rarer</a> for ideas to be accepted for a long time and then rejected. But we can divide errors into 2 basic cases corresponding to <a href="http://en.wikipedia.org/wiki/type%20I%20and%20type%20II%20errors" title="Wikipedia: type I and type II errors">type I and type II errors</a>:</p>
<ol type="1">
<li>Mistakes where the theorem is still true, but the proof was incorrect (type I)</li>
<li>Mistakes where the theorem was <em>false</em>, and the proof was also necessarily incorrect (type II)</li>
</ol>
<p>Before someone comes up with a final answer, a mathematician may have <a href="http://www.maa.org/sites/default/files/images/images/upload_library/22/Polya/07468342.di020715.02p0066x.pdf" title="'What Do I Know? A Study of Mathematical Self-Awareness', Davis 1983">many levels of intuition</a> in formulating &amp; working on the problem, but we‚Äôll consider the final end-product where the mathematician feels satisfied that he has solved it. Case 1 is perhaps the most common case, with innumerable examples; this is sometimes due to mistakes in the proof that anyone would accept is a mistake, but many of these cases are due to changing standards of proof. For example, when David Hilbert discovered errors in Euclid‚Äôs proofs which no one noticed before, the theorems were still true, and the gaps more due to Hilbert being a modern mathematician thinking in terms of formal systems (which of course Euclid did not think in). (David Hilbert himself turns out to be a useful example of the other kind of error: his famous <a href="http://en.wikipedia.org/wiki/Hilbert%27s%20problems" title="Wikipedia: Hilbert's problems">list of 23 problems</a> was accompanied by definite opinions on the outcome of each problem and sometimes timings, several of which were wrong or questionable<a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a>.) Similarly, early calculus used ‚Äòinfinitesimals‚Äô which were sometimes treated as being 0 and sometimes treated as an indefinitely small non-zero number; this was incoherent and strictly speaking, practically <em>all</em> of the calculus results were wrong because they relied on an incoherent concept - but of course the results were some of the greatest mathematical work ever conducted<a href="#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a> and when later mathematicians put calculus on a more rigorous footing, they immediately re-derived those results (sometimes with important qualifications). Other cases are more straightforward, with mathematicians publishing multiple proofs/patches or covertly correcting papers<a href="#fn6" class="footnoteRef" id="fnref6"><sup>6</sup></a>. Poincar√© points out this mathematical version of the <a href="http://en.wikipedia.org/wiki/pessimistic%20induction" title="Wikipedia: pessimistic induction">pessimistic induction</a> in <a href="http://www-history.mcs.st-andrews.ac.uk/Extras/Poincare_Intuition.html" title="Henri Poincar√© published _Intuition and Logic in mathematics_ as part of _La valeur de la science_ in 1905. It was translated into English by G B Halsted and published in 1907 as part of Poincar√©'s _The Value of Science_. A version of Poincar√©'s article is below.">‚ÄúIntuition and Logic in Mathematics‚Äù</a>:</p>
<blockquote>
<p>Strange! If we read over the works of the ancients we are tempted to class them all among the intuitionalists. And yet nature is always the same; it is hardly probable that it has begun in this century to create minds devoted to logic. If we could put ourselves into the flow of ideas which reigned in their time, we should recognize that many of the old geometers were in tendency analysts. Euclid, for example, erected a scientific structure wherein his contemporaries could find no fault. In this vast construction, of which each piece however is due to intuition, we may still to-day, without much effort, recognize the work of a logician.</p>
<p>‚Ä¶ What is the cause of this evolution? It is not hard to find. Intuition can not give us rigour, nor even certainty; this has been recognized more and more. Let us cite some examples. We know there exist continuous functions lacking derivatives. Nothing is more shocking to intuition than this proposition which is imposed upon us by logic. Our fathers would not have failed to say: ‚ÄúIt is evident that every continuous function has a derivative, since every curve has a tangent.‚Äù How can intuition deceive us on this point?</p>
<p>‚Ä¶ I shall take as second example <a href="http://en.wikipedia.org/wiki/Dirichlet%27s%20principle" title="Wikipedia: Dirichlet‚Äôs principle">Dirichlet‚Äôs principle</a> on which rest so many theorems of mathematical physics; to-day we establish it by reasonings very rigorous but very long; heretofore, on the contrary, we were content with a very summary proof. A certain integral depending on an arbitrary function can never vanish. Hence it is concluded that it must have a minimum. The flaw in this reasoning strikes us immediately, since we use the abstract term function and are familiar with all the singularities functions can present when the word is understood in the most general sense. But it would not be the same had we used concrete images, had we, for example, considered this function as an electric potential; it would have been thought legitimate to affirm that electrostatic equilibrium can be attained. Yet perhaps a physical comparison would have awakened some vague distrust. But if care had been taken to translate the reasoning into the language of geometry, intermediate between that of analysis and that of physics, doubtless this distrust would not have been produced, and perhaps one might thus, even to-day, still deceive many readers not forewarned.</p>
<p>‚Ä¶A first question presents itself. Is this evolution ended? Have we finally attained absolute rigour? At each stage of the evolution our fathers also thought they had reached it. If they deceived themselves, do we not likewise cheat ourselves?</p>
<p>We believe that in our reasonings we no longer appeal to intuition; the philosophers will tell us this is an illusion. Pure logic could never lead us to anything but tautologies; it could create nothing new; not from it alone can any science issue. In one sense these philosophers are right; to make arithmetic, as to make geometry, or to make any science, something else than pure logic is necessary.</p>
</blockquote>
<section id="type-i-type-ii" class="level2">
<h2>Type I &gt; Type II?</h2>
<p>Case 2 is disturbing, since it is a case in which we wind up with false beliefs and also false beliefs about our beliefs (we no longer know that we don‚Äôt know). Case 2 could lead to extinction.</p>
<p>The prevalence of case 1 might lead us to be very pessimistic; case 1, case 2, what‚Äôs the difference? We have demonstrated a large error rate in mathematics (and physics is probably even worse off). Except, errors do not seem to be evenly &amp; randomly distributed between case 1 and case 2. There seem to be far more case 1s than case 2s, as already mentioned in the early calculus example: far more than 50% of the early calculus results were correct when checked more rigorously. <a href="http://en.wikipedia.org/wiki/Gian-Carlo%20Rota" title="Wikipedia: Gian-Carlo Rota">Gian-Carlo Rota</a> gives us an example with Hilbert:</p>
<blockquote>
<p>Once more let me begin with Hilbert. When the Germans were planning to publish Hilbert‚Äôs collected papers and to present him with a set on the occasion of one of his later birthdays, they realized that they could not publish the papers in their original versions because they were full of errors, some of them quite serious. Thereupon they hired a young unemployed mathematician, Olga Taussky-Todd, to go over Hilbert‚Äôs papers and correct all mistakes. Olga labored for three years; it turned out that all mistakes could be corrected without any major changes in the statement of the theorems. There was one exception, a paper Hilbert wrote in his old age, which could not be fixed; it was a purported proof of the continuum hypothesis, you will find it in a volume of the <em>Mathematische Annalen</em> of the early thirties. At last, on Hilbert‚Äôs birthday, a freshly printed set of Hilbert‚Äôs collected papers was presented to the Geheimrat. Hilbert leafed through them carefully and did not notice anything.<a href="#fn7" class="footnoteRef" id="fnref7"><sup>7</sup></a></p>
</blockquote>
<p>So only one of those papers was irreparable, while all the others were correct and fixable? Rota himself experienced this:</p>
<blockquote>
<p>Now let us shift to the other end of the spectrum, and allow me to relate another personal anecdote. In the summer of 1979, while attending a philosophy meeting in Pittsburgh, I was struck with a case of detached retinas. Thanks to Joni‚Äôs prompt intervention, I managed to be operated on in the nick of time and my eyesight was saved. On the morning after the operation, while I was lying on a hospital bed with my eyes bandaged, Joni dropped in to visit. Since I was to remain in that Pittsburgh hospital for at least a week, we decided to write a paper. Joni fished a manuscript out of my suitcase, and I mentioned to her that the text had a few mistakes which she could help me fix. There followed twenty minutes of silence while she went through the draft. ‚Äú<em>Why, it is all wrong!</em>‚Äù she finally remarked in her youthful voice. She was right. Every statement in the manuscript had something wrong. Nevertheless, after laboring for a while, she managed to correct every mistake, and the paper was eventually published.</p>
<p>There are two kinds of mistakes. There are fatal mistakes that destroy a theory; but there are also contingent ones, which are useful in testing the stability of a theory.</p>
</blockquote>
<p>A mathematician of my acquaintance referred me to <a href="http://web.archive.org/web/20121031161104/http://www.maths.gla.ac.uk/~tl/images/Jech_p118.png">pg118</a> of <a href="http://www.amazon.com/Axiom-Choice-Dover-Books-Mathematics/dp/0486466248/?tag=gwernnet-20"><em>The Axiom of Choice</em></a>, Jech 2008; he had found the sustained effect of the 5 footnotes humorous:</p>
<blockquote>
<ol type="1">
<li>The result of Problem 11 contradicts the results announced by Levy [1963b]. Unfortunately, the construction presented there cannot be completed.</li>
<li>The transfer to ZF was also claimed by Marek [1966] but the outlined method appears to be unsatisfactory and has not been published.</li>
<li>A contradicting result was announced and later withdrawn by Truss [1970].</li>
<li>The example in Problem 22 is a counterexample to another condition of Mostowski, who conjectured its sufficiency and singled out this example as a test case.</li>
<li>The independence result contradicts the claim of Felgner [1969] that the Cofinality Principle implies the Axiom of Choice. An error has been found by Morris (see Felgner‚Äôs corrections to [1969]).</li>
</ol>
</blockquote>
<p>And referred me also to the entries in the index of <a href="http://www.amazon.com/Fourier-Analysis-T-246-rner/dp/0521389917/?tag=gwernnet-20"><em>Fourier Analysis</em></a> by Tom K√∂rner concerning the problem of the <a href="http://golem.ph.utexas.edu/category/2013/01/carlesons_theorem.html" title="'Carleson's Theorem', Tom Leinster">‚Äúpointwise convergence of Fourier series‚Äù</a>:</p>
<blockquote>
<ul>
<li><p>excessive optimism</p>
<ul>
<li><a href="http://en.wikipedia.org/wiki/Augustin-Louis%20Cauchy" title="Wikipedia: Augustin-Louis Cauchy">Cauchy</a>, 3</li>
<li><a href="http://en.wikipedia.org/wiki/Richard%20Dedekind" title="Wikipedia: Richard Dedekind">Dedekind</a>, <a href="http://en.wikipedia.org/wiki/Johann%20Peter%20Gustav%20Lejeune%20Dirichlet" title="Wikipedia: Johann Peter Gustav Lejeune Dirichlet">Dirichlet</a> and <a href="http://en.wikipedia.org/wiki/Karl%20Weierstrass" title="Wikipedia: Karl Weierstrass">Weierstrass</a>, 67</li>
<li>Dirichlet, <a href="http://en.wikipedia.org/wiki/Carl%20Friedrich%20Gauss" title="Wikipedia: Carl Friedrich Gauss">Gauss</a>, <a href="http://en.wikipedia.org/wiki/George%20Green" title="Wikipedia: George Green">Green</a>, <a href="http://en.wikipedia.org/wiki/William%20Thomson%2C%201st%20Baron%20Kelvin" title="Wikipedia: William Thomson, 1st Baron Kelvin">Kelvin</a> and <a href="http://en.wikipedia.org/wiki/Bernhard%20Riemann" title="Wikipedia: Bernhard Riemann">Riemann</a>, 126</li>
<li><a href="http://en.wikipedia.org/wiki/Michael%20Faraday" title="Wikipedia: Michael Faraday">Faraday</a> and Morse<a href="#fn8" class="footnoteRef" id="fnref8"><sup>8</sup></a>, 333</li>
<li><a href="http://en.wikipedia.org/wiki/Evariste%20Galois" title="Wikipedia: Evariste Galois">Galois</a>, 38</li>
<li>Hegel, 370</li>
<li><a href="http://en.wikipedia.org/wiki/Charles%20Hermite" title="Wikipedia: Charles Hermite">Hermite</a> and <a href="http://en.wikipedia.org/wiki/Henri%20Poincare" title="Wikipedia: Henri Poincare">Poincar√©</a>. 42</li>
<li><a href="http://en.wikipedia.org/wiki/Karl%20Pearson" title="Wikipedia: Karl Pearson">Pearson</a>, 424</li>
<li><a href="http://en.wikipedia.org/wiki/Simeon%20Denis%20Poisson" title="Wikipedia: Simeon Denis Poisson">Poisson</a>, 119</li>
<li><a href="http://en.wikipedia.org/wiki/Jakob%20Steiner" title="Wikipedia: Jakob Steiner">Steiner</a>, 163</li>
</ul></li>
<li><p>excessive pessimism</p>
<ul>
<li><a href="http://en.wikipedia.org/wiki/Jean%20Baptiste%20Joseph%20Delambre" title="Wikipedia: Jean Baptiste Joseph Delambre">Delambre</a>, 473-4</li>
<li>general, 4, 74</li>
<li><a href="http://en.wikipedia.org/wiki/Joseph%20Louis%20Lagrange" title="Wikipedia: Joseph Louis Lagrange">Lagrange</a>, 473</li>
<li><a href="http://en.wikipedia.org/wiki/Pafnuty%20Chebyshev" title="Wikipedia: Pafnuty Chebyshev">Tchebychev</a>, 198</li>
</ul></li>
</ul>
</blockquote>
<p>Some problems are notorious for provoking repeated false proofs. <a href="http://en.wikipedia.org/wiki/P%3DNP" title="Wikipedia: P=NP">P=NP</a> attracts countless cranks and <a href="http://www.win.tue.nl/~gwoegi/P-versus-NP.htm" title="This page collects links around papers that try to settle the 'P versus NP' question (in either way).">serious attempts</a>, of course, but also amusing is <a href="http://mathoverflow.net/questions/35468/widely-accepted-mathematical-results-that-were-later-shown-wrong/36020#36020">apparently the Jacobian Conjecture</a>:</p>
<blockquote>
<p>The (in)famous Jacobian Conjecture was considered a theorem since a 1939 publication by Keller (who claimed to prove it). Then Shafarevich found a new proof and published it in some conference proceedings paper (in early 1950-ies). This conjecture states that any polynomial map from C^2 to C^2 is invertible if its Jacobian is nowhere zero. In 1960-ies, Vitushkin found a counterexample to all the proofs known to date, by constructing a complex analytic map, not invertible and with nowhere vanishing Jacobian. It is still a main source of embarrassment for <code>arxiv.org</code> contributors, who publish about 3-5 false proofs yearly. Here is a funny refutation for one of the proofs: <a href="http://arxiv.org/abs/math/0604049" title="Moh 2006">‚ÄúComment on a Paper by Yucai Su On Jacobian Conjecture (Dec 30, 2005)‚Äù</a></p>
<blockquote>
<p>The problem of Jacobian Conjecture is very hard. Perhaps it will take human being another 100 years to solve it. Your attempt is noble, Maybe the Gods of Olympus will smile on you one day. Do not be too disappointed. B. Sagre has the honor of publishing three wrong proofs and C. Chevalley mistakes a wrong proof for a correct one in the 1950‚Äôs in his Math Review comments, and I.R. Shafarevich uses Jacobian Conjecture (to him it is a theorem) as a fact‚Ä¶</p>
</blockquote>
</blockquote>
<p>This look into the proverbial sausage factory should not come as a surprise to anyone taking an <a href="http://wiki.lesswrong.com/wiki/Outside_view">Outside View</a>: why wouldn‚Äôt we expect any area of intellectual endeavour to have error rates within a few orders of magnitude as any other area? How absurd to think that the rate might be ~0%; but it‚Äôs also a little questionable to be as optimistic as <a href="http://www.aleph.se/andart/archives/2012/09/flaws_in_the_perfection.html" title="Flaws in the Perfection">Anders Sandberg‚Äôs mathematician friend</a>: ‚Äúhe responded that he thought a far smaller number [1%] of papers in math were this flawed.‚Äù</p>
</section>
</section>
<section id="heuristics" class="level1">
<h1>Heuristics</h1>
<p>Other times, the correct result is known and proven, but many are unaware of the answers<a href="#fn9" class="footnoteRef" id="fnref9"><sup>9</sup></a>. The famous <a href="http://en.wikipedia.org/wiki/Millennium%20Problems" title="Wikipedia: Millennium Problems">Millennium Problems</a> - those that have been solved, anyway - have a long history of failed proofs (Fermat surely did not prove <a href="http://en.wikipedia.org/wiki/Fermat%27s%20Last%20Theorem" title="Wikipedia: Fermat‚Äôs Last Theorem">Fermat‚Äôs Last Theorem</a> &amp; may have realized this only after boasting<a href="#fn10" class="footnoteRef" id="fnref10"><sup>10</sup></a> and neither did <a href="http://en.wikipedia.org/wiki/Ferdinand%20von%20Lindemann" title="Wikipedia: Ferdinand von Lindemann">Lindemann</a><a href="#fn11" class="footnoteRef" id="fnref11"><sup>11</sup></a>). What explains this? The guiding factor that keeps popping up when mathematicians make leaps seems to go under the name of ‚Äòelegance‚Äô or <a href="http://en.wikipedia.org/wiki/mathematical%20beauty" title="Wikipedia: mathematical beauty">mathematical beauty</a>, which widely considered important<a href="#fn12" class="footnoteRef" id="fnref12"><sup>12</sup></a><a href="#fn13" class="footnoteRef" id="fnref13"><sup>13</sup></a><a href="#fn14" class="footnoteRef" id="fnref14"><sup>14</sup></a>. This imbalance suggests that mathematicians are quite correct when they say proofs are not the heart of mathematics and that they possess insight into math, a 6th sense for mathematical truth, a nose for aesthetic beauty which correlates with veracity: they disproportionately go after theorems rather than their negations.</p>
<p>Why this is so, I do not know.</p>
<p>Outright Platonism like Godel apparently believed in seems unlikely - mathematical expertise resembles a complex skill like chess-playing more than it does a sensory modality like vision. Possibly they have well-developed heuristics and short-cuts and they focus on the subsets of results on which those heuristics work well (the drunk searching under the spotlight), or perhaps they <em>do</em> run full rigorous proofs but are doing so subconsciously and merely express themselves ineptly consciously with omissions and erroneous formulations ‚Äòleft as an exercise for the reader‚Äô<a href="#fn15" class="footnoteRef" id="fnref15"><sup>15</sup></a>.</p>
<p>We could try to justify the heuristic paradigm by appealing to as-yet poorly understood aspects of the brain, like our visual cortex: argue that what is going on is that mathematicians are subconsciously doing tremendous amounts of computation (like we do tremendous amounts of computation in a thought as ordinary as recognizing a face), which they are unable to bring up explicitly. So after prolonged introspection and some comparatively simple explicit symbol manipulation or thought, they <em>feel</em> that a conjecture is true and this is due to a summary of said massive computations.</p>
<p>Perhaps they are checking many instances? Perhaps they are <a href="http://en.wikipedia.org/wiki/white-box%20testing" title="Wikipedia: white-box testing">white-box testing</a> and looking for boundaries? Could there be some sort of ‚Äúlogical probability‚Äù where going down possible proof-paths yield probabilistic information about the final target theorem, maybe in some sort of <a href="http://en.wikipedia.org/wiki/Monte%20Carlo%20method" title="Wikipedia: Monte Carlo method">Monte Carlo tree search</a> of proof-trees? Reading great mathematicians like <a href="http://en.wikipedia.org/wiki/Terence%20Tao" title="Wikipedia: Terence Tao">Terence Tao</a> discuss the heuristics they use on unsolved problems<a href="#fn16" class="footnoteRef" id="fnref16"><sup>16</sup></a>, they bear some resemblances to computer science techniques. This would be consistent with a preliminary observation about <a href="http://arxiv.org/abs/1202.3936" title="'On the distribution of time-to-proof of mathematical conjectures', Hisano &amp; Sornette 2012">how long it takes to</a> <a href="./docs/2013-hisano.pdf" title="'Challenges to the Assessment of Time-to-Proof of Mathematical Conjectures', Hisano &amp; Sornette 2013">solve mathematical conjectures</a>: while inference is rendered difficult by the exponential growth in the global population and of mathematicians, the distribution of time-to-solution roughly matches an exponential distribution or one with a constant chance of solving it in any time period, suggesting that the limiting factor is how much time &amp; effort has been spent on it. This idea of extensive unconscious computation neatly accords with Poincar√©‚Äôs account of mathematical creativity in which after long fruitless effort (preparation), he abandoned the problem for a time and engaged in ordinary activities (<a href="http://en.wikipedia.org/wiki/Incubation%20%28psychology%29" title="Wikipedia: Incubation (psychology)">incubation</a>), is suddenly struck by an answer or insight, and then verifies its correctness consciously. The existence of an incubation effect seems confirmed by psychological studies and particular the observation that incubation effects increase with the time allowed for incubation &amp; also if the subject does not undertake demanding mental tasks during the incubation period (see <a href="http://www.psy.cmu.edu/~unsio/Sio_Ormerod_meta_analysis_incubation_PB.pdf" title="Does incubation enhance problem-solving? A meta-analytic review">Sio &amp; Ormerod 2009</a>), and is consistent with extensive unconscious computation.</p>
<p>Heuristics, however, do not generalize, and fail outside their particular domain. Are we fortunate enough that the domain mathematicians work in is - deliberately or accidentally - just that domain in which their heuristics/intuition succeeds? <a href="http://www.aleph.se/andart/archives/2012/09/flaws_in_the_perfection.html">Sandberg</a> suggests not:</p>
<blockquote>
<p>Unfortunately I suspect that the connoisseurship of mathematicians for truth might be local to their domain. I have discussed with friends about how ‚Äúbrittle‚Äù different mathematical domains are, and our consensus is that there are definitely differences between logic, geometry and calculus. Philosophers also seem to have a good nose for what works or doesn‚Äôt in their domain, but it doesn‚Äôt seem to carry over to other domains. Now moving outside to applied domains things get even trickier. There doesn‚Äôt seem to be the same ‚Äúnose for truth‚Äù in risk assessment, perhaps because it is an interdisciplinary, messy domain. The cognitive abilities that help detect correct decisions are likely local to particular domains, trained through experience and maybe talent (i.e.¬†some conformity between neural pathways and deep properties of the domain). The only thing that remains is general-purpose intelligence, and that has its own limitations.</p>
</blockquote>
<p>We can probably add software to that list: early software engineering work found that, dismayingly, bug rates seem to be simply a function of <a href="http://en.wikipedia.org/wiki/lines%20of%20code" title="Wikipedia: lines of code">lines of code</a>, and one <a href="http://www.codinghorror.com/blog/2006/07/diseconomies-of-scale-and-lines-of-code.html">would expect</a> <a href="http://en.wikipedia.org/wiki/diseconomies%20of%20scale" title="Wikipedia: diseconomies of scale">diseconomies of scale</a>. So one would expect that in going from the ~4,000 lines of code of the Microsoft DOS operating system kernel to the ~50,000,000 lines of code in Windows Server 2003 (with full systems of applications and libraries being even larger: the comprehensive <a href="http://en.wikipedia.org/wiki/Debian" title="Wikipedia: Debian">Debian</a> repository in 2007 contained <a href="http://debian-counting.libresoft.es/lenny/index.php?menu=Statistics">~323,551,126</a> lines of code) that the number of active bugs at any time would be‚Ä¶ fairly large. This lead to predictions of doom and spurred much research into automated proof-checking, static analysis, and functional languages<a href="#fn17" class="footnoteRef" id="fnref17"><sup>17</sup></a>.</p>
<p>The doom, however, did not manifest and arguably operating systems &amp; applications are more reliable in the 2000s+ than they were in the 1980-1990s<a href="#fn18" class="footnoteRef" id="fnref18"><sup>18</sup></a> (eg. the general disappearance of the <a href="http://en.wikipedia.org/wiki/Blue%20Screen%20of%20Death" title="Wikipedia: Blue Screen of Death">Blue Screen of Death</a>). Users may not appreciate this point, but programmers who happen to think one day of just how the sausage of Gmail is made - how many interacting technologies and stacks of formats and protocols are involved - may get the shakes and wonder how it could <em>ever</em> work, much less be working at that moment. The answer is not really clear: it seems to be a combination of abundant computing resources driving down per-line error rates by avoiding optimization, modularization reducing interactions between lines, greater use of testing invoking an adversarial attitude to one‚Äôs code, and a light sprinkling of formal methods &amp; static checks<a href="#fn19" class="footnoteRef" id="fnref19"><sup>19</sup></a>.</p>
<p>While hopeful, it‚Äôs not clear how many of these would apply to existential risks: how does one use randomized testing on theories of existential risk, or tradeoff code clarity for computing performance?</p>
<section id="type-i-vs-type-ii" class="level2">
<h2>Type I vs Type II</h2>
<p>So we might forgive case 1 errors entirely: if a community of mathematicians take an ‚Äòincorrect‚Äô proof about a particular existential risk and ratify it (either by verifying the proof subconsciously or seeing what their heuristics say), it not being written out because it would be tedious too<a href="#fn20" class="footnoteRef" id="fnref20"><sup>20</sup></a>, then we may be more confident in it<a href="#fn21" class="footnoteRef" id="fnref21"><sup>21</sup></a> than lumping the two error rates together. Case 2 errors are the problem, and they can sometimes be systematic. Most dramatically, when an entire group of papers with all their results turn out to be wrong since they made a since-disproved assumption:</p>
<blockquote>
<p>In the 1970s and 1980s, mathematicians discovered that framed manifolds with Arf-<a href="http://en.wikipedia.org/wiki/Kervaire%20invariant" title="Wikipedia: Kervaire invariant">Kervaire invariant</a> equal to 1 - oddball manifolds not surgically related to a sphere - do in fact exist in the first five dimensions on the list: 2, 6, 14, 30 and 62. A clear pattern seemed to be established, and many mathematicians felt confident that this pattern would continue in higher dimensions‚Ä¶Researchers developed what Ravenel calls an entire ‚Äúcosmology‚Äù of conjectures based on the assumption that manifolds with Arf-Kervaire invariant equal to 1 exist in all dimensions of the form <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msup><mn>2</mn><mi>n</mi></msup><mo>‚àí</mo><mn>2</mn></mrow></math>. Many called the notion that these manifolds might not exist the ‚ÄúDoomsday Hypothesis,‚Äù as it would wipe out a large body of research. Earlier this year, Victor Snaith of the University of Sheffield in England published a book about this research, warning in the preface, ‚Äú‚Ä¶this might turn out to be a book about things which do not exist.‚Äù</p>
<p>Just weeks after Snaith‚Äôs book appeared, Hopkins announced on April 21 that Snaith‚Äôs worst fears were justified: that Hopkins, Hill and Ravenel had proved that no manifolds of Arf-Kervaire invariant equal to 1 exist in dimensions 254 and higher. Dimension 126, the only one not covered by their analysis, remains a mystery. The new finding is convincing, even though it overturns many mathematicians‚Äô expectations, Hovey said.<a href="#fn22" class="footnoteRef" id="fnref22"><sup>22</sup></a></p>
</blockquote>
<p>The <a href="http://en.wikipedia.org/wiki/Parallel%20postulate%23History" title="Wikipedia: Parallel postulate#History">parallel postulate</a> is another fascinating example of mathematical error of the second kind; its history is replete with false proofs even by greats like <a href="http://en.wikipedia.org/wiki/Joseph%20Louis%20Lagrange" title="Wikipedia: Joseph Louis Lagrange">Lagrange</a> (on what strike the modern reader as bizarre grounds)<a href="#fn23" class="footnoteRef" id="fnref23"><sup>23</sup></a>, self-deception, and misunderstandings - <a href="http://en.wikipedia.org/wiki/Giovanni%20Girolamo%20Saccheri" title="Wikipedia: Giovanni Girolamo Saccheri">Giovanni Girolamo Saccheri</a> developed a non-Euclidean geometry flawlessly but concluded it was flawed:</p>
<blockquote>
<p>The second possibility turned out to be harder to refute. In fact he was unable to derive a logical contradiction and instead derived many non-intuitive results; for example that triangles have a maximum finite area and that there is an absolute unit of length. He finally concluded that: ‚Äúthe hypothesis of the acute angle is absolutely false; because it is repugnant to the nature of straight lines‚Äù. Today, his results are theorems of <a href="http://en.wikipedia.org/wiki/hyperbolic%20geometry" title="Wikipedia: hyperbolic geometry">hyperbolic geometry</a>.</p>
</blockquote>
<p>We could look upon Type II errors as having a benevolent aspect: they show both that our existing methods are too weak &amp; informal <em>and</em> that our intuition/heuristics break down at it - implying that all previous mathematical effort has been <em>systematically</em> misled in avoiding that area (as empty), and that there is much low-hanging fruit. (Consider how many scores or hundreds of key theorems were proven by the very first mathematicians to work in the non-Euclidean geometries!)</p>
</section>
</section>
<section id="future-implications" class="level1">
<h1>Future implications</h1>
<p>Should such widely-believed conjectures as <a href="http://en.wikipedia.org/wiki/P%3DNP" title="Wikipedia: P=NP">P‚â†NP</a> or the <a href="http://en.wikipedia.org/wiki/Riemann%20hypothesis" title="Wikipedia: Riemann hypothesis">Riemann hypothesis</a> turn out be false, then because they are assumed by so many existing proofs, a far larger math holocaust would ensue<a href="#fn24" class="footnoteRef" id="fnref24"><sup>24</sup></a> - and our previous estimates of error rates will turn out to have been substantial underestimates. But it may be a cloud with a silver lining, if it doesn‚Äôt come at a time of danger.</p>
</section>
<section id="external-links" class="level1">
<h1>External links</h1>
<ul>
<li><a href="https://archive.org/details/eassayonthepsych006281mbp"><em>An Essay on the Psychology of Invention in the Mathematical Field</em></a> (<a href="http://en.wikipedia.org/wiki/Jacques%20Hadamard" title="Wikipedia: Jacques Hadamard">Jacques Hadamard</a>; 1945)</li>
<li><p>Responses:</p>
<ul>
<li><a href="http://www.aleph.se/andart/archives/2012/09/flaws_in_the_perfection.html">‚ÄúFlaws in the Perfection‚Äù</a> -(Anders Sandberg commentary on this essay)</li>
<li><a href="https://news.ycombinator.com/item?id=6500577">Hacker News discussion</a></li>
</ul></li>
<li><a href="http://lesswrong.com/r/discussion/lw/fzc/bounding_the_impact_of_agi/">‚ÄúBounding the impact of AGI‚Äù</a></li>
<li><a href="http://intelligence.org/2013/10/03/proofs/">‚ÄúMathematical Proofs Improve But Don‚Äôt Guarantee Security, Safety, and Friendliness‚Äù</a> (Luke Muehlhauser)</li>
<li><a href="https://terrytao.wordpress.com/2012/09/18/the-probabilistic-heuristic-justification-of-the-abc-conjecture/">‚ÄúThe probabilistic heuristic justification of the ABC conjecture‚Äù</a> (Terence Tao)</li>
<li><p><a href="http://rjlipton.wordpress.com/2014/03/15/could-we-have-felt-evidence-for-sdp-p/">‚ÄúCould We Have Felt Evidence For SDP ‚â† P?‚Äù</a> (see particularly ‚ÄúBad Guesses‚Äù)</p></li>
</ul>
</section>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><p>Citations:</p>
<blockquote>
<ul>
<li>Bell, E.T.: 1951, ‚ÄúThe Queen of Mathematics‚Äù, reprinted in J. R. Newman (ed.), <a href="http://www.amazon.com/World-Mathematics-Four--Set/dp/0486432688/?tag=gwernnet-20"><em>The World of Mathematics</em></a>, Simon and Schuster (1956)</li>
<li>De Milo, R. Lipton, and A. Perlis: 1979, ‚ÄúSocial Processes and Proofs of Theorems and Programs‚Äù, <em>Communication of the ACM</em>, Vol. 22, No. 5. Reprinted in T. Tymozcko (ed.), <a href="http://www.amazon.com/Directions-Philosophy-Mathematics-Thomas-Tymoczko/dp/0691034982/?tag=gwernnet-20"><em>New Directions in the Philosophy of Mathematics</em></a>, Princeton University Press (1998). Page numbers refer to the book</li>
</ul>
</blockquote>
<a href="#fnref1">‚Ü©</a></li>
<li id="fn2"><p>There are various delusions (eg. <a href="http://en.wikipedia.org/wiki/Cotard%20delusion" title="Wikipedia: Cotard delusion">Cotard delusion</a>), <a href="http://en.wikipedia.org/wiki/false%20memory%20syndrome" title="Wikipedia: false memory syndrome">false memory syndrome</a>s, compulsive lying (<a href="http://en.wikipedia.org/wiki/pseudologia%20fantastica" title="Wikipedia: pseudologia fantastica">pseudologia fantastica</a>), disorders provoking <a href="http://en.wikipedia.org/wiki/Confabulation" title="Wikipedia: Confabulation">confabulation</a> such as the general symptom of <a href="http://en.wikipedia.org/wiki/anosognosia" title="Wikipedia: anosognosia">anosognosia</a>; in a dramatic example of how the mind is what the brain does, some anosognosia can be temporarily cured by squirting cold water in an ear; from <a href="http://lesswrong.com/lw/20/the_apologist_and_the_revolutionary/">‚ÄúThe Apologist and the Revolutionary‚Äù</a>:</p>
<blockquote>
<p>Take the example of the woman discussed in Lishman‚Äôs <a href="http://www.amazon.com/Organic-Psychiatry-Psychological-Consequences-Cerebral/dp/0865428204/?tag=gwernnet-20"><em>Organic Psychiatry</em></a>. After a right-hemisphere stroke, she lost movement in her left arm but continuously denied it. When the doctor asked her to move her arm, and she observed it not moving, she claimed that it wasn‚Äôt actually her arm, it was her daughter‚Äôs. Why was her daughter‚Äôs arm attached to her shoulder? The patient claimed her daughter had been there in the bed with her all week. Why was her wedding ring on her daughter‚Äôs hand? The patient said her daughter had borrowed it. Where was the patient‚Äôs arm? The patient ‚Äúturned her head and searched in a bemused way over her left shoulder‚Äù‚Ä¶In any case, a patient who has been denying paralysis for weeks or months will, upon having cold water placed in the ear, admit to paralysis, admit to having been paralyzed the past few weeks or months, and express bewilderment at having ever denied such an obvious fact. And then the effect wears off, and the patient not only denies the paralysis but denies ever having admitted to it.</p>
</blockquote>
<a href="#fnref2">‚Ü©</a></li>
<li id="fn3"><p>Most/all math results require their system to be consistent; but this is one particular philosophical view. <a href="http://en.wikipedia.org/wiki/Ludwig%20Wittgenstein" title="Wikipedia: Ludwig Wittgenstein">Ludwig Wittgenstein</a>, in <em><a href="http://en.wikipedia.org/wiki/Remarks%20on%20the%20Foundations%20of%20Mathematics" title="Wikipedia: Remarks on the Foundations of Mathematics">Remarks on the Foundations of Mathematics</a></em>:</p>
<blockquote>
<p>If a contradiction were now actually found in arithmetic - that would only prove that an arithmetic with <em>such</em> a contradiction in it could render very good service; and it would be better for us to modify our concept of the certainty required, than to say it would really not yet have been a proper arithmetic.</p>
</blockquote>
<p><a href="http://en.wikipedia.org/wiki/Saul%20Kripke" title="Wikipedia: Saul Kripke">Saul Kripke</a>, <a href="http://en.wikipedia.org/wiki/Wittgenstein%20on%20Rules%20and%20Private%20Language" title="Wikipedia: Wittgenstein on Rules and Private Language">reconstructing a Wittgensteinian skeptical argument</a>, points out one way to react to such issues:</p>
<blockquote>
<p>A <em>skeptical</em> solution of a philosophical problem begins‚Ä¶ by conceding that the skeptic‚Äôs negative assertions are unanswerable. Nevertheless our ordinary practice or belief is justified because-contrary appearances notwithstanding-it need not require the justification the sceptic has shown to be untenable. And much of the value of the sceptical argument consists precisely in the fact that he has shown that an ordinary practice, if it is to be defended at all, cannot be defended in a certain way.</p>
</blockquote>
<a href="#fnref3">‚Ü©</a></li>
<li id="fn4"><p><a href="http://rjlipton.wordpress.com/2010/06/19/guessing-the-truth/">Lipton</a> <a href="http://rjlipton.wordpress.com/2009/09/27/surprises-in-mathematics-and-theory/">lists</a> several:</p>
<ol type="1">
<li>the transcendality of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msup><mn>2</mn><msqrt><mn>2</mn></msqrt></msup></mrow></math> and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msup><mi>e</mi><mi>œÄ</mi></msup></mrow></math>: resolved as predicted, but &gt;78 years faster than he predicted.</li>
<li>proof of the consistency of arithmetic: prediction that arithmetic was consistent and this was provable was falsified (Goedel showing it is unprovable)</li>
</ol>
<p>One could add to this Hilbert list: the continuum hypothesis (independent); and the algorithm for solving Diophantines (impossible to give, to the surprise of <a href="http://en.wikipedia.org/wiki/Georg%20Kreisel" title="Wikipedia: Georg Kreisel">Georg Kreisel</a> who said reviewing one of the papers ‚ÄúWell, that‚Äôs not the way it‚Äôs gonna go.‚Äù). From <a href="http://mathoverflow.net/questions/35468/widely-accepted-mathematical-results-that-were-later-shown-wrong/35554#35554">MathOverflow</a>:</p>
<blockquote>
<p>Hilbert‚Äôs 21st problem, on the existence of linear DEs with prescribed monodromy group, was for a long time thought to have been solved by Plemelj in 1908. In fact, Plemelj died in 1967 still believing he had solved the problem. However, in 1989, Bolibruch discovered a counterexample. Details are in the book <a href="http://www.amazon.com/Riemann-Hilbert-Problem-Aspects-Mathematics/dp/352806496X/?tag=gwernnet-20"><em>The Riemann-Hilbert Problem</em></a> by Anosov and Bolibruch (Vieweg-Teubner 1994), and a nice popular recounting of the story is in Ben Yandell‚Äôs <a href="http://www.amazon.com/Honors-Class-Hilberts-Problems-Solvers/dp/1568812167/?tag=gwernnet-20"><em>The Honors Class</em></a> (A K Peters 2002).</p>
</blockquote>
<p>Lipton also provides as examples:</p>
<ul>
<li>Warren Hirsch‚Äôs polytope conjecture</li>
<li>Subhash Khot‚Äôs conjecture that his Unique Games problem is NP-hard (not falsified but substantially weakened)</li>
<li>the search for a proof of Euclid‚Äôs fifth postulate (covered already)</li>
<li>George P√≥lya‚Äôs prime factorization conjecture</li>
<li>Euler‚Äôs generalization of Fermat‚Äôs last theorem</li>
<li>Virginia Ragsdale‚Äôs combinatorial conjecture, related to a Hilbert problem</li>
<li><p>Erik Zeeman‚Äôs knot-tying conjecture; the resolution is too good to not quote:</p>
<blockquote>
<p>After trying to prove this for almost ten years, one day he worked on the opposite direction, and solved it in hours.</p>
</blockquote></li>
<li>a von Neumann topological conjecture</li>
<li>conventional wisdom in complexity theory ‚Äúthat bounded-width programs could not compute the majority function, and many other functions‚Äù</li>
<li>ditto, ‚ÄúMost believed that nondeterministic logspace (<em>NLOG</em>) is not closed under complement.‚Äù</li>
<li>B√©la Julesz‚Äôs human vision statistics conjecture</li>
<li><p><a href="http://en.wikipedia.org/wiki/Burnside%27s%20problem" title="Wikipedia: Burnside's problem">Burnside‚Äôs conjecture</a></p></li>
</ul>
<a href="#fnref4">‚Ü©</a></li>
<li id="fn5"><p>John von Neumann, <a href="http://www-history.mcs.st-and.ac.uk/Extras/Von_Neumann_Part_1.html">‚ÄúThe Mathematician‚Äù</a> (1947):</p>
<blockquote>
<p>That Euclid‚Äôs axiomatization does at some minor points not meet the modern requirements of absolute axiomatic rigour is of lesser importance in this respect‚Ä¶The first formulations of the calculus were not even mathematically rigorous. An inexact, semi-physical formulation was the only one available for over a hundred and fifty years after Newton! And yet, some of the most important advances of analysis took place during this period, against this inexact, mathematically inadequate background! Some of the leading mathematical spirits of the period were clearly not rigorous, like Euler; but others, in the main, were, like Gauss or Jacobi. The development was as confused and ambiguous as can be, and its relation to empiricism was certainly not according to our present (or Euclid‚Äôs) ideas of abstraction and rigour. Yet no mathematician would want to exclude it from the fold - that period produced mathematics as first-class as ever existed! And even after the reign of rigour was essentially re-established with Cauchy, a very peculiar relapse into semi-physical methods took place with Riemann.</p>
</blockquote>
<a href="#fnref5">‚Ü©</a></li>
<li id="fn6"><p><a href="http://arxiv.org/pdf/0905.3590">‚ÄúDesperately seeking mathematical proof‚Äù</a> (<a href="http://arxiv.org/abs/0905.3590">arXiv</a>), Melvyn B. Nathanson 2009:</p>
<blockquote>
<p>The history of mathematics is full of philosophically and ethically troubling reports about bad proofs of theorems. For example, the <a href="http://en.wikipedia.org/wiki/fundamental%20theorem%20of%20algebra" title="Wikipedia: fundamental theorem of algebra">fundamental theorem of algebra</a> states that every polynomial of degree <em>n</em> with complex coefficients has exactly <em>n</em> complex roots. D‚ÄôAlembert published a proof in 1746, and the theorem became known ‚ÄúD‚ÄôAlembert‚Äôs theorem‚Äù, but the proof was wrong. Gauss published his first proof of the fundamental theorem in 1799, but this, too, had gaps. Gauss‚Äôs subsequent proofs, in 1816 and 1849, were OK. It seems to have been hard to determine if a proof of the fundamental theorem of algebra was correct. Why?</p>
<p><a href="http://en.wikipedia.org/wiki/Henri%20Poincare" title="Wikipedia: Henri Poincare">Poincar√©</a> was awarded a prize from King Oscar II of Sweden and Norway for a paper on the <a href="http://en.wikipedia.org/wiki/three-body%20problem" title="Wikipedia: three-body problem">three-body problem</a>, and his paper was published in <em>Acta Mathematica</em> in 1890. But the published paper was not the prize-winning paper. The paper that won the prize contained serious mistakes, and Poincare and other mathematicians, most importantly, <a href="http://en.wikipedia.org/wiki/G%C3%B6sta%20Mittag-Leffler" title="Wikipedia: G√∂sta Mittag-Leffler">Mittag-Leffler</a>, engaged in a conspiracy to suppress the truth and to replace the erroneous paper with an extensively altered and corrected one.</p>
</blockquote>
<p>(<a href="http://www.math.uvic.ca/faculty/diacu/diacuNbody.pdf" title="Diacu 1996">‚ÄúThe Solution of the <em>n</em>-body Problem‚Äù</a> gives a summary of the eventual exact solution to the three-body problem.)<a href="#fnref6">‚Ü©</a></p></li>
<li id="fn7"><p><a href="http://alumni.media.mit.edu/~cahn/life/gian-carlo-rota-10-lessons.html#mistakes">‚ÄúTen Lessons I wish I had been Taught‚Äù</a>, Gian-Carlo Rota 1996<a href="#fnref7">‚Ü©</a></p></li>
<li id="fn8"><p>There are 2 20th century mathematicians, born too late to work with Faraday, and the telegraph inventor Samuel Morse who while overlapping with Faraday, has a Wikipedia entry mentioning no work in mathematics; I do not know which Morse may be meant.<a href="#fnref8">‚Ü©</a></p></li>
<li id="fn9"><p>An example of this would be <a href="http://digital.lib.washington.edu/dspace/bitstream/handle/1773/4592/An_enduring_error.pdf?sequence=1">‚ÄúAn Enduring Error‚Äù</a>, Branko Gr√ºnbaum:</p>
<blockquote>
<p>Mathematical truths are immutable, but mathematicians do make errors, especially when carrying out non-trivial enumerations. Some of the errors are ‚Äúinnocent‚Äù ‚Äì plain mistakes that get corrected as soon as an independent enumeration is carried out. For example, Daublebsky [14] in 1895 found that there are precisely 228 types of configurations (123), that is, collections of 12 lines and 12 points, each incident with three of the others. In fact, as found by Gropp [19] in 1990, the correct number is 229. Another example is provided by the enumeration of the uniform tilings of the 3-dimensional space by Andreini [1] in 1905; he claimed that there are precisely 25 types. However, as shown [20] in 1994, the correct number is 28. Andreini listed some tilings that should not have been included, and missed several others ‚Äì but again, these are simple errors easily corrected‚Ä¶.It is surprising how errors of this type escape detection for a long time, even though there is frequent mention of the results. One example is provided by the enumeration of 4-dimensional simple polytopes with 8 facets, by Br√ºckner [7] in 1909. He replaces this enumeration by that of 3-dimensional ‚Äúdiagrams‚Äù that he interpreted as Schlegel diagrams of convex 4-polytopes, and claimed that the enumeration of these objects is equivalent to that of the polytopes. However, aside from several ‚Äúinnocent‚Äù mistakes in his enumeration, there is a fundamental error: While to all 4-polytopes correspond 3-dimensional diagrams, there is no reason to assume that every diagram arises from a polytope. At the time of Br√ºckner‚Äôs paper, even the corresponding fact about 3-polyhedra and 2-dimensional diagrams has not yet been established ‚Äì this followed only from Steinitz‚Äôs characterization of complexes that determine convex polyhedra [45], [46]. In fact, in the case considered by Br√ºckner, the assumption is not only unjustified, but actually wrong: One of Br√ºckner‚Äôs polytopes does not exist, see [25].</p>
<p>‚Ä¶Polyhedra have been studied since antiquity. It is, therefore, rather surprising that even concerning some of the polyhedra known since that time there is a lot of confusion, regarding both terminology and essence. But even more unexpected is the fact that many expositions of this topic commit serious mathematical and logical errors. Moreover, this happened not once or twice, but many times over the centuries, and continues to this day in many printed and electronic publications; the most recent case is in the second issue for 2008 of this journal‚Ä¶.With our understandings and exclusions, there are fourteen convex polyhedra that satisfy the local criterion and should be called ‚ÄúArchimedean‚Äù, but only thirteen that satisfy the global criterion and are appropriately called ‚Äúuniform‚Äù (or ‚Äúsemiregular‚Äù). Representatives of the thirteen uniform convex polyhedra are shown in the sources mentioned above, while the fourteenth polyhedron is illustrated in Figure 1. It satisfies the local criterion but not the global one, and therefore is - in our terminology - Archimedean but not uniform. The history of the realization that the local criterion leads to fourteen polyhedra will be discussed in the next section; it is remarkable that this development occurred only in the 20th century. This implies that prior to the twentieth century all enumerations of the polyhedra satisfying the local criterion were mistaken. Unfortunately, many later enumerations make the same error.</p>
</blockquote>
<a href="#fnref9">‚Ü©</a></li>
<li id="fn10"><p>Dana Mackinzie, <a href="http://www.amazon.com/gp/product/B007BP3ATU/?tag=gwernnet-20"><em>The Universe in Zero Words: The Story of Mathematics as Told through Equations</em></a> (as quoted by <a href="http://www.johndcook.com/blog/2013/10/15/fermats-proof-of-his-last-theorem/">John D. Cook</a>):</p>
<blockquote>
<p>Fermat repeatedly bragged about the <em>n</em> = 3 and <em>n</em> = 4 cases and posed them as challenges to other mathematicians ‚Ä¶ But he never mentioned the general case, <em>n</em> = 5 and higher, in any of his letters. Why such restraint? Most likely, <a href="http://en.wikipedia.org/wiki/Andr%C3%A9%20Weil" title="Wikipedia: Andr√© Weil">Weil</a> argues, because Fermat had realized that his ‚Äútruly wonderful proof‚Äù did not work in those cases‚Ä¶Every mathematician has had days like this. You think you have a great insight, but then you go out for a walk, or you come back to the problem the next day, and you realize that your great idea has a flaw. Sometimes you can go back and fix it. And sometimes you can‚Äôt.</p>
</blockquote>
<a href="#fnref10">‚Ü©</a></li>
<li id="fn11"><p>From <a href="http://en.wikipedia.org/wiki/MathWorld" title="Wikipedia: MathWorld">MathWorld</a>, <a href="http://mathworld.wolfram.com/FermatsLastTheorem.html">‚ÄúFermat‚Äôs Last Theorem‚Äù</a>:</p>
<blockquote>
<p>Much additional progress was made over the next 150 years, but no completely general result had been obtained. Buoyed by false confidence after his proof that pi is transcendental, the mathematician Lindemann proceeded to publish several proofs of Fermat‚Äôs Last Theorem, all of them invalid (Bell 1937, pp.¬†464-465). A prize of 100000 German marks, known as the Wolfskehl Prize, was also offered for the first valid proof (Ball and Coxeter 1987, p.¬†72; Barner 1997; Hoffman 1998, pp.¬†193-194 and 199).</p>
<p>A recent false alarm for a general proof was raised by Y. Miyaoka (Cipra 1988) whose proof, however, turned out to be flawed. Other attempted proofs among both professional and amateur mathematicians are discussed by vos Savant (1993), although vos Savant erroneously claims that work on the problem by Wiles (discussed below) is invalid.</p>
</blockquote>
<a href="#fnref11">‚Ü©</a></li>
<li id="fn12"><p>To take a random example (which could be multiplied indefinitely); from <a href="http://www.edge.org/3rd_culture/goldstein05/goldstein05_index.html">G√∂del and the Nature of Mathematical Truth: A Talk with Rebecca Goldstein</a> (6.8.2005):</p>
<blockquote>
<p>Einstein told the philosopher of science <a href="http://en.wikipedia.org/wiki/Hans%20Reichenbach" title="Wikipedia: Hans Reichenbach">Hans Reichenbach</a> that he‚Äôd known even before the solar eclipse of 1918 supported his general theory of relativity that the theory must be true because it was so beautiful. And <a href="http://en.wikipedia.org/wiki/Hermann%20Weyl" title="Wikipedia: Hermann Weyl">Hermann Weyl</a>, who worked on both relativity theory and quantum mechanics, said ‚ÄúMy work always tried to unite the true with the beautiful, but when I had to choose one or the other, I usually chose the beautiful.‚Äù‚Ä¶Mathematics seems to be the one place where you don‚Äôt have to choose, where truth and beauty are always united. One of my all-time favorite books is <em><a href="http://en.wikipedia.org/wiki/A%20Mathematician%27s%20Apology" title="Wikipedia: A Mathematician‚Äôs Apology">A Mathematician‚Äôs Apology</a></em>. <a href="http://en.wikipedia.org/wiki/G.H.%20Hardy" title="Wikipedia: G.H. Hardy">G.H. Hardy</a> tries to demonstrate to a general audience that mathematics is intimately about beauty. He gives as examples two proofs, one showing that the square root of 2 is irrational, the other showing that there‚Äôs no largest prime number. Simple, easily graspable proofs, that stir the soul with wonder.</p>
</blockquote>
<a href="#fnref12">‚Ü©</a></li>
<li id="fn13"><p>Nathanson 2009 claims the opposite:</p>
<blockquote>
<p>Many mathematicians have the opposite opinion; they do not or cannot distinguish the beauty or importance of a theorem from its proof. A theorem that is first published with a long and difficult proof is highly regarded. Someone who, preferably many years later, finds a short proof is ‚Äúbrilliant.‚Äù But if the short proof had been obtained in the beginning, the theorem might have been disparaged as an ‚Äúeasy result.‚Äù Erd≈ës was a genius at finding brilliantly simple proofs of deep results, but, until recently, much of his work was ignored by the mathematical establishment.</p>
</blockquote>
<a href="#fnref13">‚Ü©</a></li>
<li id="fn14"><p>From <a href="./docs/2009-sinclair.pdf">‚ÄúAesthetics as a Liberating Force in Mathematics Education?‚Äù</a>, by Nathalie Sinclair (reprinted in <a href="http://www.amazon.com/Best-Writing-Mathematics-2010/dp/0691148414/?tag=gwernnet-20"><em>The Best Writing on Mathematics 2010</em></a>, ed. Mircea Pitici); pg208:</p>
<blockquote>
<p>There is a long tradition in mathematics of describing proofs and theorems in aesthetic terms, often using words such as ‚Äòelegance‚Äô and ‚Äòdepth‚Äô. Further, mathematicians have also argued that their subject is more akin to an art than it is to a science (see <a href="http://en.wikipedia.org/wiki/A%20Mathematician%27s%20Apology" title="Wikipedia: A Mathematician's Apology">Hardy, 1967</a>; Littlewood, 1986; Sullivan 1925/1956), and, like the arts, ascribe to mathematics aesthetic goals. For example, the mathematician W. Krull (<a href="./docs/1987-krull.pdf" title="The aesthetic viewpoint in mathematics">1930/1987</a>) writes: ‚Äúthe primary goals of the mathematician are aesthetic, and not epistemological‚Äù (p.¬†49). This statement seems contradictory with the oft-cited concern of mathematics with finding or discovering truths, but it emphasises the fact that the mathematician‚Äôs interest is in expressing truth, and in doing so in clever, simple, succinct ways.</p>
<p>While Krull focuses on mathematical expression, the mathematician H. Poincare (<a href="http://paradise.caltech.edu/ist4/lectures/Poincare_Reflections.pdf" title="Mathematical Creation">1908/1966</a>) concerns himself with the psychology of mathematical invention, but he too underlines the aesthetic dimension of mathematics, not the logical. In Poincare‚Äôs theory, a large part of a mathematician‚Äôs work is done at the subconscious level, where an aesthetic sensibility is responsible for alerting the mathematicians to the most fruitful and interesting of ideas. Other mathematicians have spoken of this special sensibility as well and also in terms of the way it guides mathematicians to choose certain problems. This choice is essential in mathematic given that there exists no external reality against which mathematicians can decide which problems or which branches of mathematics are important (see von Neumann, 1947 [‚ÄúThe Mathematician‚Äù]): the choice involves human values and preference - and, indeed, these change over time, as exemplified by the dismissal of geometry by some prominent mathematicians in the early 20th century (see <a href="http://www.math.yorku.ca/Who/Faculty/Whiteley/cmesg.pdf">Whiteley, 1999</a>).</p>
<ul>
<li>Littlewood, 1986: ‚ÄúThe mathematician‚Äôs art of work‚Äù; in B. Bollobas (ed.), <a href="http://www.amazon.com/Littlewoods-Miscellany-John-E-Littlewood/dp/052133702X/?tag=gwernnet-20"><em>Littlewood‚Äôs miscellany</em></a>, Cambridge University press</li>
<li>Sullivan 1925/1956: ‚ÄúMathematics as an art‚Äù; in J. Newman (ed.), <em>The world of mathematics</em>, vol 3 (p 2015-2021)</li>
</ul>
</blockquote>
<a href="#fnref14">‚Ü©</a></li>
<li id="fn15"><p>From pg 211-212, Sinclair 2009:</p>
<blockquote>
<p>The survey of mathematicians conducted by <a href="./docs/1990-wells.pdf">Wells (1990)</a> provides a more empirically-based challenge to the intrinsic view of the mathematical aesthetic. Wells obtained responses from over 80 mathematicians, who were asked to identify the most beautiful theorem from a given set of 24 theorems. (These theorems were chosen because they were ‚Äòfamous‚Äô, in the sense that Wells judged them to be well-known by most mathematicians, and of interest to the discipline in general, rather than to a particular subfield.) Wells finds that the mathematicians varied widely in their judgments. More interestingly, in explaining their choices, the mathematicians revealed a wide range of personal responses affecting their aesthetic responses to the theorems. Wells effectively puts to rest the belief that mathematicians have some kind of secret agreement on what counts as beautiful in mathematics‚Ä¶.Burton‚Äôs (2004) work focuses on the practices of mathematicians and their understanding of those practices. Based on extensive interviews with a wide range of mathematicians‚Ä¶She points out that mathematicians range on a continuum from unimportant to crucial in terms of their positionings on the role of the aesthetic, with only 3 of the 43 mathematicians dismissing its importance. For example, one said ‚ÄúBeauty doesn‚Äôt matter. I have never seen a beautiful mathematical paper in my life‚Äù (p.¬†65). Another mathematician was initially dismissive about mathematical beauty but later, when speaking about the review process, said: ‚ÄúIf it was a very elegant way of doing things, I would be inclined to forgive a lot of faults‚Äù (p.¬†65).</p>
<ul>
<li>Burton, Leone (2004): <a href="http://www.amazon.com/Mathematicians-Enquirers-Learning-Mathematics-Education/dp/1402078595/?tag=gwernnet-20"><em>Mathematicians as enquirers: Learning about learning mathematics</em></a>; Dordrecht: Kluwer Academic Publishers</li>
</ul>
</blockquote>
<a href="#fnref15">‚Ü©</a></li>
<li id="fn16"><p>Tao left a <a href="http://rjlipton.wordpress.com/2010/06/19/guessing-the-truth/#comment-3711">lengthy comment</a> on a previously linked Lipton post:</p>
<blockquote>
<p>It is possible to gather reasonably convincing support for a conjecture by a variety of means, long before it is actually proven, though many mathematicians are reluctant to argue too strongly based on such support due to the lack of rigour or the risk of embarrassment in hindsight. Examples of support include:</p>
<ul>
<li>Numerical evidence; but one has to be careful in situations where the null hypothesis would also give comparable numerical evidence. The first ten trillion zeroes of zeta on the critical line is, in my opinion, only mild evidence in favour of RH (the null hypothesis may be, for instance, that the zeroes go haywire once log log t becomes sufficiently large); but the numerical data on spacings of zeroes is quite convincing evidence for the GUE hypothesis, in my view. (It is a priori conceivable that the spacings are distributed according to GUE plus another correction that dominates when log log t (say) is large, but this begins to strain Occam‚Äôs razor.)</li>
<li>Non-trivial special cases. But it depends on how ‚Äúrepresentative‚Äù one believes the special cases to be. For instance, if one can verify low-dimensional cases of a conjecture that is true in high dimensions, this is usually only weak (but not entirely insignificant) evidence, as it is possible that there exist high-dimensional pathologies that sink the conjecture but cannot be folded up into a low-dimensional situation. But if one can do all odd-dimensional cases, and all even-dimensional cases up to dimension 8 (say), then that begins to look more convincing.</li>
<li>Proofs of parallel, analogous, or similar conjectures. Particularly if these proofs were non-trivial and led to new insights and techniques. RH in function fields is a good example here; it raises the hope of some sort of grand unified approach to GRH that somehow handles all number fields (or some other general class) simultaneously.</li>
<li>Converse of the conjecture is provable, and looks ‚Äúoptimal‚Äù somehow. One might be able to construct a list of all obvious examples of objects with property X, find significant difficulty extending the list, and then conjecture that this is list is complete. This is a common way to make conjectures, but can be dangerous, as one may simply have a lack of imagination. So this is thin evidence by itself (many false conjectures have arisen from this converse-taking method), but it does carry a little bit of weight once combined with other strands of evidence.</li>
<li>Conjecture is ambitious and powerful, and yet is not immediately sunk by the obvious consistency checks. This is vaguely analogous to the concept of a ‚Äúfalsifiable theory‚Äù in science. A strong conjecture could have many powerful consequences in a variety of disparate areas of mathematics - so powerful, in fact, that one would not be surprised that they could be disproven with various counterexamples. But surprisingly, when one checks the cases that one does understand quite well, the conjecture holds up. A typical example here might include a very general conjectured identity which, when specialised to various well-understood special cases, become a provable identity - but with the identity in each special case being provable by very different methods, and the connection between all the identities being mysterious other than via the conjecture. The general conjecture that the primes behave pseudorandomly after accounting for small moduli is an example of such a conjecture; we usually can‚Äôt control how the primes behave, but when we can, the pseudorandomess heuristic lines up perfectly.</li>
<li>Attempts at disproof run into interesting obstacles. This one is a bit hard to formalise, but sometimes you can get a sense that attempts to disprove a conjecture are failing not due to one‚Äôs own lack of ability, or due to accidental contingencies, but rather due to ‚Äúenemy activity‚Äù; some lurking hidden structure to the problem, corners of which emerge every time one tries to build a counterexample. The question is then whether this ‚Äúenemy‚Äù is stupid enough to be outwitted by a sufficiently clever counterexample, or is powerful enough to block all such attempts. Identifying this enemy precisely is usually the key to resolving the conjecture (or transforming the conjecture into a stronger and better conjecture).</li>
<li>Conjecture generalises to a broader conjecture that enjoys support of the types listed above. The twin prime conjecture, by itself, is difficult to support on its own; but when it comes with an asymptotic that one can then verify numerically to high accuracy and is a consequence of the much more powerful prime tuples conjecture (and more generally, the pseudorandomness heuristic for the primes) which is supported both because of its high falsifiability and also its nature as an optimal-looking converse (the only structure to the primes are the ‚Äúobvious‚Äù structures), it becomes much more convincing. Another textbook example is the Poincare conjecture, which became much more convincing after being interpreted as a special case of geometrisation (which had a lot of support, e.g.¬†the two-dimensional analogue, Haken manifolds, lots of falsifiable predictions, etc.).</li>
</ul>
<p>It can be fun (though a little risky, reputation-wise) to debate how strong various pieces of evidence really are, but one soon reaches a point of diminishing returns, as often we are limited by our own ignorance, lack of imagination, or cognitive biases. But we are at least reasonably able to perform <em>relative</em> comparisons of the strength of evidence of two conjectures in the same topic (I guess complexity theory is full of instances of this‚Ä¶).</p>
</blockquote>
<a href="#fnref16">‚Ü©</a></li>
<li id="fn17"><p><a href="./docs/1996-hoare.pdf">‚ÄúHow Did Software Get So Reliable Without Proof?‚Äù</a>, <a href="http://en.wikipedia.org/wiki/C.A.R.%20Hoare" title="Wikipedia: C.A.R. Hoare">C.A.R. Hoare</a> 1996:</p>
<blockquote>
<p>Twenty years ago it was reasonable to predict that the size and ambition of software products would be severely limited by the unreliability of their component programs. Crude estimates suggest that professionally written programs delivered to the customer can contain between one and ten independently correctable errors per thousand lines of code; and any software error in principle can have spectacular effect (or worse: a subtly misleading effect) on the behaviour of the entire system. Dire warnings have been issued..The arguments were sufficiently persuasive to trigger a significant research effort devoted to the problem of program correctness. A proportion of this research was based on the ideal of certainty achieved by mathematical proof.</p>
</blockquote>
<a href="#fnref17">‚Ü©</a></li>
<li id="fn18"><p>Hoare 1996:</p>
<blockquote>
<p>Fortunately, the problem of program correctness has turned out to be far less serious than predicted. A recent analysis by Mackenzie has shown that of several thousand deaths so far reliably attributed to dependence on computers, only ten or so can be explained by errors in the software: most of these were due to a couple of instances of incorrect dosage calculations in the treatment of cancer by radiation. Similarly predictions of collapse of software due to size have been falsified by continuous operation of real-time software systems now measured in tens of millions of lines of code, and subjected to thousands of updates per year‚Ä¶And aircraft, both civil and military, are now flying with the aid of software measured in millions of lines - though not all of it is safety-critical. Compilers and operating systems of a similar size now number their satisfied customers in millions. So the questions arise: why have twenty years of pessimistic predictions been falsified? Was it due to successful application of the results of the research which was motivated by the predictions? How could that be, when clearly little software has ever has been subjected to the rigours of formal proof?</p>
</blockquote>
<a href="#fnref18">‚Ü©</a></li>
<li id="fn19"><p>Hoare 1996:</p>
<blockquote>
<p>Success in the use of mathematics for specification, design and code reviews does not require strict formalisation of all the proofs. Informal reasoning among those who are fluent in the idioms of mathematics is extremely efficient, and remarkably reliable. It is not immune from failure; for example simple misprints can be surprisingly hard to detect by eye. Fortunately, these are exactly the kind of error that can be removed by early tests. More formal calculation can be reserved for the most crucial issues, such as interrupts and recovery procedures, where bugs would be most dangerous, expensive, and most difficult to diagnose by tests‚Ä¶Many more tests should be designed than there will ever be time to conduct; they should be generated as directly as possible from the specification, preferably automatically by computer program. Random selection at the last minute will protect against the danger that under pressure of time the program will be adapted to pass the tests rather than meeting the rest of its specification. There is some evidence that early attention to a comprehensive and rigorous test strategy can improve reliability of a delivered product, even when at the last minute there was no time to conduct the tests before delivery!</p>
</blockquote>
<a href="#fnref19">‚Ü©</a></li>
<li id="fn20"><p>The missing steps may be quite difficult to fully prove, though; Nathanson 2009:</p>
<blockquote>
<p>There is a lovely but probably apocryphal anecdote about <a href="http://en.wikipedia.org/wiki/Norbert%20Weiner" title="Wikipedia: Norbert Weiner">Norbert Weiner</a>. Teaching a class at MIT, he wrote something on the blackboard and said it was ‚Äòobvious.‚Äô One student had the temerity to ask for a proof. Weiner started pacing back and forth, staring at what he had written on the board and saying nothing. Finally, he left the room, walked to his office, closed the door, and worked. After a long absence he returned to the classroom. ‚ÄòIt <em>is</em> obvious‚Äô, he told the class, and continued his lecture.</p>
</blockquote>
<a href="#fnref20">‚Ü©</a></li>
<li id="fn21"><p>What conditions count as full scrutiny by the math community may not be too clear; Nathanson 2009 trenchantly mocks math talks:</p>
<blockquote>
<p>Social pressure often hides mistakes in proofs. In a seminar lecture, for example, when a mathematician is proving a theorem, it is technically possible to interrupt the speaker in order to ask for more explanation of the argument. Sometimes the details will be forthcoming. Other times the response will be that it‚Äôs ‚Äúobvious‚Äù or ‚Äúclear‚Äù or ‚Äúfollows easily from previous results.‚Äù Occasionally speakers respond to a question from the audience with a look that conveys the message that the questioner is an idiot. That‚Äôs why most mathematicians sit quietly through seminars, understanding very little after the introductory remarks, and applauding politely at the end of a mostly wasted hour.</p>
</blockquote>
<a href="#fnref21">‚Ü©</a></li>
<li id="fn22"><p><a href="http://simonsfoundation.org/mathematics-physical-sciences/featured-articles/-/asset_publisher/bo1E/content/mathematicians-solve-45-year-old-kervaire-invariant-puzzle">‚ÄúMathematicians solve 45-year-old Kervaire invariant puzzle‚Äù</a>, Erica Klarreich 2009<a href="#fnref22">‚Ü©</a></p></li>
<li id="fn23"><p><a href="http://hans.math.upenn.edu/~kazdan/proof/notes/parallel-postulateGrabiner2009.pdf">‚ÄúWhy Did Lagrange ‚ÄòProve‚Äô the Parallel Postulate?‚Äù</a>, Grabiner 2009:</p>
<blockquote>
<p>It is true that Lagrange never did publish it, so he must have realized there was something wrong. In another version of the story, told by <a href="http://en.wikipedia.org/wiki/Jean-Baptiste%20Biot" title="Wikipedia: Jean-Baptiste Biot">Jean-Baptiste Biot</a>, who claims to have been there (though the minutes do not list his name), everybody there could see that something was wrong, so Lagrange‚Äôs talk was followed by a moment of complete silence [2, p.¬†84]. Still, Lagrange kept the manuscript with his papers for posterity to read.</p>
</blockquote>
<p>Why work on it at all?</p>
<blockquote>
<p>The historical focus on the fifth postulate came because it felt more like the kind of thing that gets proved. It is not self-evident, it requires a diagram even to explain, so it might have seemed more as though it should be a theorem. In any case, there is a tradition of attempted proofs throughout the Greek and then Islamic and then eighteenth-century mathematical worlds. Lagrange follows many eighteenth-century mathematicians in seeing the lack of a proof of the fifth postulate as a serious defect in <a href="http://en.wikipedia.org/wiki/Euclid%27s%20Elements" title="Wikipedia: Euclid's Elements">Euclid‚Äôs <em>Elements</em></a>. But Lagrange‚Äôs criticism of the postulate in his manuscript is unusual. He said that the assumptions of geometry should be demonstrable ‚Äújust by the <a href="http://en.wikipedia.org/wiki/principle%20of%20contradiction" title="Wikipedia: principle of contradiction">principle of contradiction</a>‚Äù-the same way, he said, that we know the axiom that the whole is greater than the part [32, p.¬†30R]. The theory of parallels rests on something that is not self-evident, he believed, and he wanted to do something about this.</p>
</blockquote>
<p>What was the strange and alien to the modern mind approach that Lagrange used?</p>
<blockquote>
<p>Recall that Lagrange said in this manuscript that axioms should follow from the principle of contradiction. But, he added, besides the principle of contradiction, ‚ÄúThere is another principle equally self-evident,‚Äù and that is Leibniz‚Äôs <a href="http://en.wikipedia.org/wiki/principle%20of%20sufficient%20reason" title="Wikipedia: principle of sufficient reason">principle of sufficient reason</a>. That is: nothing is true ‚Äúunless there is a sufficient reason why it should be so <em>and not otherwise</em>‚Äù [42, p.¬†31; italics added]. This, said Lagrange, gives as solid a basis for mathematical proof as does the principle of contradiction [32, p.¬†30V]. But is it legitimate to use the principle of sufficient reason in mathematics? Lagrange said that we are justified in doing this, because it has already been done. For example, Archimedes <a href="http://en.wikipedia.org/wiki/Mechanical%20advantage%23The%20law%20of%20the%20lever" title="Wikipedia: Mechanical advantage#The law of the lever">used it</a> to establish that equal weights at equal distances from the fulcrum of a lever balance. Lagrange added that we also use it to show that three equal forces acting on the same point along lines separated by a third of the circumference of a circle are in equilibrium [32, pp.¬†31R-31V]‚Ä¶The modern reader may object that Lagrange‚Äôs symmetry arguments are, like the uniqueness of parallels, equivalent to Euclid‚Äôs postulate. But the logical correctness, or lack thereof, of Lagrange‚Äôs proof is not the point. (In this manuscript, by the way, Lagrange went on to give an analogous proof-also by the principle of sufficient reason-that between two points there is just one straight line, because if there were a second straight line on one side of the first, we could then draw a third straight line on the other side, and so on [32, pp.¬†34R-34V]. Lagrange, then, clearly liked this sort of argument.)</p>
<p>‚Ä¶Why did philosophers conclude that space had to be infinite, homogeneous, and the same in all directions? Effectively, because of the principle of sufficient reason. For instance, <a href="http://en.wikipedia.org/wiki/Giordano%20Bruno" title="Wikipedia: Giordano Bruno">Giordano Bruno</a> in 1600 argued that the universe must be infinite because there is no reason to stop at any point; the existence of an infinity of worlds is no less reasonable than the existence of a finite number of them. Descartes used similar reasoning in his <em>Principles of Philosophy</em>: ‚ÄúWe recognize that this world. . . has no limits in its extension. . . . Wherever we imagine such limits, we . . . imagine beyond them some indefinitely extended space‚Äù [28, p.¬†104]. Similar arguments were used by other seventeenth-century authors, including Newton. Descartes identified space and the extension of matter, so geometry was, for him, about real physical space. But geometric space, for Descartes, had to be Euclidean‚Ä¶Descartes, some 50 years before Newton published his first law of motion, was a co-discoverer of what we call linear inertia: that in the absence of external influences a moving body goes in a straight line at a constant speed. Descartes called this the first law of nature, and for him, this law follows from what we now recognize as the principle of sufficient reason. Descartes said, ‚ÄúNor is there any reason to think that, if [a part of matter] moves. . . and is not impeded by anything, it should ever by itself cease to move with the same force‚Äù [30, p.¬†75]‚Ä¶.Leibniz, by contrast, did not believe in absolute space. He not only said that spatial relations were just the relations between bodies, he used the principle of sufficient reason to show this. If there were absolute space, there would have to be a reason to explain why two objects would be related in one way if East is in one direction and West in the opposite direction, and related in another way if East and West were reversed [24, p.¬†147]. Surely, said Leibniz, the relation between two objects is just one thing! But Leibniz did use arguments about symmetry and sufficient reason-sufficient reason was his principle, after all. Thus, although Descartes and Leibniz did not believe in empty absolute space and Newton did, they all agreed that what I am calling the Euclidean properties of space are essential to physics.</p>
<p>‚Ä¶In his 1748 essay <a href="http://eulerarchive.maa.org/docs/translations/E149tr.pdf">‚ÄúReflections on Space and Time‚Äù</a>, Euler argued that space must be real; it cannot be just the relations between bodies as the Leibnizians claim [10]. This is because of the principles of mechanics-that is, Newton‚Äôs first and second laws. These laws are beyond doubt, because of the ‚Äúmarvelous‚Äù agreement they have with the observed motions of bodies. The inertia of a single body, Euler said, cannot possibly depend on the behavior of other bodies. The conservation of uniform motion in the same direction makes sense, he said, only if measured with respect to immovable space, not to various other bodies. And space is not in our minds, said Euler; how can physics-real physics-depend on something in our minds?‚Ä¶in his <em><a href="http://en.wikipedia.org/wiki/Critique%20of%20Pure%20Reason" title="Wikipedia: Critique of Pure Reason">Critique of Pure Reason</a></em> of 1781, Kant placed space in the mind nonetheless. We order our perceptions in space, but space itself is in the mind, an intuition of the intellect. Nevertheless, Kant‚Äôs space turned out to be Euclidean too. Kant argued that we need the intuition of space to prove theorems in geometry. This is because it is in space that we make the constructions necessary to prove theorems. And what theorem did Kant use as an example? The sum of the angles of a triangle is equal to two right angles, a result whose proof requires the truth of the parallel postulate [26, ‚ÄúOf space,‚Äù p.¬†423]‚Ä¶.Lagrange himself is supposed to have said that spherical trigonometry does not need Euclid‚Äôs parallel postulate [4, pp.¬†52-53]. But the surface of a sphere, in the eighteenth-century view, is not non-Euclidean; it exists in 3-dimensional Euclidean space [20, p.¬†71]. The example of the sphere helps us see that the eighteenth-century discussion of the parallel postulate‚Äôs relationship to the other postulates is not really about what is logically possible, but about what is true of real space.</p>
</blockquote>
<p>The final step:</p>
<blockquote>
<p><a href="http://en.wikipedia.org/wiki/Johann%20Heinrich%20Lambert" title="Wikipedia: Johann Heinrich Lambert">Johann Heinrich Lambert</a> was one of the mathematicians who worked on the problem of Postulate 5. Lambert explicitly recognized that he had not been able to prove it, and considered that it might always have to remain a postulate. He even briefly suggested a possible geometry on a sphere with an imaginary radius. But Lambert also observed that the parallel postulate is related to the law of the lever [20, p.¬†75]. He said that a lever with weightless arms and with equal weights at equal distances is balanced by a force in the opposite direction at the center equal to the sum of the weights, and that all these forces are parallel. So either we are using the parallel postulate, or perhaps, Lambert thought, some day we could use this physical result to prove the parallel postulate‚Ä¶.These men did not want to do mechanics, as, say, Newton had done. They wanted to show not only that the world was this way, but that it necessarily had to be. A modern philosophical critic, Helmut Pulte, has said that Lagrange‚Äôs attempt to ‚Äúreduce‚Äù mechanics to analysis strikes us today as ‚Äúa misplaced endeavour to mathematize. . . an empirical science, and thus to endow it with infallibility‚Äù [39, p.¬†220]. Lagrange would have responded, ‚ÄúRight! That‚Äôs just exactly what we are all doing.‚Äù</p>
</blockquote>
<a href="#fnref23">‚Ü©</a></li>
<li id="fn24"><p><a href="http://rjlipton.wordpress.com/2012/09/29/why-we-lose-sleep-some-nights/" title="Why We Lose Sleep Some Nights">Supposing P=NP</a>:</p>
<blockquote>
<p>Much of CS theory would disappear. In my own research some of Ken‚Äôs and my ‚Äúbest‚Äù results would survive, but many would be destroyed. The Karp-Lipton Theorem is gone in this world. Ditto all ‚Äúdichotomy‚Äù results between P and NP-complete, and for P = #P, Jin-Yi‚Äôs similar work. Many barrier results, such as oracle theorems and natural proofs, lose their main motivation, while much fine structure in hardness-versus-randomness tradeoffs would be blown up. The PCP Theorem and all the related work is gone. Modern cryptography could survive if the algorithm were galactic, but otherwise would be in trouble. I am currently teaching Complexity Theory at Tech using the textbook by Sanjeev Arora and Boaz Barak‚Ä¶Most of the 573 pages of Arora-Barak would be gone:</p>
<ul>
<li>Delete all of chapter 3 on NP.</li>
<li>Delete all of chapter 5 on the polynomial hierarchy.</li>
<li>Delete most of chapter 6 on circuits.</li>
<li>Delete all of chapter 7 on probabilistic computation.</li>
<li>Mark as dangerous chapter 9 on cryptography.</li>
<li>Delete most of chapter 10 on quantum computation - who would care about Shor‚Äôs algorithm then?</li>
<li>Delete all of chapter 11 on the PCP theorem.</li>
</ul>
<p>I will stop here. Most of the initial part of the book is gone. The same for much of Homer-Selman, and basically all of the ‚ÄúReducibility and Completeness‚Äù CRC chapter.</p>
</blockquote>
<a href="#fnref24">‚Ü©</a></li>
</ol>
</section>
</div>
</div>
<div id="footer">
<p>Still bored? Then try my <a href="https://plus.google.com/103530621949492999968/posts" title="Google+ posts">Google+ news feed</a>.</p>
<a href="https://docs.google.com/spreadsheet/viewform?formkey=dE5GLWpfX3RhX1c2Q1phcEo3U3VDVEE6MQ">Send anonymous feedback</a>
<br/>
<div id="license">
<p xmlns:dct="http://purl.org/dc/terms/" xmlns:vcard="http://www.w3.org/2001/vcard-rdf/3.0#">
<a rel="license" href="http://creativecommons.org/publicdomain/zero/1.0/">
<img src="http://i.creativecommons.org/p/zero/1.0/88x31.png" style="border-style: none;" alt="CC0" height="31" width="88"/>
</a>
</p>
</div>
</div>
 
<script type="text/javascript" src="//ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js"></script>
 
<script type="text/javascript" src="./static/js/footnotes.js"></script>
 
<script type="text/javascript" src="./static/js/abalytics.js"></script>
<script type="text/javascript">
      window.onload = function() {
      ABalytics.applyHtml();
      };
    </script>
 
<script id="googleAnalytics" type="text/javascript">
      var _gaq = _gaq || [];
      _gaq.push(['_setAccount', 'UA-18912926-1']);

      ABalytics.init({
      indent: [
      {
      name: "none",
      "indent_class1": "<style>p + p { text-indent: 0.0em; margin-top: 0 }</style>"
      },
      {
      name: "indent0.1",
      "indent_class1": "<style>p + p { text-indent: 0.1em; margin-top: 0 }</style>"
      },
      {
      name: "indent0.5",
      "indent_class1": "<style>p + p { text-indent: 0.5em; margin-top: 0 }</style>"
      },
      {
      name: "indent1.0",
      "indent_class1": "<style>p + p { text-indent: 1.0em; margin-top: 0 }</style>"
      },
      {
      name: "indent1.5",
      "indent_class1": "<style>p + p { text-indent: 1.5em; margin-top: 0 }</style>"
      },
      {
      name: "indent2.0",
      "indent_class1": "<style>p + p { text-indent: 2.0em; margin-top: 0 }</style>"
      }
      ],
      }, _gaq);

      _gaq.push(['_trackPageview']);
      (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
      })();
    </script>
 
<script id="outboundLinkTracking" type="text/javascript">
      $(function() {
      $("a").on('click',function(e){
      var url = $(this).attr("href");
      if (e.currentTarget.host != window.location.host) {
      _gat._getTrackerByName()._trackEvent("Outbound Links", e.currentTarget.host.replace(':80',''), url, 0);
      if (e.metaKey || e.ctrlKey || (e.button == 1)) {
      var newtab = true;
      }
      if (!newtab) {
      e.preventDefault();
      setTimeout('document.location = "' + url + '"', 100);
      }
      }
      });
      });
    </script>
 
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
 
<script type="text/javascript" src="./static/js/footnotes.js"></script>
 
<script type="text/javascript" src="./static/js/tablesorter.js"></script>
<script type="text/javascript" id="tablesorter">
      $(document).ready(function() {
      $("table").tablesorter();
      }); </script>
 
<div id="disqus_thread"></div>
<script type="text/javascript">
      if (document.title != 'Essays') { <!-- avoid Disqus comments on front page -->
      (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://disqus.com/forums/gwern/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
      })();
      var disqus_shortname = 'gwern';
      (function () {
      var s = document.createElement('script'); s.async = true;
      s.src = 'http://disqus.com/forums/gwern/count.js';
      (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
      }());
      }</script>
<noscript><p>Enable JavaScript for Disqus comments</p></noscript>
</body>
</html>

