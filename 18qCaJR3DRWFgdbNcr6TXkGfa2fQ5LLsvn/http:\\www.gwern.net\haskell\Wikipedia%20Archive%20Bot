http://www.gwern.net/haskell/Wikipedia%20Archive%20Bot
HTTP/1.1 200 OK
Server: cloudflare-nginx
Date: Thu, 24 Jul 2014 04:13:39 GMT
Content-Type: text/html; charset=utf-8
Connection: close
Set-Cookie: __cfduid=dc66120b3d0ba194aa43594b778442a461406175219524; expires=Mon, 23-Dec-2019 23:50:00 GMT; path=/; domain=.gwern.net; HttpOnly
x-amz-id-2: UI7o9te1B3nljysY3cTuZZs0VXTF9K+Q7CdlvoKDddZSIvF4hGZD06wY6ZavHbcY
x-amz-request-id: 13D999D84857D4D4
x-amz-meta-s3cmd-attrs: uid:1000/gname:gwern/uname:gwern/gid:1000/mode:33152/mtime:1405189116/atime:1405189114/ctime:1405189116
Cache-Control: max-age=604800, public
Last-Modified: Sat, 12 Jul 2014 18:50:30 GMT
CF-RAY: 14ed49520d2c0097-IAD
Content-Encoding: gzip

<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8"/>
<meta name="generator" content="hakyll"/>
<meta name="google-site-verification" content="BOhOQI1uMfsqu_DopVApovk1mJD5ZBLfan0s9go3phk"/>
<meta name="author" content="gwern"/>
<meta name="description" content="Haskell: archive Wikipedia with TagSoup and WebCite"/>
<meta name="dc.date.issued" content="26 Sep 2008"/>
<meta name="dcterms.modified" content="06 Sep 2013"/>
<title>Wikipedia Archive Bot</title>
<link rel="stylesheet" type="text/css" href="../static/css/default.css"/>
<link href="../atom.xml" type="application/atom+xml" rel="alternate" title="Sitewide ATOM/RSS Feed"/>
<link rel="shortcut icon" type="image/x-icon" href="../static/img/favicon.ico"/>
</head>
<body>
 
<div class="indent_class1"></div>
<div id="main">
<div id="sidebar">
<div id="logo"><img alt="Logo: a Gothic/Fraktur blackletter capital G/ùï≤" height="36" src="../images/logo.png" width="32"/></div>
<div id="sidebar-links">
<p>
<a href="../index" title="index: categorized list of articles">Home</a>
<a href="../About" title="Site ideals, source, content, traffic, examples, license">Site</a>
<a href="../Links" title="Who am I online, what have I done, what am I like? Contact information; sites I use; things I've worked on">Me</a>
</p>
<hr/>
<div id="sidebar-news">
<p>
<a href="../Changelog" title="What's new or updated">New:</a>
<a href="../atom.xml" type="application/atom+xml" rel="alternate" title="Sitewide ATOM/RSS Feed">RSS</a>
<a href="http://eepurl.com/Kc155" title="Monthly mailing list: signup form">MAIL</a>
</p>
<hr/>
</div>
<div id="cse-sitesearch">
<script>
            (function() {
            var cx = '009114923999563836576:dv0a4ndtmly';
            var gcse = document.createElement('script'); gcse.type = 'text/javascript'; gcse.async = true;
            gcse.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//www.google.com/cse/cse.js?cx=' + cx;
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(gcse, s);
            })();
          </script>
<div style="width:0px;overflow:hidden;height:0px;">
<gcse:search></gcse:search>
</div>
<form id="searchbox_009114923999563836576:dv0a4ndtmly">
<input value="009114923999563836576:dv0a4ndtmly" name="cx" type="hidden"/>
<input value="FORID:11" name="cof" type="hidden"/>
<input id="q" style name="q" size="5" type="text" placeholder="search"/>
</form>
</div>
</div>
<hr/>
<div id="metadata">
<div id="abstract"><em>Haskell: archive Wikipedia with TagSoup and WebCite</em></div>
<br/>
<div id="tags"><i></i></div>
<br/>
<div id="page-created">created:
<br/>
<i>26 Sep 2008</i></div>
<div id="last-modified">modified:
<br/>
<i>06 Sep 2013</i></div>
<br/>
<div id="version">status:
<br/>
<i>finished</i></div>
<br/>
<div id="epistemological-status"><a href="../About#belief-tags" title="Explanation of 'belief' metadata">belief:</a>
<br/>
<i>likely</i>
</div>
<hr/>
</div>
<div id="donations">
<div id="bitcoin-donation-address">
<a href="http://en.wikipedia.org/wiki/Bitcoin">‡∏ø</a>: 18qCaJR3DRWFgdbNcr6TXkGfa2fQ5LLsvn
</div>
<div id="paypal">
<form style="display: inline" action="https://www.paypal.com/cgi-bin/webscr" method="post" onClick="_gaq.push(['_trackEvent', 'Click', 'PayPalClicked', '']);">
<div class="form-type">
<input type="hidden" name="cmd" value="_s-xclick"/>
<input type="hidden" name="hosted_button_id" value="8GSLCWGCC6AF8"/>
<input type="image" src="http://www.paypalobjects.com/en_US/i/btn/btn_donate_SM.gif" name="submit" alt="Help support my writings!"/>
</div>
</form>
</div>
<div id="Gittip">
<script data-gittip-username="gwern" data-gittip-widget="button" src="//gttp.co/v1.js"></script>
</div>
</div>
</div>
 
<div id="adsense">
<a href="http://41j.com/ads/ad.html"><img alt="Advertisement for 'HTerm, The Graphical Terminal'" src="http://41j.com/ads/ad.png" height="90" width="728"></a>
</div>
<div id="header">
<h1>Wikipedia Archive Bot</h1>
</div>
<div id="content">
<div id="TOC"><ul>
<li><a href="#archiving">Archiving</a><ul>
<li><a href="#how-to">How to?</a></li>
<li><a href="#the-steps">The steps</a><ul>
<li><a href="#article-names">Article names</a></li>
<li><a href="#article-contents">Article contents</a></li>
<li><a href="#parsing-html">Parsing HTML</a></li>
<li><a href="#archiving-urls">Archiving URLs</a></li>
<li><a href="#duplicate-urls">Duplicate URLs</a></li>
<li><a href="#prototype">Prototype</a></li>
<li><a href="#performance">Performance</a></li>
<li><a href="#parallelizing-requests">Parallelizing requests</a></li>
<li><a href="#laziness">Laziness</a></li>
<li><a href="#frugal-removal">Frugal removal</a></li>
</ul></li>
</ul></li>
<li><a href="#see-also">See also</a></li>
</ul></div>
<p>One of the best ways to learn something like <a href="http://en.wikipedia.org/wiki/Haskell%20%28programming%20language%29" title="Wikipedia: Haskell (programming language)">Haskell</a> is to simply dive in and make it do something useful. In my case, I‚Äôve wanted to learn Haskell for a long time: the syntax was gorgeous compared to <a href="http://en.wikipedia.org/wiki/Common%20Lisp" title="Wikipedia: Common Lisp">Common Lisp</a>, <a href="http://en.wikipedia.org/wiki/Bash" title="Wikipedia: Bash">Bash</a>, or Java (the only other languages I had experience with); various ideas such as <a href="http://en.wikipedia.org/wiki/Monad%20%28functional%20programming%29" title="Wikipedia: Monad (functional programming)">monads</a>, <a href="http://en.wikipedia.org/wiki/lazy%20evaluation" title="Wikipedia: lazy evaluation">lazy evaluation</a>, and <a href="http://en.wikipedia.org/wiki/functional%20purity" title="Wikipedia: functional purity">functional purity</a> struck me as fascinating and exciting; and the community was excellent.</p>
<p>But I didn‚Äôt have any practical use for it, and I‚Äôm too lazy to learn it unless I have to. Bash worked well enough for my shell scripts, and I generally only messed with Common Lisp because of my use of the <a href="http://en.wikipedia.org/wiki/StumpWM" title="Wikipedia: StumpWM">Stump window manager</a>, but I had finished configuring and extending StumpWM to my liking<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>. Fortunately, I am a heavy user and long-time editor of Wikipedia, and some technical details bug me.</p>
<p>2 in particular struck me as fixable without requiring modifications to the MediaWiki codebase (a messy yet featureful pile of PHP):</p>
<ol type="1">
<li>the ‚Äúfeature‚Äù of MediaWiki that by default, <code>Fujiwara no Teika</code> is a pagename distinct from <code>Fujiwara no teika</code>. Going to the latter does not automatically redirect to the former. One must either create redirects to the right pagename<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a> , or simply accept that mis-capitalizations will result in broken links and needless searches.</li>
<li>Links to other non-Wikipedia websites, ‚Äúexternal links‚Äù, often break. Because articles can evolve so fast, the <a href="http://en.wikipedia.org/wiki/Internet%20Archive" title="Wikipedia: Internet Archive">Internet Archive</a> doesn‚Äôt necessarily manage to archive all external links; worse, the Internet Archive is dependent for its data on data dumps from <a href="http://en.wikipedia.org/wiki/Alexa" title="Wikipedia: Alexa">Alexa</a> &amp; its <a href="http://en.wikipedia.org/wiki/Alexa%20Toolbar" title="Wikipedia: Alexa Toolbar">toolbar</a>, which are provided an eternity (6 months or more) after the original spidering of the external link. An external link could be added to an article, used as a reference, fall victim to the infamous 404 error, be noticed to be a dead link and removed on that basis within a few weeks much less 9 months!</li>
</ol>
<section id="archiving" class="level1">
<h1>Archiving</h1>
<section id="how-to" class="level2">
<h2>How to?</h2>
<p>Let‚Äôs talk about Problem 2.</p>
<p>The beginning of a solution is to realize that the Internet Archive is not usable here. Their <a href="http://www.archive.org/about/faqs.php#1">FAQ</a> specifically says that archiving is done only through Alexa, and Alexa only does it through their spiders, the Alexa toolbar (proprietary and MS Windows/IE-only), and some web form which doesn‚Äôt appear to do anything<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a>. Their <a href="http://www.archive-it.org/">Archive-It</a> service does do on-demand archiving, but at steep institution-targeted fees; not something for individual users.</p>
<p>Fortunately, if we poke around on the subject of archiving URLs, we‚Äôll eventually discover something like <a href="http://en.wikipedia.org/wiki/WebCite" title="Wikipedia: WebCite">WebCite</a>, which is tailor-made for our purposes. They offer persistent archiving services, for free, and best of all they can archive on demand!</p>
<p>Reading through their documentation, it seems they will eventually allow you to upload a file containing a large number of URLs to cite, but not yet. That‚Äôs alright - just trying out the archiving (or reading the <a href="http://www.webcitation.org/doc/WebCiteBestPracticesGuide.pdf">technical FAQ</a>) reveals the submission URL encodes everything in a very simple format:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="st">&quot;http://www.webcitation.org/archive?url=&quot;</span> <span class="fu">++</span> url <span class="fu">++</span> <span class="st">&quot;&amp;email=<a class="__cf_email__" href="http://www.cloudflare.com/email-protection" data-cfemail="71171e1e311310035f121e1c">[email&nbsp;protected]</a><script type="text/javascript">
/* <![CDATA[ */
(function(){try{var s,a,i,j,r,c,l,b=document.getElementsByTagName("script");l=b[b.length-1].previousSibling;a=l.getAttribute('data-cfemail');if(a){s='';r=parseInt(a.substr(0,2),16);for(j=2;a.length-j;j+=2){c=parseInt(a.substr(j,2),16)^r;s+=String.fromCharCode(c);}s=document.createTextNode(s);l.parentNode.replaceChild(s,l);}}catch(e){}})();
/* ]]> */
</script>&quot;</span></code></pre>
</section>
<section id="the-steps" class="level2">
<h2>The steps</h2>
<p>So going back to our problem. Our problem is that we want to take all the articles of the English Wikipedia, somehow extract all the external links from said articles, transform those URLs according to the previous paragraph, and then actually open them (which will cause the embedded URL to be archived).</p>
<section id="article-names" class="level3">
<h3>Article names</h3>
<p>Our first question is naturally ‚ÄúHow on Earth do we even get the addresses of the millions of Wikipedia articles? Saying they‚Äôre all ‚Äòsomewhere in <code>en.wikipedia.org/wiki/</code>‚Äô doesn‚Äôt help.‚Äù I‚Äôm going to cop out a bit here and not actually explain how I hit upon this approach, but we‚Äôll borrow some code from the bot I coded to fix Problem 1, which looks a little like this:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell">main <span class="fu">=</span> <span class="kw">do</span>
    cd <span class="st">&quot;/home/gwern/bin/pywikipedia/&quot;</span>
    <span class="co">{- The list comprehension is to prevent from operating on page titles which will</span>
<span class="co">    cause enormous numbers of redirects to be created. It's what comes before that matters. -}</span>
    list <span class="ot">&lt;-</span> liftM (\bs <span class="ot">-&gt;</span> [n <span class="fu">|</span> n<span class="ot">&lt;-</span>bs,  length n <span class="fu">&lt;=</span> (<span class="dv">2</span><span class="fu">^</span><span class="dv">4</span>)]) <span class="fu">$</span> liftM words <span class="fu">$</span> getContents</code></pre>
<p><a href="Redirect%2Dbot%2Ehs" title="Go to wiki page: Redirect%2Dbot%2Ehs">Redirect-bot.hs</a> is assuming here that stdin is the source of a list. This long (&gt;9,555,933 lines) list takes this form:</p>
<pre><code>...
Delehaye
Delekovac
Delele
Delemont
Delemont_(Jura)
Delemont_JU
Delena
Delena_cancerides
Delenda
Deleni
...</code></pre>
<p>Notice that spaces are being escaped as underscores, and that each page name is on a separate line. We are getting all this information from a special file kindly provided by Wikipedia precisely for people like us, who don‚Äôt want to spend the effort to parse <a href="http://en.wikipedia.org/wiki/Special%3AAllpages" title="Wikipedia: Special:Allpages">Special:Allpages</a> to get the live list of article names; parsing Allpages is how all the serious Wikipedia bots work, but relying on old database dumps gets us 90% of the functionality at 10% the effort. Go visit <a href="http://download.wikimedia.org/enwiki/latest/">http://download.wikimedia.org/enwiki/latest/</a> and look for a file called <code>all_titles_in_ns0.gz</code>. When it‚Äôs downloaded and uncompressed to a ~60M file, it provides suitable fodder.</p>
<p>So, we have getContents lazily slurping in names of articles to standard in, and we have <a href="http://www.haskell.org/hoogle/?hoogle=words" title="Hoogle: words">words</a> (it‚Äôs a pure non-IO function, but <a href="http://www.haskell.org/hoogle/?hoogle=liftM" title="Hoogle: liftM">liftM</a> lets us use it in the IO monad) breaking a single long string with lots of newlines into a list of strings.</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">import </span><span class="dt">Control.Monad</span> (liftM) <span class="co">-- Don't forget your imports!</span>

<span class="ot">main ::</span> <span class="dt">IO</span> ()
main <span class="fu">=</span> <span class="kw">do</span>
         articlelist <span class="ot">&lt;-</span> liftM words <span class="fu">$</span> getContents</code></pre>
</section>
<section id="article-contents" class="level3">
<h3>Article contents</h3>
<p>Now what? Well, a list of items each of which we want to perform the exact same operation on almost cries out for us to use a (monadic) <code>map</code> on it.</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell">         urllist <span class="ot">&lt;-</span> mapM fetchArticleURLs articlelist</code></pre>
<p>But what <em>is</em> this mystery function <code>fetchArticleText</code>? Well, obviously it will take as its single argument a String, and equally obviously it will return a list of Strings since any given article might have many different external links in it. And since we certainly aren‚Äôt loading into memory an immutable copy of Wikipedia (regardless of whether we download a full dump of the articles or decide to fetch articles over the Internet), the result will be promoted into the IO monad. So the type signature must be:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">fetchArticleURLs ::</span> <span class="dt">String</span> <span class="ot">-&gt;</span> <span class="dt">IO</span> [<span class="dt">String</span>]</code></pre>
<p>Purely arbitrarily, we‚Äôll have <code>fetchArticleURLs</code> work on pages from the live English Wikipedia; but you could probably also go the route of working from an offline database dump, which would have the advantage of halving network requests and parsing out URLs much faster (since there‚Äôd be no need to request individual pages over the network).</p>
</section>
<section id="parsing-html" class="level3">
<h3>Parsing HTML</h3>
<p>It‚Äôs not too hard to see how to get the URL for any given article (<code>&quot;http://en.wikipedia.org/wiki/&quot;++article</code>), nor how to use <a href="http://www.haskell.org/hoogle/?hoogle=Network.HTTP" title="Hoogle: Network.HTTP">Network.HTTP</a> to download the HTML file (couldn‚Äôt be more than 10 lines) - but reliably parsing that HTML to extract genuine external links doesn‚Äôt seem trivial at all! We could go with some sort of clumsy regexp matching on ‚Äúhttp://‚Äù, but hit-or-miss regular expressions just aren‚Äôt The Haskell Way.</p>
<p>Stumped, the thing to do is to go bum around on the <a href="http://www.haskell.org/haskellwiki/Haskell">Haskell wiki</a> and #haskell, where some excellent fellow will eventually inform us that ‚ÄúHey, you know, parsing Wikipedia pages‚Äô HTML to extract out all external links kind of reminds me of one of the examples for Neil Mitchell‚Äôs <a href="http://hackage.haskell.org/package/tagsoup" title="Hackage: tagsoup"><code>tagsoup</code></a> library. You should go check it out.‚Äù</p>
<p>Indeed, we need some sort of library to parse HTML for us and maybe handle the network business, and <a href="http://www-users.cs.york.ac.uk/~ndm/tagsoup/">TagSoup</a> fits the bill admirably. One of the examples in Example.hs (<code>googleTechNews</code>) does almost precisely what we want, except for Google Tech News. The example in its entirety:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell">googleTechNews <span class="fu">=</span> <span class="kw">do</span>
       tags <span class="ot">&lt;-</span> liftM parseTags <span class="fu">$</span> openURL <span class="st">&quot;http://news.google.com/?ned=us&amp;topic=t&quot;</span>
       <span class="kw">let</span> links <span class="fu">=</span> mapMaybe extract <span class="fu">$</span> sections match tags
       putStr <span class="fu">$</span> unlines links
   <span class="kw">where</span> extract xs <span class="fu">=</span> maybeTagText (xs <span class="fu">!!</span> <span class="dv">2</span>)
         match <span class="fu">=</span>
             Match.tagOpenAttrNameLit <span class="st">&quot;a&quot;</span> <span class="st">&quot;id&quot;</span>
              (\value <span class="ot">-&gt;</span> <span class="st">&quot;r&quot;</span> <span class="ot">`isPrefixOf`</span> value <span class="fu">&amp;&amp;</span> <span class="ch">'i'</span> <span class="ot">`notElem`</span> value)</code></pre>
<p>Reading this, one is struck by <code>openURL</code>; we don‚Äôt even need to read the documentation to know what it does. We already have the beginning of our <code>fetchArticleURLs</code> definition:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">import </span><span class="dt">Text.HTML.Download</span> (openURL)

<span class="ot">fetchArticleURLs ::</span> <span class="dt">String</span> <span class="ot">-&gt;</span> <span class="dt">IO</span> [<span class="dt">String</span>]
fetchArticleURLs article <span class="fu">=</span> undefined <span class="fu">$</span> openURL(<span class="st">&quot;http://en.wikipedia.org/wiki/&quot;</span><span class="fu">++</span>article)</code></pre>
<p>We could replace <code>undefined</code> with whatever parsing we cook up, but we might want to use it somewhere else, and besides, it‚Äôs bad practice to muddy up a function that could be pure (like our hypothetical <code>extractURLs</code> function) with IO. <a href="http://en.wikipedia.org/wiki/Separation%20of%20concerns" title="Wikipedia: Separation of concerns">Separation of concerns</a>, and all that.</p>
<p>So we‚Äôre up to this:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell">fetchArticleURLs article <span class="fu">=</span> liftM extractURLs <span class="fu">$</span> openURL(<span class="st">&quot;http://en.wikipedia.org/wiki/&quot;</span><span class="fu">++</span>article)
<span class="ot">extractURLs ::</span> <span class="dt">String</span> <span class="ot">-&gt;</span> [<span class="dt">String</span>]
extractURLs arg <span class="fu">=</span> undefined</code></pre>
<p>The definition of <code>extractURLs</code> is a bit magical, since we don‚Äôt immediately understand the entire hierarchy of types and constructors which TagSoup operate ons:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">import </span><span class="dt">Text.HTML.TagSoup</span> (parseTags, <span class="dt">Tag</span>(<span class="dt">TagOpen</span>))
<span class="kw">import </span><span class="dt">Data.List</span> (isPrefixOf)

<span class="ot">extractURLs ::</span> <span class="dt">String</span> <span class="ot">-&gt;</span> [<span class="dt">String</span>]
extractURLs arg <span class="fu">=</span> [x <span class="fu">|</span> <span class="dt">TagOpen</span> <span class="st">&quot;a&quot;</span> atts <span class="ot">&lt;-</span> (parseTags arg),
                       (_,x) <span class="ot">&lt;-</span> atts,
                       <span class="st">&quot;http://&quot;</span> <span class="ot">`isPrefixOf`</span> x]</code></pre>
<p>Alright. This <a href="http://en.wikipedia.org/wiki/list%20comprehension" title="Wikipedia: list comprehension">list comprehension</a> has 3 parts, which we will read from top down. We start with our <code>arg</code>, a String. It immediately passes to <a href="http://hackage.haskell.org/packages/archive/tagsoup/0.6/doc/html/Text-HTML-TagSoup-Parser.html#v:parseTags">parseTags</a>, which turns it into [Tag] - notice it‚Äôs not a tree or hierarchical structure like our String actually represents; this is why it‚Äôs ‚Äòsoup‚Äô.</p>
<p>A <code>Tag</code> can be <a href="http://hackage.haskell.org/packages/archive/tagsoup/0.6/doc/html/Text-HTML-TagSoup-Parser.html#v%3AparseTags">a lot of things</a>, but we quickly realize we only want <code>TagOpen</code>.<a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a> The <code>&quot;a&quot;</code> is there because <code>&lt;href&gt;</code> actually begins with <code>&lt;a href=...&gt;</code>.</p>
<p>But how does <code>TagOpen &quot;a&quot; atts</code> do anything? We can think of a list comprehension as syntax sugar over a bunch of <a href="http://www.haskell.org/hoogle/?hoogle=filter" title="Hoogle: filter">filter</a>s and whatnot. In this case, what‚Äôs really happening is something like <code>filter (\TagOpen &quot;a&quot; x -&gt; x) (parseTags arg)</code>; any entry which isn‚Äôt a <code>TagOpen</code> is omitted from the intermediate list.</p>
<p>The second line is exactly the same. We‚Äôre still working on a <code>[Tag]</code>, and our little <code>filter</code> is still testing away, but now our ‚Äòtest‚Äô is really just pulling out the second entry in each <code>TagOpen</code>‚Äôs <code>[Attribute]</code> - it‚Äôs equivalent to a <code>map</code> of <a href="http://www.haskell.org/hoogle/?hoogle=snd" title="Hoogle: snd">snd</a>. And this gives us a <code>[String]</code> of URLs! The first entry in the lists are ‚Äúhref‚Äù, and the second are the URLs the href points to. But when we test out our two-liner, we realize to our dismay we are getting junk results like <code>[&quot;/wiki/Japanese_poetry&quot;,..]</code>. A quick <a href="http://www.haskell.org/hoogle/?hoogle=isPrefixOf" title="Hoogle: isPrefixOf">isPrefixOf</a> and we fix that, and that finishes our list comprehension.</p>
</section>
<section id="archiving-urls" class="level3">
<h3>Archiving URLs</h3>
<section id="archiving-in-webcite" class="level4">
<h4>Archiving in WebCite</h4>
<p>Oy. So we wrote <code>extractURLs</code>, which was used in <code>fetchArticleURLs</code>, which was used in <code>main</code>. Let‚Äôs backtrack a bit; we had left <code>main</code> at:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell">main <span class="fu">=</span> <span class="kw">do</span>
         articlelist <span class="ot">&lt;-</span> liftM words <span class="fu">$</span> getContents
         urllist <span class="ot">&lt;-</span> mapM fetchArticleURLs articlelist</code></pre>
<p>By the time <code>urllist</code> is generated, we‚Äôve got an <code>IO [String]</code> which is containing all the external links. Now we can once again indulge the desire to map some sort of function over it. Another map, another hypothetical function:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell">         mapM archiveURL urllist</code></pre>
<p>For convenience‚Äôs sake, we‚Äôll reuse <code>openURL</code> even though we don‚Äôt want output, we really want something like this:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">archiveURL ::</span> <span class="dt">String</span> <span class="ot">-&gt;</span> <span class="dt">IO</span> ()</code></pre>
<p>The simplest way to define it is this:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">archiveURL ::</span> <span class="dt">String</span> <span class="ot">-&gt;</span> <span class="dt">IO</span> <span class="dt">String</span> <span class="co">-- Reality</span>
archiveURL url <span class="fu">=</span> openURL(<span class="st">&quot;http://www.webcitation.org/archive?url=&quot;</span> <span class="fu">++</span> url <span class="fu">++</span> <span class="st">&quot;&amp;email=<a class="__cf_email__" href="http://www.cloudflare.com/email-protection" data-cfemail="50363f3f103231227e333f3d">[email&nbsp;protected]</a><script type="text/javascript">
/* <![CDATA[ */
(function(){try{var s,a,i,j,r,c,l,b=document.getElementsByTagName("script");l=b[b.length-1].previousSibling;a=l.getAttribute('data-cfemail');if(a){s='';r=parseInt(a.substr(0,2),16);for(j=2;a.length-j;j+=2){c=parseInt(a.substr(j,2),16)^r;s+=String.fromCharCode(c);}s=document.createTextNode(s);l.parentNode.replaceChild(s,l);}}catch(e){}})();
/* ]]> */
</script>&quot;</span>)</code></pre>
<p>But we can improve on this! We are using <a href="http://www.haskell.org/hoogle/?hoogle=mapM" title="Hoogle: mapM">mapM</a> which will go to all the trouble of retaining all the output from <code>archiveURL</code> being run on the dozens, hundreds, thousands, or millions of entries in <code>urllist</code>.</p>
<p>Can‚Äôt we be more efficient somehow? This sort of situation is exactly where naming conventions can come in handy. I happen to remember that just as <code>foo'</code> denotes some stricter version of a function <code>foo</code>, a <code>foo_</code> denotes some sort of function that will throw away its output. One blindly tries <a href="http://www.haskell.org/hoogle/?hoogle=mapM_" title="Hoogle: mapM_">mapM_</a> instead, and it works!</p>
<p>We could have been more consistent. We know that <code>mapM :: (a -&gt; m b) -&gt; [a] -&gt; m [b]</code>, and we want to get rid of the output, or turn the <code>[b]</code> into nothing, not even a list, which means <code>()</code>; we throw the new <a href="http://en.wikipedia.org/wiki/type%20signature" title="Wikipedia: type signature">type signature</a> into <a href="http://www.haskell.org/hoogle/?hoogle=%28a%20-%3E%20m%20b%29%20-%3E%20%5Ba%5D%20-%3E%20m%20%28%29" title="Hoogle: (a -&gt; m b) -&gt; [a] -&gt; m ()">Hoogle</a>, and the very first result is <code>mapM_</code>.</p>
</section>
<section id="archiving-in-alexa" class="level4">
<h4>Archiving in Alexa</h4>
<p>We <em>could</em> also throw in a speculative request to Alexa, which handles archiving for the Internet Archive. Supposedly any URL visited by someone using their toolbar will be spidered and then the spidered copy given to the Internet Archive. We can mimic the request of the toolbar. It turns out to be not that difficult to do, not nearly as difficult as Alexa could have made it. (Ironically, my first attempt was based on trying to read the JavaScript source code to the Alexa toolbar, which I followed in detail - and the moment I checked an actual request URL, I realized I had gotten it completely wrong.) This code, for brevity‚Äôs sake, will not be in the final WP archive bot code, but it is included in the general-purpose <a href="http://hackage.haskell.org/package/archiver"><code>archiver</code></a> daemon which will archive any URLs in a file in multiple ways and can be seen as the generalized version of this WP archive bot.</p>
<p>With the handy Firefox extension <a href="https://addons.mozilla.org/en-US/firefox/addon/live-http-headers/">Live HTTP Headers</a>, we can easily snoop on the toolbar‚Äôs traffic. I turned it on, visited a few domains with short names, saved the traffic to a file, and grepped for ‚Äòalexa.com‚Äô and ‚Äòhttp://‚Äô:</p>
<pre><code>http://data.alexa.com/data/SbADd155Tq0000?cli=10&amp;ver=spkyf-1.5.0&amp;dat=ns
    &amp;cdt=rq%3D0%26wid%3D7005&amp;ref=&amp;url=http%3A%2F%2Fwww.cnn.com%2F
http://widgets.alexa.com/traffic/sparky/?v=1&amp;url=cnn.com
http://data.alexa.com/data/SbADd155Tq0000?cli=10&amp;ver=spkyf-1.5.0&amp;dat=ns
    &amp;cdt=rq%3D1%26wid%3D7005%26ttl%3D1400&amp;ref=&amp;url=http%3A%2F%2Fwww.iana.org%2Fdomains%2Fexample%2F
http://widgets.alexa.com/traffic/sparky/?v=1&amp;url=iana.org
http://data.alexa.com/data/SbADd155Tq0000?cli=10&amp;ver=spkyf-1.5.0&amp;dat=ns
    &amp;cdt=rq%3D2%26wid%3D7005%26ttl%3D989&amp;ref=&amp;url=http%3A%2F%2Fwebcitation.org%2F
http://widgets.alexa.com/traffic/sparky/?v=1&amp;url=webcitation.org
http://widgets.alexa.com/traffic/rankr/?ref=http%3A%2F%2Fwebcitation.org%2F
http://data.alexa.com/data/SbADd155Tq0000?cli=10&amp;ver=spkyf-1.5.0&amp;dat=ns
    &amp;cdt=rq%3D3%26wid%3D7005%26ttl%3D2241&amp;ref=&amp;url=http%3A%2F%2Fwww.archive.org%2Findex.php
http://widgets.alexa.com/traffic/sparky/?v=1&amp;url=archive.org</code></pre>
<p>We can rule out <code>widgets.alexa.com</code> - the URL structure and the name indicates that these requests are being made by the part of the toolbar that is showing the little traffic-vs-time graph in the Firefox GUI. So:</p>
<pre><code>http://data.alexa.com/data/SbADd155Tq0000?cli=10&amp;ver=spkyf-1.5.0&amp;dat=ns&amp;cdt=rq%3D0%26 /
    wid%3D7005&amp;ref=&amp;url=http%3A%2F%2Fwww.cnn.com%2F
http://data.alexa.com/data/SbADd155Tq0000?cli=10&amp;ver=spkyf-1.5.0&amp;dat=ns&amp;cdt=rq%3D1%26 /
    wid%3D7005%26ttl%3D1400&amp;ref=&amp;url=http%3A%2F%2Fwww.iana.org%2Fdomains%2Fexample%2F
http://data.alexa.com/data/SbADd155Tq0000?cli=10&amp;ver=spkyf-1.5.0&amp;dat=ns&amp;cdt=rq%3D2%26 /
    wid%3D7005%26ttl%3D989&amp;ref=&amp;url=http%3A%2F%2Fwebcitation.org%2F
http://data.alexa.com/data/SbADd155Tq0000?cli=10&amp;ver=spkyf-1.5.0&amp;dat=ns&amp;cdt=rq%3D3%26 /
    wid%3D7005%26ttl%3D2241&amp;ref=&amp;url=http%3A%2F%2Fwww.archive.org%2Findex.php</code></pre>
<p>To split the last URL:</p>
<ol type="1">
<li><code>http://data.alexa.com/data/SbADd155Tq0000</code></li>
<li><code>?cli=10</code></li>
<li><code>&amp;ver=spkyf-1.5.0</code></li>
<li><code>&amp;dat=ns</code></li>
<li><code>&amp;cdt=rq%3D2%26wid%3D7005%26ttl%3D989</code></li>
<li><code>&amp;ref=</code></li>
<li><code>&amp;url=http%3A%2F%2Fwebcitation.org%2F</code> (the <a href="http://en.wikipedia.org/wiki/Percent-encoding" title="Wikipedia: Percent-encoding">URL-encoding</a> form of <code>http://webcitation.org/</code>)</li>
</ol>
<p>We can obviously hardwire #1 &amp; #3; I am guessing that we can hardwire #2 and #4; #6 can be left empty since none of the examples used it; #7 is just the payload; but unfortunately, #5 seems a little more difficult. We have 4 examples here for the <code>cdt</code> field:</p>
<pre><code>rq%3D0%26wid%3D7005
rq%3D1%26wid%3D7005%26ttl%3D1400
rq%3D2%26wid%3D7005%26ttl%3D989
rq%3D3%26wid%3D7005%26ttl%3D2241</code></pre>
<p>What is this gibberish? <code>ttl</code> looks like a field name (‚Äò<a href="http://en.wikipedia.org/wiki/time%20to%20live" title="Wikipedia: time to live">time to live</a>‚Äô, perhaps?); it‚Äôs URL-encoded gunk, so let‚Äôs <a href="http://meyerweb.com/eric/tools/dencoder/">decode</a> it:</p>
<pre><code>rq=0&amp;wid=7005
rq=1&amp;wid=7005&amp;ttl=1400
rq=2&amp;wid=7005&amp;ttl=989
rq=3&amp;wid=7005&amp;ttl=2241</code></pre>
<ul>
<li><code>rq</code> is obviously short for ‚Äòrequest‚Äô, and an incrementing integer suggests that it‚Äôs counting how many pages one has visited. For the archiver bot, we can hardwire it as ‚Äò0‚Äô because there will be a good 20 seconds between each request (due to the WebCite timeout).</li>
<li><code>wid</code> is troubling because it‚Äôs constant, and a fairly large number. It doesn‚Äôt seem large enough to be a user ID - surely the toolbar has had more than 7000 users, since the <a href="https://addons.mozilla.org/en-us/firefox/addon/alexa-sparky/">toolbar</a> page says it has had 1.6 million downloads. Is it a user ID? We‚Äôll leave it for now.</li>
<li><code>ttl</code> is also troubling because it changes but isn‚Äôt even in the first request. <em>Does</em> it stand for ‚Äòtime to live‚Äô? Does it vary if I load the same page many times, is it a measure of how fast pages load or something (a metric very important to search engines, who rank higher the sites which are faster)? Can we get away with omitting it?</li>
</ul>
<p>We need more information on <code>ttl</code> and <code>wid</code>. So let‚Äôs visit a bunch more URLs and see whether more data says anything:</p>
<pre><code>http://data.alexa.com/data/SbADd155Tq0000?cli=10&amp;ver=spkyf-1.5.0&amp;dat=ns
    &amp;cdt=rq%3D4%26wid%3D15698%26ttl%3D1830&amp;ref=&amp;url=http%3A%2F%2Fwww.reddit.com%2F
http://data.alexa.com/data/SbADd155Tq0000?cli=10&amp;ver=spkyf-1.5.0&amp;dat=ns
    &amp;cdt=rq%3D5%26wid%3D15698%26ttl%3D425&amp;ref=&amp;url=http%3A%2F%2Fwww.gwern.net%2F
http://data.alexa.com/data/SbADd155Tq0000?cli=10&amp;ver=spkyf-1.5.0&amp;dat=ns
    &amp;cdt=rq%3D6%26wid%3D15698%26ttl%3D1614&amp;ref=&amp;url=http%3A%2F%2Fwww.reddit.com%2F
http://data.alexa.com/data/SbADd155Tq0000?cli=10&amp;ver=spkyf-1.5.0&amp;dat=ns
    &amp;cdt=rq%3D7%26wid%3D15698%26ttl%3D376&amp;ref=&amp;url=http%3A%2F%2Fwww.gwern.net%2F
http://data.alexa.com/data/SbADd155Tq0000?cli=10&amp;ver=spkyf-1.5.0&amp;dat=ns
    &amp;cdt=rq%3D8%26wid%3D15698%26ttl%3D1468&amp;ref=&amp;url=http%3A%2F%2Fwww.reddit.com%2F
http://data.alexa.com/data/SbADd155Tq0000?cli=10&amp;ver=spkyf-1.5.0&amp;dat=ns
    &amp;cdt=rq%3D9%26wid%3D15698%26ttl%3D2092&amp;ref=&amp;url=http%3A%2F%2Flesswrong.com%2F
http://data.alexa.com/data/SbADd155Tq0000?cli=10&amp;ver=spkyf-1.5.0&amp;dat=ns
    &amp;cdt=rq%3D10%26wid%3D15698%26ttl%3D1717&amp;ref=&amp;url=http%3A%2F%2Fwww.overcomingbias.com%2F
http://data.alexa.com/data/SbADd155Tq0000?cli=10&amp;ver=spkyf-1.5.0&amp;dat=ns
    &amp;cdt=rq%3D11%26wid%3D15698%26ttl%3D2010&amp;ref=http%3A%2F%2Fwww.overcomingbias.com%2F
    &amp;url=http%3A%2F%2Fwww.overcomingbias.com%2F2011%2F06%2Frevised-growth-claim.html%23comments</code></pre>
<p>Filter and URL-decode the <code>ttl</code> field:</p>
<pre><code>ttl=1830
ttl=425
ttl=1614
ttl=376
ttl=1468
ttl=2092
ttl=1717
ttl=2010</code></pre>
<p>The smallest in any <code>ttl</code> is 376, the largest is 2241. This is a range which smells suspiciously like a page load time - few sites load much faster than 0.25 seconds and most clock in at a second or two. Combined with the observation that the first sample URL doesn‚Äôt have a <code>ttl</code>, I think we can safely omit the <code>ttl</code> field.</p>
<p>And <code>wid</code>? We speculated it‚Äôs some kind of user ID. In this second batch, the field is <code>wid%3D15698</code> or <code>wid=15698</code>. So the <code>wid</code> is not consistent across Firefox sessions, but it is consistent across multiple page loads. This suggests to me that Alexa is only aggregating URLs by a ‚Äòbrowser session‚Äô ID (maybe it originally tracked individual ‚Äòwindows‚Äô, hence the ‚Äòw‚Äô part of the ID). We can probably just generate a random number between 1000 and 20000 every time we archive a URL. So, all told our pseudocode goes like this:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="st">&quot;http://data.alexa.com/data/SbADd155Tq0000?cli=10&amp;ver=spkyf-1.5.0&amp;dat=ns&amp;cdt=&quot;</span> <span class="fu">++</span>
    escape (<span class="st">&quot;rq=0&amp;wid=&quot;</span> <span class="fu">++</span> show randomint <span class="fu">++</span> <span class="st">&quot;&amp;ref=&amp;url=&quot;</span> <span class="fu">++</span> url)</code></pre>
<p>How do we get our <code>randomint</code> and <code>urlEncode</code>? I have had to URL-encode strings in the past, for XMonad‚Äôs <a href="http://www.haskell.org/hoogle/?hoogle=XMonad.Actions.Search" title="Hoogle: XMonad.Actions.Search">XMonad.Actions.Search</a> module:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">escape ::</span> <span class="dt">String</span> <span class="ot">-&gt;</span> <span class="dt">String</span>
escape <span class="fu">=</span> concatMap escapeURIChar
    <span class="kw">where</span><span class="ot"> escapeURIChar ::</span> <span class="dt">Char</span> <span class="ot">-&gt;</span> <span class="dt">String</span>
          escapeURIChar c <span class="fu">|</span> isAscii c <span class="fu">&amp;&amp;</span> isAlphaNum c <span class="fu">=</span> [c]
                          <span class="fu">|</span> otherwise                 <span class="fu">=</span> concatMap (printf <span class="st">&quot;%%%02X&quot;</span>) <span class="fu">$</span> encode [c]</code></pre>
<p>We‚Äôll do the random IO with System.Random, hide it internally inside the Alexa toolbar archive function since that function <em>has</em> to be in IO anyway, and reuse <code>openURL</code>:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">import </span><span class="dt">System.Random</span> (getStdGen, randomR)
<span class="kw">import </span><span class="dt">Text.HTML.Download</span> (openURL)
<span class="kw">import </span><span class="dt">Data.Char</span> (isAlphaNum, isAscii)
<span class="kw">import </span><span class="dt">Text.Printf</span> (printf)

<span class="ot">a ::</span> <span class="dt">String</span> <span class="ot">-&gt;</span> <span class="dt">IO</span> ()
a url <span class="fu">=</span> <span class="kw">do</span> gen <span class="ot">&lt;-</span> getStdGen
           <span class="kw">let</span> rint <span class="fu">=</span> fst <span class="fu">$</span> randomR (<span class="dv">1000</span><span class="ot">::</span><span class="dt">Int</span>,<span class="dv">20000</span>) gen
           <span class="kw">let</span> payload <span class="fu">=</span> escape (<span class="st">&quot;wid=&quot;</span> <span class="fu">++</span> show rint <span class="fu">++</span> <span class="st">&quot;&amp;ref=&amp;url=&quot;</span> <span class="fu">++</span> url)
           print<span class="fu">$</span><span class="st">&quot;http://data.alexa.com/data/SbADd155Tq0000?cli=10&amp;ver=spkyf-1.5.0&amp;dat=ns&amp;cdt=rq=0&amp;&quot;</span>
                     <span class="fu">++</span> payload

             <span class="kw">where</span><span class="ot"> escape ::</span> <span class="dt">String</span> <span class="ot">-&gt;</span> <span class="dt">String</span>
                   escape <span class="fu">=</span> concatMap escapeURIChar
<span class="ot">                   escapeURIChar ::</span> <span class="dt">Char</span> <span class="ot">-&gt;</span> <span class="dt">String</span>
                   escapeURIChar c <span class="fu">|</span> isAscii c <span class="fu">&amp;&amp;</span> isAlphaNum c <span class="fu">=</span> [c]
                                   <span class="fu">|</span> otherwise                <span class="fu">=</span> concatMap (printf <span class="st">&quot;%%%02X&quot;</span>) [c]</code></pre>
<p>A better name would be <code>alexaToolbar</code>. We‚Äôll test it: <code>alexaToolbar &quot;http://www.google.com&quot;</code> evaluates to:</p>
<pre><code>&quot;http://data.alexa.com/data/SbADd155Tq0000?cli=10&amp;ver=spkyf-1.5.0&amp;dat=ns
    &amp;cdt=rq%3D0%26wid%3D%2819413%2C218941083%2040692%29%26ref%3D%26url%3Dhttp%3A%2F%2Fwww%2Egoogle%2Ecom%2F&quot;</code></pre>
<p>We run it in <code>curl</code>, and we get:</p>
<pre class="sourceCode xml"><code class="sourceCode xml"><span class="kw">&lt;?xml</span> version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;<span class="kw">?&gt;</span>
<span class="kw">&lt;ALEXA</span><span class="ot"> VER=</span><span class="st">&quot;0.9&quot;</span><span class="ot"> URL=</span><span class="st">&quot;404&quot;</span><span class="ot"> HOME=</span><span class="st">&quot;0&quot;</span><span class="ot"> AID=</span><span class="st">&quot;=&quot;</span><span class="kw">&gt;</span>
<span class="kw">&lt;/ALEXA&gt;</span></code></pre>
<p>Is that right? Let‚Äôs see what the very first URL example said, since as far as we could tell, the URL examples should be indefinitely reusable:</p>
<pre class="sourceCode xml"><code class="sourceCode xml"><span class="kw">&lt;?xml</span> version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;<span class="kw">?&gt;</span>
<span class="kw">&lt;ALEXA</span><span class="ot"> VER=</span><span class="st">&quot;0.9&quot;</span><span class="ot"> URL=</span><span class="st">&quot;cnn.com/&quot;</span><span class="ot"> HOME=</span><span class="st">&quot;0&quot;</span><span class="ot"> AID=</span><span class="st">&quot;=&quot;</span><span class="kw">&gt;</span>
<span class="kw">&lt;RLS</span><span class="ot"> PREFIX=</span><span class="st">&quot;http://&quot;</span><span class="ot"> more=</span><span class="st">&quot;92&quot;</span><span class="kw">&gt;</span>
<span class="kw">&lt;RL</span><span class="ot"> HREF=</span><span class="st">&quot;foxnews.com/&quot;</span><span class="ot"> TITLE=</span><span class="st">&quot;Fox News Channel&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;RL</span><span class="ot"> HREF=</span><span class="st">&quot;abcnews.go.com/&quot;</span><span class="ot"> TITLE=</span><span class="st">&quot;Abc News : Online News, Breaking News, Feature Stories And More&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;RL</span><span class="ot"> HREF=</span><span class="st">&quot;www.cbsnews.com/&quot;</span><span class="ot"> TITLE=</span><span class="st">&quot;CBS News&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;RL</span><span class="ot"> HREF=</span><span class="st">&quot;news.bbc.co.uk/&quot;</span><span class="ot"> TITLE=</span><span class="st">&quot;BBC News&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;RL</span><span class="ot"> HREF=</span><span class="st">&quot;cnnenespanol.com/entv&quot;</span><span class="ot"> TITLE=</span><span class="st">&quot;CNNenEspanol&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;RL</span><span class="ot"> HREF=</span><span class="st">&quot;nytimes.com/&quot;</span><span class="ot"> TITLE=</span><span class="st">&quot;The New York Times&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;RL</span><span class="ot"> HREF=</span><span class="st">&quot;www.msnbc.com/&quot;</span><span class="ot"> TITLE=</span><span class="st">&quot;Msnbc&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;RL</span><span class="ot"> HREF=</span><span class="st">&quot;news.google.com/?output=rss&quot;</span><span class="ot"> TITLE=</span><span class="st">&quot;Google News&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;RL</span><span class="ot"> HREF=</span><span class="st">&quot;www.microsite.reuters.com/rss/worldNews&quot;</span><span class="ot"> TITLE=</span><span class="st">&quot;Reuters - World News&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;RL</span><span class="ot"> HREF=</span><span class="st">&quot;www.pbs.org/&quot;</span><span class="ot"> TITLE=</span><span class="st">&quot;Pbs&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;RL</span><span class="ot"> HREF=</span><span class="st">&quot;fullcoverage.yahoo.com/&quot;</span><span class="ot"> TITLE=</span><span class="st">&quot;fullcoverage.yahoo.com/&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;/RLS&gt;</span>
<span class="kw">&lt;SD</span><span class="ot"> TITLE=</span><span class="st">&quot;A&quot;</span><span class="ot"> FLAGS=</span><span class="st">&quot;DMOZ&quot;</span><span class="ot"> HOST=</span><span class="st">&quot;cnn.com&quot;</span><span class="kw">&gt;</span>
<span class="kw">&lt;TITLE</span><span class="ot"> TEXT=</span><span class="st">&quot;CNN - Cable News Network&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;ADDR</span><span class="ot"> STREET=</span><span class="st">&quot;1 CNN Center, One CNN Center&quot;</span><span class="ot"> CITY=</span><span class="st">&quot;Atlanta&quot;</span><span class="ot"> STATE=</span><span class="st">&quot;GA&quot;</span><span class="ot"> ZIP=</span><span class="st">&quot;30303&quot;</span><span class="ot"> COUNTRY=</span><span class="st">&quot;US&quot;</span> <span class="kw">/&gt;</span>
<span class="kw">&lt;CREATED</span><span class="ot"> DATE=</span><span class="st">&quot;22-Sep-1993&quot;</span><span class="ot"> DAY=</span><span class="st">&quot;22&quot;</span><span class="ot"> MONTH=</span><span class="st">&quot;09&quot;</span><span class="ot"> YEAR=</span><span class="st">&quot;1993&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;PHONE</span><span class="ot"> NUMBER=</span><span class="st">&quot;404.827.1500&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;OWNER</span><span class="ot"> NAME=</span><span class="st">&quot;Cable News Network&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;EMAIL</span><span class="ot"> ADDR=</span><span class="st">&quot;<a class="__cf_email__" href="http://www.cloudflare.com/email-protection" data-cfemail="beeaf3f9ecf1ebeefecacbccd0dbcc90ddd1d3">[email&nbsp;protected]</a><script type="text/javascript">
/* <![CDATA[ */
(function(){try{var s,a,i,j,r,c,l,b=document.getElementsByTagName("script");l=b[b.length-1].previousSibling;a=l.getAttribute('data-cfemail');if(a){s='';r=parseInt(a.substr(0,2),16);for(j=2;a.length-j;j+=2){c=parseInt(a.substr(j,2),16)^r;s+=String.fromCharCode(c);}s=document.createTextNode(s);l.parentNode.replaceChild(s,l);}}catch(e){}})();
/* ]]> */
</script>&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;DOS&gt;</span>
<span class="kw">&lt;DO</span><span class="ot"> DOMAIN=</span><span class="st">&quot;insidersadvantage.com&quot;</span><span class="ot"> TITLE=</span><span class="st">&quot;insidersadvantage.com&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;/DOS&gt;</span>
<span class="kw">&lt;TICKER</span><span class="ot"> SYMBOL=</span><span class="st">&quot;AOL&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;LANG</span><span class="ot"> LEX=</span><span class="st">&quot;en&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;LINKSIN</span><span class="ot"> NUM=</span><span class="st">&quot;77443&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;SPEED</span><span class="ot"> TEXT=</span><span class="st">&quot;1451&quot;</span><span class="ot"> PCT=</span><span class="st">&quot;49&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;REVIEWS</span><span class="ot"> AVG=</span><span class="st">&quot;3.0&quot;</span><span class="ot"> NUM=</span><span class="st">&quot;53&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;CHILD</span><span class="ot"> SRATING=</span><span class="st">&quot;0&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;/SD&gt;</span>
<span class="kw">&lt;KEYWORDS&gt;</span>
<span class="kw">&lt;KEYWORD</span><span class="ot"> VAL=</span><span class="st">&quot;Networks&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;KEYWORD</span><span class="ot"> VAL=</span><span class="st">&quot;Cable&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;KEYWORD</span><span class="ot"> VAL=</span><span class="st">&quot;CNN News Group&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;/KEYWORDS&gt;&lt;DMOZ&gt;</span>
<span class="kw">&lt;SITE</span><span class="ot"> BASE=</span><span class="st">&quot;cnn.com/&quot;</span><span class="ot"> TITLE=</span><span class="st">&quot;CNN Interactive&quot;</span><span class="ot"> DESC=</span><span class="st">&quot;News, weather, sports, and services including</span>
<span class="st">    e-mail news alerts and downloadable audio/video reports.&quot;</span><span class="kw">&gt;</span>
<span class="kw">&lt;CATS&gt;</span>
<span class="kw">&lt;CAT</span><span class="ot"> ID=</span><span class="st">&quot;Top/News&quot;</span><span class="ot"> TITLE=</span><span class="st">&quot;English/News&quot;</span><span class="ot"> CID=</span><span class="st">&quot;998601&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;CAT</span><span class="ot"> ID=</span><span class="st">&quot;Top/Arts/Television/News&quot;</span><span class="ot"> TITLE=</span><span class="st">&quot;Television/News&quot;</span><span class="ot"> CID=</span><span class="st">&quot;395700&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;CAT</span><span class="ot"> ID=</span><span class="st">&quot;Top/Arts/Television/Networks/Cable/CNN&quot;</span><span class="ot"> TITLE=</span><span class="st">&quot;Cable/CNN&quot;</span><span class="ot"> CID=</span><span class="st">&quot;392942&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;/CATS&gt;</span>
<span class="kw">&lt;/SITE&gt;</span>
<span class="kw">&lt;/DMOZ&gt;</span>
<span class="kw">&lt;SD&gt;</span>
<span class="kw">&lt;POPULARITY</span><span class="ot"> URL=</span><span class="st">&quot;cnn.com/&quot;</span><span class="ot"> TEXT=</span><span class="st">&quot;49&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;REACH</span><span class="ot"> RANK=</span><span class="st">&quot;42&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;RANK</span><span class="ot"> DELTA=</span><span class="st">&quot;+1&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;/SD&gt;</span>
<span class="kw">&lt;/ALEXA&gt;</span></code></pre>
<p>Well, drat. That looks very different. What could the error be? We compare our generated with an original, and they match, but only up to <code>wid</code> and later parameters:</p>
<pre><code>wid%3D7005&amp;ref=&amp;url=http%3A%2F%2Fwww.cnn.com%2F
wid%3D%288260%2C2113025614%2040692%29%26ref%3D%26url%3Dhttp%3A%2F%2Fwww%2Ecnn%2Ecom</code></pre>
<p>So maybe we need to escape only the URL, so:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">let</span> payload <span class="fu">=</span> <span class="st">&quot;rq=0&amp;wid=&quot;</span> <span class="fu">++</span> show rint <span class="fu">++</span> <span class="st">&quot;&amp;ref=&amp;url=&quot;</span> <span class="fu">++</span> escape url</code></pre>
<p>and now <code>alexaToolbar &quot;http://www.cnn.com&quot;</code> evaluates to:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="st">&quot;http://data.alexa.com/data/SbADd155Tq0000?cli=10&amp;ver=spkyf-1.5.0&amp;</span>
<span class="st">    dat=ns&amp;cdt=rq=0&amp;wid=8100&amp;ref=&amp;url=http%3A%2F%2Fwww%2Ecnn%2Ecom&quot;</span></code></pre>
<p>Which seems to work:</p>
<pre class="sourceCode xml"><code class="sourceCode xml"><span class="kw">&lt;?xml</span> version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;<span class="kw">?&gt;</span>
<span class="kw">&lt;ALEXA</span><span class="ot"> VER=</span><span class="st">&quot;0.9&quot;</span><span class="ot"> URL=</span><span class="st">&quot;cnn.com/&quot;</span><span class="ot"> HOME=</span><span class="st">&quot;0&quot;</span><span class="ot"> AID=</span><span class="st">&quot;=&quot;</span><span class="kw">&gt;</span>
<span class="kw">&lt;RLS</span><span class="ot"> PREFIX=</span><span class="st">&quot;http://&quot;</span><span class="ot"> more=</span><span class="st">&quot;92&quot;</span><span class="kw">&gt;</span>
<span class="kw">&lt;RL</span><span class="ot"> HREF=</span><span class="st">&quot;foxnews.com/&quot;</span><span class="ot"> TITLE=</span><span class="st">&quot;Fox News Channel&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;RL</span><span class="ot"> HREF=</span><span class="st">&quot;abcnews.go.com/&quot;</span><span class="ot"> TITLE=</span><span class="st">&quot;Abc News : Online News, Breaking News, Feature Stories And More&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;RL</span><span class="ot"> HREF=</span><span class="st">&quot;www.cbsnews.com/&quot;</span><span class="ot"> TITLE=</span><span class="st">&quot;CBS News&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;RL</span><span class="ot"> HREF=</span><span class="st">&quot;news.bbc.co.uk/&quot;</span><span class="ot"> TITLE=</span><span class="st">&quot;BBC News&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;RL</span><span class="ot"> HREF=</span><span class="st">&quot;cnnenespanol.com/entv&quot;</span><span class="ot"> TITLE=</span><span class="st">&quot;CNNenEspanol&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;RL</span><span class="ot"> HREF=</span><span class="st">&quot;nytimes.com/&quot;</span><span class="ot"> TITLE=</span><span class="st">&quot;The New York Times&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;RL</span><span class="ot"> HREF=</span><span class="st">&quot;www.msnbc.com/&quot;</span><span class="ot"> TITLE=</span><span class="st">&quot;Msnbc&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;RL</span><span class="ot"> HREF=</span><span class="st">&quot;news.google.com/?output=rss&quot;</span><span class="ot"> TITLE=</span><span class="st">&quot;Google News&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;RL</span><span class="ot"> HREF=</span><span class="st">&quot;www.microsite.reuters.com/rss/worldNews&quot;</span><span class="ot"> TITLE=</span><span class="st">&quot;Reuters - World News&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;RL</span><span class="ot"> HREF=</span><span class="st">&quot;www.pbs.org/&quot;</span><span class="ot"> TITLE=</span><span class="st">&quot;Pbs&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;RL</span><span class="ot"> HREF=</span><span class="st">&quot;fullcoverage.yahoo.com/&quot;</span><span class="ot"> TITLE=</span><span class="st">&quot;fullcoverage.yahoo.com/&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;/RLS&gt;</span>
<span class="kw">&lt;SD</span><span class="ot"> TITLE=</span><span class="st">&quot;A&quot;</span><span class="ot"> FLAGS=</span><span class="st">&quot;DMOZ&quot;</span><span class="ot"> HOST=</span><span class="st">&quot;cnn.com&quot;</span><span class="kw">&gt;</span>
<span class="kw">&lt;TITLE</span><span class="ot"> TEXT=</span><span class="st">&quot;CNN - Cable News Network&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;ADDR</span><span class="ot"> STREET=</span><span class="st">&quot;1 CNN Center, One CNN Center&quot;</span><span class="ot"> CITY=</span><span class="st">&quot;Atlanta&quot;</span><span class="ot"> STATE=</span><span class="st">&quot;GA&quot;</span><span class="ot"> ZIP=</span><span class="st">&quot;30303&quot;</span><span class="ot"> COUNTRY=</span><span class="st">&quot;US&quot;</span> <span class="kw">/&gt;</span>
<span class="kw">&lt;CREATED</span><span class="ot"> DATE=</span><span class="st">&quot;22-Sep-1993&quot;</span><span class="ot"> DAY=</span><span class="st">&quot;22&quot;</span><span class="ot"> MONTH=</span><span class="st">&quot;09&quot;</span><span class="ot"> YEAR=</span><span class="st">&quot;1993&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;PHONE</span><span class="ot"> NUMBER=</span><span class="st">&quot;404.827.1500&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;OWNER</span><span class="ot"> NAME=</span><span class="st">&quot;Cable News Network&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;EMAIL</span><span class="ot"> ADDR=</span><span class="st">&quot;<a class="__cf_email__" href="http://www.cloudflare.com/email-protection" data-cfemail="e5b1a8a2b7aab0b5a59190978b8097cb868a88">[email&nbsp;protected]</a><script type="text/javascript">
/* <![CDATA[ */
(function(){try{var s,a,i,j,r,c,l,b=document.getElementsByTagName("script");l=b[b.length-1].previousSibling;a=l.getAttribute('data-cfemail');if(a){s='';r=parseInt(a.substr(0,2),16);for(j=2;a.length-j;j+=2){c=parseInt(a.substr(j,2),16)^r;s+=String.fromCharCode(c);}s=document.createTextNode(s);l.parentNode.replaceChild(s,l);}}catch(e){}})();
/* ]]> */
</script>&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;DOS&gt;</span>
<span class="kw">&lt;DO</span><span class="ot"> DOMAIN=</span><span class="st">&quot;insidersadvantage.com&quot;</span><span class="ot"> TITLE=</span><span class="st">&quot;insidersadvantage.com&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;/DOS&gt;</span>
<span class="kw">&lt;TICKER</span><span class="ot"> SYMBOL=</span><span class="st">&quot;AOL&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;LANG</span><span class="ot"> LEX=</span><span class="st">&quot;en&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;LINKSIN</span><span class="ot"> NUM=</span><span class="st">&quot;77443&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;SPEED</span><span class="ot"> TEXT=</span><span class="st">&quot;1451&quot;</span><span class="ot"> PCT=</span><span class="st">&quot;49&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;REVIEWS</span><span class="ot"> AVG=</span><span class="st">&quot;3.0&quot;</span><span class="ot"> NUM=</span><span class="st">&quot;53&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;CHILD</span><span class="ot"> SRATING=</span><span class="st">&quot;0&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;/SD&gt;</span>
<span class="kw">&lt;KEYWORDS&gt;</span>
<span class="kw">&lt;KEYWORD</span><span class="ot"> VAL=</span><span class="st">&quot;Networks&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;KEYWORD</span><span class="ot"> VAL=</span><span class="st">&quot;Cable&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;KEYWORD</span><span class="ot"> VAL=</span><span class="st">&quot;CNN News Group&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;/KEYWORDS&gt;&lt;DMOZ&gt;</span>
<span class="kw">&lt;SITE</span><span class="ot"> BASE=</span><span class="st">&quot;cnn.com/&quot;</span><span class="ot"> TITLE=</span><span class="st">&quot;CNN Interactive&quot;</span><span class="ot"> DESC=</span><span class="st">&quot;News, weather, sports, and services including</span>
<span class="st">    e-mail news alerts and downloadable audio/video reports.&quot;</span><span class="kw">&gt;</span>
<span class="kw">&lt;CATS&gt;</span>
<span class="kw">&lt;CAT</span><span class="ot"> ID=</span><span class="st">&quot;Top/News&quot;</span><span class="ot"> TITLE=</span><span class="st">&quot;English/News&quot;</span><span class="ot"> CID=</span><span class="st">&quot;998601&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;CAT</span><span class="ot"> ID=</span><span class="st">&quot;Top/Arts/Television/News&quot;</span><span class="ot"> TITLE=</span><span class="st">&quot;Television/News&quot;</span><span class="ot"> CID=</span><span class="st">&quot;395700&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;CAT</span><span class="ot"> ID=</span><span class="st">&quot;Top/Arts/Television/Networks/Cable/CNN&quot;</span><span class="ot"> TITLE=</span><span class="st">&quot;Cable/CNN&quot;</span><span class="ot"> CID=</span><span class="st">&quot;392942&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;/CATS&gt;</span>
<span class="kw">&lt;/SITE&gt;</span>
<span class="kw">&lt;/DMOZ&gt;</span>
<span class="kw">&lt;SD&gt;</span>
<span class="kw">&lt;POPULARITY</span><span class="ot"> URL=</span><span class="st">&quot;cnn.com/&quot;</span><span class="ot"> TEXT=</span><span class="st">&quot;49&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;REACH</span><span class="ot"> RANK=</span><span class="st">&quot;42&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;RANK</span><span class="ot"> DELTA=</span><span class="st">&quot;+1&quot;</span><span class="kw">/&gt;</span>
<span class="kw">&lt;/SD&gt;</span>
<span class="kw">&lt;/ALEXA&gt;</span></code></pre>
<p>Similarly, if we try ‚Äúhttp://www.google.com‚Äù, that seems to work as well. Now we can modify the function to be directly usable:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">import </span><span class="dt">System.Random</span> (getStdGen, randomR)
<span class="kw">import </span><span class="dt">Text.HTML.Download</span> (openURL)
<span class="kw">import </span><span class="dt">Data.Char</span> (isAlphaNum, isAscii)
<span class="kw">import </span><span class="dt">Text.Printf</span> (printf)

<span class="ot">alexaToolbar ::</span> <span class="dt">String</span> <span class="ot">-&gt;</span> <span class="dt">IO</span> ()
alexaToolbar url <span class="fu">=</span> <span class="kw">do</span> gen <span class="ot">&lt;-</span> getStdGen
                      <span class="kw">let</span> rint <span class="fu">=</span> fst <span class="fu">$</span> randomR (<span class="dv">1000</span><span class="ot">::</span><span class="dt">Int</span>,<span class="dv">20000</span>) gen
                      <span class="kw">let</span> payload <span class="fu">=</span> <span class="st">&quot;wid=&quot;</span> <span class="fu">++</span> show rint <span class="fu">++</span> <span class="st">&quot;&amp;ref=&amp;url=&quot;</span> <span class="fu">++</span> escape url
                      _ <span class="ot">&lt;-</span> openURL <span class="fu">$</span> <span class="st">&quot;http://data.alexa.com/data/SbADd155Tq0000?\</span>
<span class="st">                                     \cli=10&amp;ver=spkyf-1.5.0&amp;dat=ns&amp;cdt=rq=0&amp;&quot;</span> <span class="fu">++</span> payload
                      returnf ()
             <span class="kw">where</span><span class="ot"> escape ::</span> <span class="dt">String</span> <span class="ot">-&gt;</span> <span class="dt">String</span>
                   escape <span class="fu">=</span> concatMap escapeURIChar
<span class="ot">                   escapeURIChar ::</span> <span class="dt">Char</span> <span class="ot">-&gt;</span> <span class="dt">String</span>
                   escapeURIChar c <span class="fu">|</span> isAscii c <span class="fu">&amp;&amp;</span> isAlphaNum c <span class="fu">=</span> [c]
                                   <span class="fu">|</span> otherwise                <span class="fu">=</span> concatMap (printf <span class="st">&quot;%%%02X&quot;</span>) [c]</code></pre>
</section>
</section>
<section id="duplicate-urls" class="level3">
<h3>Duplicate URLs</h3>
<p>We compile the entire program, and it is short. It is sweet. It works, and does what we want, and has explicit types and import statements, and we‚Äôve reasoned out every bit of it. So we should be pretty happy with it. But I‚Äôve noticed one thing while playing around in GHCi: it‚Äôs naive and inefficient. Not only does it eat up ungodly amounts of memory and time, it also seems to be making duplicate requests! The reason for this is that on every Wikipedia webpage containing an article, there are a number of external links which aren‚Äôt part of the article itself; this includes linking to the <a href="http://en.wikipedia.org/wiki/WikiMedia%20Foundation" title="Wikipedia: WikiMedia Foundation">WikiMedia Foundation</a> (the non-profit organization which runs all the Wikipedias and associated projects), links to donations, etc.</p>
<p>Well, not a hard problem. We want to ensure there are no duplicate entries in our list; one suspects this is a common desire in list processing.</p>
<p>The type signature would be <code>[a] -&gt; [a]</code>, but unfortunately, this is far too general: <a href="http://www.haskell.org/hoogle/?hoogle=%5Ba%5D%20-%3E%20%5Ba%5D" title="Hoogle: [a] -&gt; [a]">Hoogle</a> will not even put the right function on the first page.</p>
<p>We need to think: any function of this sort must go through the list, and compare entries. Compare what? For greater-than, less-than, etc.? That would imply an <a href="http://www.haskell.org/hoogle/?hoogle=Ord" title="Hoogle: Ord">Ord</a> constraint, but punched in, <a href="http://www.haskell.org/hoogle/?hoogle=Ord%20a%20%3D%3E%20%5Ba%5D%20-%3E%20%5Ba%5D" title="Hoogle: Ord a =&gt; [a] -&gt; [a]">we see</a> nothing useful. No, those are useful for sorting, but we only want the entries to be unique and not sorted in anyway. We only need <code>==</code>, which means an <a href="http://www.haskell.org/hoogle/?hoogle=Eq" title="Hoogle: Eq">Eq</a> constraint. <a href="http://www.haskell.org/hoogle/?hoogle=nub" title="Hoogle: nub">nub</a> is the very first hit for <a href="http://www.haskell.org/hoogle/?hoogle=Eq%20a%20%3D%3E%20%5Ba%5D%20-%3E%20%5Ba%5D" title="Hoogle: Eq a =&gt; [a] -&gt; [a]">Eq a =&gt; [a] -&gt; [a]</a>.</p>
<p>(Of course, we could just read through <a href="http://www.haskell.org/hoogle/?hoogle=Data.List" title="Hoogle: Data.List">Data.List</a>.).</p>
<p>It makes the most sense to put <code>nub</code> just before we begin mapping <code>archiveURL</code> over <code>urllist</code>, so in it goes:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell">         mapM_ (archiveURL) (liftM nub urllist)</code></pre>
</section>
<section id="prototype" class="level3">
<h3>Prototype</h3>
<p>Well, that‚Äôs that! Let‚Äôs put it all together:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">import </span><span class="dt">Text.HTML.TagSoup</span> (parseTags, <span class="dt">Tag</span>(<span class="dt">TagOpen</span>))
<span class="kw">import </span><span class="dt">Text.HTML.Download</span> (openURL)
<span class="kw">import </span><span class="dt">Data.List</span> (isPrefixOf, nub)
<span class="kw">import </span><span class="dt">Monad</span> (liftM)

<span class="ot">main ::</span> <span class="dt">IO</span> ()
main <span class="fu">=</span> <span class="kw">do</span> articlelist <span class="ot">&lt;-</span> liftM words <span class="fu">$</span> getContents
          urllist <span class="ot">&lt;-</span> liftM concat <span class="fu">$</span> mapM fetchArticleURLs articlelist
          mapM_ (archiveURL) (liftM nub urllist)

<span class="ot">archiveURL ::</span> <span class="dt">String</span> <span class="ot">-&gt;</span> <span class="dt">IO</span> <span class="dt">String</span>
archiveURL url <span class="fu">=</span> openURL(<span class="st">&quot;http://www.webcitation.org/archive?url=&quot;</span> <span class="fu">++</span> url <span class="fu">++</span> <span class="st">&quot;&amp;email=<a class="__cf_email__" href="http://www.cloudflare.com/email-protection" data-cfemail="66000909260407144805090b">[email&nbsp;protected]</a><script type="text/javascript">
/* <![CDATA[ */
(function(){try{var s,a,i,j,r,c,l,b=document.getElementsByTagName("script");l=b[b.length-1].previousSibling;a=l.getAttribute('data-cfemail');if(a){s='';r=parseInt(a.substr(0,2),16);for(j=2;a.length-j;j+=2){c=parseInt(a.substr(j,2),16)^r;s+=String.fromCharCode(c);}s=document.createTextNode(s);l.parentNode.replaceChild(s,l);}}catch(e){}})();
/* ]]> */
</script>&quot;</span>)

<span class="ot">fetchArticleURLs ::</span> <span class="dt">String</span> <span class="ot">-&gt;</span> <span class="dt">IO</span> [<span class="dt">String</span>]
fetchArticleURLs article <span class="fu">=</span> liftM extractURLs <span class="fu">$</span> openURL(<span class="st">&quot;http://en.wikipedia.org/wiki/&quot;</span><span class="fu">++</span>article)

<span class="ot">extractURLs ::</span> <span class="dt">String</span> <span class="ot">-&gt;</span> [<span class="dt">String</span>]
extractURLs arg <span class="fu">=</span> [x <span class="fu">|</span> <span class="dt">TagOpen</span> <span class="st">&quot;a&quot;</span> atts <span class="ot">&lt;-</span> (parseTags arg),
                       (_,x) <span class="ot">&lt;-</span> atts,
                       <span class="st">&quot;http://&quot;</span> <span class="ot">`isPrefixOf`</span> x]</code></pre>
<p>Is this not lovely? Not counting imports or type signatures, it‚Äôs 6 lines (10 with imports, 14 all told) all in clear natural Haskell.</p>
</section>
<section id="performance" class="level3">
<h3>Performance</h3>
<section id="nub" class="level4">
<h4>nub</h4>
<p>But alas, we see an all too common problem with beautiful concise Haskell: it doesn‚Äôt perform well. We use it from the shell like thus:</p>
<pre><code>$ head -n 20 enwiki-all-titles-in-ns0 | archive-bot</code></pre>
<p>It performs acceptably for small values of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>n</mi></mrow></math>, but if we try 100 or more, we quickly notice extreme slowness and outsized memory usage. Looking through the code, <code>nub</code> immediately comes to mind as a culprit. Everywhere else, we‚Äôre using <code>map</code>s and the like, which are lazy and make nice streams with constant memory-use, but <code>nub</code> operates on the whole list of URLs at once, so perhaps it‚Äôs slow. <code>nub</code> is <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>n</mi><mn>2</mn></msup><mo stretchy="false">)</mo></mrow></math> because it compares every entry against every other entry in a list. Let‚Äôs optimize it.</p>
<p><code>nub</code> has to do <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>n</mi><mn>2</mn></msup><mo stretchy="false">)</mo></mrow></math> matches in part because it‚Äôs trying to preserve order (which is sort of important for a list). But we don‚Äôt care at all about order, so we‚Äôre free to do something clever‚Ä¶ like convert the list to the mathematical structure of sets and then back! We know in sets each member is unique (no {1,1,2} business), so we know it works, and the performance is better than <code>nub</code>. So add in:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">import </span><span class="dt">Data.Set</span> (toList, fromList)</code></pre>
<p>And replace the last line of main with:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell">          mapM_ archiveURL <span class="fu">$</span> liftM (toList <span class="fu">.</span> fromList) urllist</code></pre>
<p>But we must continue our quest for it is still not fast enough.</p>
</section>
<section id="bytestrings" class="level4">
<h4>ByteStrings</h4>
<p>The conventional wisdom is whenever you are using String and it isn‚Äôt fast enough, use the <a href="http://hackage.haskell.org/package/bytestring" title="Hackage: bytestring">bytestring</a> library. Our next version will make use of lazy ByteStrings:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">import qualified</span> <span class="dt">Data.ByteString.Lazy.Char8</span> <span class="kw">as</span> <span class="dt">B</span>
            (<span class="dt">ByteString</span>(), getContents, lines, unlines, pack, unpack, words)</code></pre>
<p>To convert to ByteString, we first convert to ByteString equivalents wherever possible - <code>B.words $ B.getContents</code>, for example. Unfortunately for our main function, ByteString introduces some weirdness, so we de-sugar the do notation to use the good old <a href="http://www.haskell.org/hoogle/?hoogle=%3D%3C%3C" title="Hoogle: =&lt;&lt;">=&lt;&lt;</a> operator to make sure everything fits together. But take heart, it‚Äôs shorter than before:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell">main <span class="fu">=</span> mapM_ archiveURL <span class="fu">=&lt;&lt;</span> (liftM uniq <span class="fu">$</span> mapM fetchArticleURLs
                               <span class="fu">=&lt;&lt;</span> (liftM B.words <span class="fu">$</span> B.getContents))
              <span class="kw">where</span><span class="ot"> uniq ::</span> (<span class="dt">Ord</span> a) <span class="ot">=&gt;</span> [[a]] <span class="ot">-&gt;</span> [a]
                    uniq <span class="fu">=</span> toList <span class="fu">$</span> fromList <span class="fu">$</span> concat</code></pre>
<p>Notice how we‚Äôve split out our concatenating and uniqueifying code to its own little points-free local definition. You may‚Äôve also noticed that we‚Äôre using the regular <a href="http://www.haskell.org/hoogle/?hoogle=concat" title="Hoogle: concat">concat</a> and not <code>ByteString.concat</code>; this is because we actually aren‚Äôt concatenating the ByteStrings themselves but merely the list of lists.</p>
<section id="bytestring-bot" class="level5">
<h5>Bytestring bot</h5>
<p>The other bit of trickiness is that TagSoup regular Strings, so we need manually convert back and forth between Strings and ByteStrings using <code>B.pack</code> and <code>B.unpack</code>, and of course the type signatures need to be updated. But this is all pretty simple and mechanical; the final result of all this fiddling is the noticeably uglier but also noticeably faster and leaner code:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">module</span> <span class="dt">Main</span> () <span class="kw">where</span>
<span class="kw">import </span><span class="dt">Text.HTML.TagSoup</span> (parseTags, <span class="dt">Tag</span>(<span class="dt">TagOpen</span>))
<span class="kw">import </span><span class="dt">Text.HTML.Download</span> (openURL)
<span class="kw">import </span><span class="dt">Data.List</span> (isPrefixOf)
<span class="kw">import </span><span class="dt">Monad</span> (liftM)
<span class="kw">import </span><span class="dt">Data.Set</span> (toList, fromList)
<span class="kw">import qualified</span> <span class="dt">Data.ByteString.Lazy.Char8</span> <span class="kw">as</span> <span class="dt">B</span>
             (<span class="dt">ByteString</span>(), getContents, lines, unlines, pack, unpack, words)

<span class="ot">main ::</span> <span class="dt">IO</span> ()
main <span class="fu">=</span> mapM_ archiveURL
           <span class="fu">=&lt;&lt;</span> (liftM uniq <span class="fu">$</span> mapM fetchArticleURLs
                <span class="fu">=&lt;&lt;</span> (liftM B.words <span class="fu">$</span> B.getContents))
              <span class="kw">where</span><span class="ot"> uniq ::</span> (<span class="dt">Ord</span> a) <span class="ot">=&gt;</span> [[a]] <span class="ot">-&gt;</span> [a]
                    uniq <span class="fu">=</span> toList <span class="fu">$</span> fromList <span class="fu">$</span> concat

<span class="ot">archiveURL ::</span> <span class="dt">B.ByteString</span> <span class="ot">-&gt;</span> <span class="dt">IO</span> <span class="dt">String</span>
archiveURL url <span class="fu">=</span> openURL(<span class="st">&quot;www.webcitation.org/archive?url=&quot;</span> <span class="fu">++</span> (B.unpack url)
                          <span class="fu">++</span> <span class="st">&quot;&amp;email=<a class="__cf_email__" href="http://www.cloudflare.com/email-protection" data-cfemail="680e0707280a091a460b0705">[email&nbsp;protected]</a><script type="text/javascript">
/* <![CDATA[ */
(function(){try{var s,a,i,j,r,c,l,b=document.getElementsByTagName("script");l=b[b.length-1].previousSibling;a=l.getAttribute('data-cfemail');if(a){s='';r=parseInt(a.substr(0,2),16);for(j=2;a.length-j;j+=2){c=parseInt(a.substr(j,2),16)^r;s+=String.fromCharCode(c);}s=document.createTextNode(s);l.parentNode.replaceChild(s,l);}}catch(e){}})();
/* ]]> */
</script>&quot;</span>)

<span class="ot">fetchArticleURLs ::</span> <span class="dt">B.ByteString</span> <span class="ot">-&gt;</span> <span class="dt">IO</span> [<span class="dt">B.ByteString</span>]
fetchArticleURLs article <span class="fu">=</span> liftM extractURLs <span class="fu">$</span> openURL(<span class="st">&quot;en.wikipedia.org/wiki/&quot;</span>
                                                      <span class="fu">++</span> (B.unpack article))

<span class="ot">extractURLs ::</span> <span class="dt">String</span> <span class="ot">-&gt;</span> [<span class="dt">B.ByteString</span>]
extractURLs arg <span class="fu">=</span> map B.pack <span class="fu">$</span> [x <span class="fu">|</span> <span class="dt">TagOpen</span> <span class="st">&quot;a&quot;</span> atts <span class="ot">&lt;-</span> (parseTags arg),
                                    (_,x) <span class="ot">&lt;-</span> atts,
                                    <span class="st">&quot;http://&quot;</span> <span class="ot">`isPrefixOf`</span> x]</code></pre>
</section>
</section>
</section>
<section id="parallelizing-requests" class="level3">
<h3>Parallelizing requests</h3>
<p>What‚Äôs that, you say? While ByteStrings has indeed made some difference, it‚Äôs marginal?</p>
<p>Fortunately, we can go still further - there‚Äôs not a whole lot we can do for the algorithm itself yet, but we can investigate parallelizing matters.</p>
<p>Remember that <code>archiveURL</code> was a bit inefficient because even with <code>mapM_</code>, each entry was being processed one at a time? Well, is this not Haskell? Aren‚Äôt functional programming languages famous for having functions like <code>map</code> which are embarrassingly easy to parallelize? If <code>archiveURL</code> were pure, we‚Äôd use <a href="http://www.haskell.org/hoogle/?hoogle=Control.Parallel.Strategies" title="Hoogle: Control.Parallel.Strategies">Control.Parallel.Strategies</a>, but it‚Äôs not.</p>
<p>We‚Äôre throwing away the output from <code>openURL</code> inside <code>archiveURL</code>. Ideally we would somehow be mapping a function over <code>urllist</code> which would say in effect ‚ÄúTake this single ByteString and go off somewhere by yourself and do whatever needs doing; don‚Äôt bother coming back.‚Äù In short, we want to fork <code>archiveURL</code> off.</p>
<p>But what function will do this for us? What is its signature? Let us think about it.</p>
<p>Clearly, if it really is going away forever, it cannot be pure, because such a function would be useless. If we can only write <code>fork (1+1)</code>, how do we know it ever ran at all? So the result of the argument must be something in IO. Perhaps it is <code>IO [a]</code>? But that‚Äôs not good, since the argument doesn‚Äôt <em>have</em> to evaluate to a list - what about arguments which mess around with tuples, or sets, or all the other data structures we have? The most general argument type is <code>IO a</code>.</p>
<p>We could imagine a ‚ÄògoAway :: (a -&gt; IO a) -&gt; a -&gt; IO ()‚Äô, and many other variants; but we cannot communicate with <code>goAway</code> - that‚Äôs the whole point - and so like a spaceship, it must have everything it needs and its arguments combined must be <code>IO a</code> - so why insist on one particular call-scheme? <code>goAway :: IO a -&gt; IO ()</code> is more general.</p>
<p>Unfortunately, Hoogle cannot help us here. If we ask for <a href="http://www.haskell.org/hoogle/?hoogle=IO%20a%20-%3E%20IO%20%28%29" title="Hoogle: IO a -&gt; IO ()">IO a -&gt; IO ()</a> or <a href="http://www.haskell.org/hoogle/?hoogle=IO%20a%20-%3E%20IO%20a" title="Hoogle: IO a -&gt; IO a">IO a -&gt; IO a</a> or other plausible types we could think of, we get a wide variety of functions, none of which we want. What we want is <code>forkIO</code>, with the signature <a href="http://www.haskell.org/hoogle/?hoogle=IO%20a%20-%3E%20IO%20ThreadId" title="Hoogle: IO a -&gt; IO ThreadId">IO a -&gt; IO ThreadId</a>.</p>
<p>This is a good illustration of why purity is important: it narrows down the range of possibilities. When a function starts with IO actions and ends with IO actions, it could be doing anything, and our search results reflect that. In comparison, a type like <code>(a,b) -&gt; a</code> is so specific that <a href="http://hackage.haskell.org/package/djinn" title="Hackage: djinn">djinn</a> can mechanically generate the function for that type<a href="#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a></p>
<p>We change <code>mapM_</code>:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">import </span><span class="dt">Control.Concurrent</span> (forkIO)

main <span class="fu">=</span> mapM_ (forkIO <span class="fu">.</span> archiveURL) <span class="fu">=&lt;&lt;</span>
           (liftM uniq <span class="fu">$</span> mapM fetchArticleURLs
              <span class="fu">=&lt;&lt;</span> (liftM B.words <span class="fu">$</span> B.getContents))
<span class="co">-- We need return () because otherwise `openURL` would return a String and break forkIO's heart</span>
archiveURL url <span class="fu">=</span> openURL (<span class="st">&quot;www.webcitation.org/archive?url=&quot;</span><span class="fu">++</span>B.unpack url<span class="fu">++</span><span class="st">&quot;&amp;email=<a class="__cf_email__" href="http://www.cloudflare.com/email-protection" data-cfemail="d5b3baba95b7b4a7fbb6bab8">[email&nbsp;protected]</a><script type="text/javascript">
/* <![CDATA[ */
(function(){try{var s,a,i,j,r,c,l,b=document.getElementsByTagName("script");l=b[b.length-1].previousSibling;a=l.getAttribute('data-cfemail');if(a){s='';r=parseInt(a.substr(0,2),16);for(j=2;a.length-j;j+=2){c=parseInt(a.substr(j,2),16)^r;s+=String.fromCharCode(c);}s=document.createTextNode(s);l.parentNode.replaceChild(s,l);}}catch(e){}})();
/* ]]> */
</script>&quot;</span>)
                     <span class="fu">&gt;&gt;</span> return ()</code></pre>
<p>Much better! I‚Äôve noticed improvements of 20-100%, since we can run on multiple CPUs. That little change was certainly worth it.</p>
<p>One small tweak occurs to me; if we ask a GHC 7 version of Hoogle for a function with the type <code>m a -&gt; m ()</code>, it will return a hit named <code>Control.Monad.void</code>, which is basically our <code>&gt;&gt; return ()</code> (in functor garb). If <code>void</code> is available, we would rewrite <code>archiveURL</code> like this:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell">archiveURL url <span class="fu">=</span> void (openURL (<span class="st">&quot;www.webcitation.org/archive?url=&quot;</span><span class="fu">++</span>B.unpack url<span class="fu">++</span><span class="st">&quot;&amp;email=<a class="__cf_email__" href="http://www.cloudflare.com/email-protection" data-cfemail="87e1e8e8c7e5e6f5a9e4e8ea">[email&nbsp;protected]</a><script type="text/javascript">
/* <![CDATA[ */
(function(){try{var s,a,i,j,r,c,l,b=document.getElementsByTagName("script");l=b[b.length-1].previousSibling;a=l.getAttribute('data-cfemail');if(a){s='';r=parseInt(a.substr(0,2),16);for(j=2;a.length-j;j+=2){c=parseInt(a.substr(j,2),16)^r;s+=String.fromCharCode(c);}s=document.createTextNode(s);l.parentNode.replaceChild(s,l);}}catch(e){}})();
/* ]]> */
</script>&quot;</span>))</code></pre>
</section>
<section id="laziness" class="level3">
<h3>Laziness</h3>
<p>But these speed increases have made me greedy - I want to be able to process a few thousand names at once, not a measly few hundred. This should cause us to ponder. Don Stewart has a quite fast program to check the viability of links, <a href="http://hackage.haskell.org/package/urlcheck" title="Hackage: urlcheck">urlcheck</a>; it delves pretty heavily into threads and gets great performance but it honestly looks pretty scary and hard to read. Do we have to resort to such nastiness?</p>
<p>Well, there‚Äôs a Haskell saying: ‚Äúthe best way to optimize a program is to make it lazier or stricter‚Äù.</p>
<p>It‚Äôs already strict in a lot of places because of the IO, and going further doesn‚Äôt seem like a good option - how can one pipe in thousands of articles if the program is going to strictly and immediately eat all one‚Äôs RAM? Laziness is the way to go.</p>
<p>To figure out how to get greater laziness, let‚Äôs go through step by step. We know <a href="http://www.haskell.org/hoogle/?hoogle=getContents" title="Hoogle: getContents">getContents</a> is lazy because it makes use of <a href="http://www.haskell.org/hoogle/?hoogle=unsafeInterleaveIO" title="Hoogle: unsafeInterleaveIO">unsafeInterleaveIO</a> according to the documentation - which is why we can have lazy IO. Let‚Äôs hold onto that thought.</p>
<p>Next is <code>B.words</code>. A quick experiment in GHCi (take 100 $ unwords $ repeat ‚ÄúYes‚Äù; that sort of thing) convinces me that <code>words</code> is lazy as one would expect.</p>
<p>Next is <code>mapM fetchArticleURLs</code>. Here‚Äôs a problem. <code>fetchArticleURLs</code> does IO and so is strict, and mapM means it is little better than a loop over the list - the entire list. There goes our laziness since the <em>whole</em> list will be processed before being passed onto <code>forkIO</code> and <code>archiveURL</code>. But laziness and IO can co-exist in peace and harmony!</p>
<p>Remember <code>getContents</code> is lazy, and it can achieve this magic using <code>unsafeInterleaveIO</code>. Reading through the documentation, it seems to be safe in certain situations: when the IO target isn‚Äôt going to change, isn‚Äôt going to change as a result of whatever is done - or one doesn‚Äôt care when the IO is performed.</p>
<p>In our situation, it‚Äôs irrelevant whether we access an article at time <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>n</mi></mrow></math> or time <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></math>. When you‚Äôre working on millions of articles, it doesn‚Äôt matter much if one article is changed or even deleted. So we can safely use <code>unsafeInterleaveIO</code>! We could stick it in <code>main</code> or <code>fetchArticleURLs</code>, but for convenience‚Äôs sake, I put it in the latter.</p>
<p>So now we have:</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">import </span><span class="dt">System.IO.Unsafe</span> (unsafeInterleaveIO)

fetchArticleURLs article <span class="fu">=</span> liftM (B.lines <span class="fu">.</span> extractURLs)
                            (unsafeInterleaveIO <span class="fu">$</span> openURL(wiki <span class="fu">++</span> B.unpack article))</code></pre>
<p>Let‚Äôs think about the flow now. <code>getContents</code> keeps on delivering a few characters to <code>words</code>, which is waiting for a <a href="http://en.wikipedia.org/wiki/newline" title="Wikipedia: newline">newline</a>, at which point it turns those characters into a String and passes them onto <code>mapM</code> which will immediately run <code>fetchArticleURLs</code> - and <code>fetchArticleURLs</code> will immediately ‚Äòfinish‚Äô, leaving behind some thunks or whatever holding a promise that it‚Äôll run the IO actions (downloading a particular Web page) whenever it‚Äôs needed. And that promise gets passed into <code>nub</code>, which is busy concatenating and then uniqueifying the results of those thunks.</p>
<p>So now the program will basically run in constant space (I notice that even when I pass it 10000 or 20000 names it‚Äôll use a steady 7.6% or so of memory as opposed to a varying ~40% with previous versions running on a few hundred names). It may take a while longer, but this is a small price to pay - now my computer will still be usable while the program is running.</p>
</section>
<section id="frugal-removal" class="level3">
<h3>Frugal removal</h3>
<p>Are we tired of this program yet? I‚Äôve thought of one last and particularly nasty thing to do to speed things up and recover the speed lost to laziness. We have uniq in there to remove duplicate entries and be a little friendlier to WebCite, correct? But if the program is hardwired to always run on Wikipedia pages, then we can just run <code>fetchArticleURLs</code> on a few pages, note down all the duplicates to help pages and legal notices etc., and hard-wire in a <code>filter</code> to remove them. This obviously is a hack.</p>
<p>But here is the final, ugly, fast and frugal version. This combines the lazy IO covered previously and adds in the hardwired filter.</p>
<pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">module</span> <span class="dt">Main</span> () <span class="kw">where</span>

<span class="kw">import </span><span class="dt">Control.Concurrent</span> (forkIO)
<span class="kw">import </span><span class="dt">Control.Monad</span> (liftM)
<span class="kw">import </span><span class="dt">Data.List</span> (isPrefixOf)
<span class="kw">import </span><span class="dt">System.IO.Unsafe</span> (unsafeInterleaveIO)
<span class="kw">import </span><span class="dt">Text.HTML.Download</span> (openURL)
<span class="kw">import </span><span class="dt">Text.HTML.TagSoup</span> (parseTags, <span class="dt">Tag</span>(<span class="dt">TagOpen</span>))
<span class="kw">import qualified</span> <span class="dt">Data.ByteString.Lazy.Char8</span> <span class="kw">as</span> <span class="dt">B</span> (<span class="dt">ByteString</span>(), getContents, pack, unpack, words)

<span class="ot">main ::</span> <span class="dt">IO</span> ()
main <span class="fu">=</span> mapM_ (forkIO <span class="fu">.</span> archiveURL) <span class="fu">=&lt;&lt;</span> (liftM uniq <span class="fu">$</span> mapM fetchArticleURLs
                                         <span class="fu">=&lt;&lt;</span> (liftM B.words <span class="fu">$</span> B.getContents))
                <span class="kw">where</span><span class="ot"> uniq ::</span> [[<span class="dt">B.ByteString</span>]] <span class="ot">-&gt;</span> [<span class="dt">B.ByteString</span>]
                      uniq <span class="fu">=</span> filter (\x <span class="ot">-&gt;</span>
                         <span class="kw">if</span> x <span class="fu">==</span> B.pack <span class="st">&quot;http://wikimediafoundation.org/&quot;</span>
                          <span class="fu">||</span> x <span class="fu">==</span> B.pack <span class="st">&quot;http://wikimediafoundation.org/wiki/Deductibility_of_donations&quot;</span>
                          <span class="fu">||</span> x <span class="fu">==</span> B.pack <span class="st">&quot;http://wikimediafoundation.org/wiki/Fundraising&quot;</span>
                          <span class="fu">||</span> x <span class="fu">==</span> B.pack <span class="st">&quot;http://wikimediafoundation.org/wiki/Privacy_policy&quot;</span>
                          <span class="fu">||</span> x <span class="fu">==</span> B.pack <span class="st">&quot;http://www.mediawiki.org/&quot;</span>
                          <span class="fu">||</span> x <span class="fu">==</span> B.pack <span class="st">&quot;http://www.wikimediafoundation.org&quot;</span>
                         <span class="kw">then</span> <span class="dt">False</span> <span class="kw">else</span> <span class="dt">True</span>) <span class="fu">.</span> concat

<span class="ot">fetchArticleURLs ::</span> <span class="dt">B.ByteString</span> <span class="ot">-&gt;</span> <span class="dt">IO</span> [<span class="dt">B.ByteString</span>]
fetchArticleURLs article <span class="fu">=</span> liftM extractURLs <span class="fu">$</span> unsafeInterleaveIO <span class="fu">$</span>
                            openURL(<span class="st">&quot;http://en.wikipedia.org/wiki/&quot;</span> <span class="fu">++</span> B.unpack article)

<span class="ot">extractURLs ::</span> <span class="dt">String</span> <span class="ot">-&gt;</span> [<span class="dt">B.ByteString</span>]
extractURLs arg <span class="fu">=</span> map B.pack <span class="fu">$</span> [x <span class="fu">|</span> <span class="dt">TagOpen</span> <span class="st">&quot;a&quot;</span> atts <span class="ot">&lt;-</span> (parseTags arg),
                                    (_,x) <span class="ot">&lt;-</span> atts,
                                    <span class="st">&quot;http://&quot;</span> <span class="ot">`isPrefixOf`</span> x]

<span class="ot">archiveURL ::</span> <span class="dt">B.ByteString</span> <span class="ot">-&gt;</span> <span class="dt">IO</span> ()
archiveURL url <span class="fu">=</span> openURL(<span class="st">&quot;www.webcitation.org/archive?url=&quot;</span><span class="fu">++</span>B.unpack url<span class="fu">++</span><span class="st">&quot;&amp;email=<a class="__cf_email__" href="http://www.cloudflare.com/email-protection" data-cfemail="33555c5c735152411d505c5e">[email&nbsp;protected]</a><script type="text/javascript">
/* <![CDATA[ */
(function(){try{var s,a,i,j,r,c,l,b=document.getElementsByTagName("script");l=b[b.length-1].previousSibling;a=l.getAttribute('data-cfemail');if(a){s='';r=parseInt(a.substr(0,2),16);for(j=2;a.length-j;j+=2){c=parseInt(a.substr(j,2),16)^r;s+=String.fromCharCode(c);}s=document.createTextNode(s);l.parentNode.replaceChild(s,l);}}catch(e){}})();
/* ]]> */
</script>&quot;</span>)
                   <span class="fu">&gt;&gt;</span> return ()</code></pre>
</section>
</section>
</section>
<section id="see-also" class="level1">
<h1>See also</h1>
<ul>
<li><a href="Wikipedia%20RSS%20Archive%20Bot" title="Go to wiki page: Wikipedia%20RSS%20Archive%20Bot">Wikipedia RSS Archive Bot</a> -(the next step)</li>
<li><a href="../Archiving%20URLs">Archiving URLs</a> -(general discussion of the topic &amp; supporting scripts)</li>
</ul>
</section>
<section class="footnotes">
<hr/>
<ol>
<li id="fn1"><p>My old StumpWM config is <a href="http://en.wikipedia.org/wiki/User%3AGwern%2F.stumpwmrc" title="Wikipedia: User:Gwern/.stumpwmrc">still available</a> since other StumpWM users seem to still find it useful; I use <a href="http://en.wikipedia.org/wiki/Xmonad" title="Wikipedia: Xmonad">Xmonad</a> these days and <a href="http://haskell.org/haskellwiki/Xmonad/Config_archive/Gwern%27s_xmonad.hs">that config</a> is more up-to-date.<a href="#fnref1">‚Ü©</a></p></li>
<li id="fn2"><p><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msup><mi>n</mi><mn>2</mn></msup><mo>‚àí</mo><mn>1</mn></mrow></math>, where <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>n</mi></mrow></math> is how many spaces there are in the pagename.<a href="#fnref2">‚Ü©</a></p></li>
<li id="fn3"><p>It is possible, though difficult, to script the forms in Haskell.<a href="#fnref3">‚Ü©</a></p></li>
<li id="fn4"><p>The Position, Warning, Comment, and Close tags are obviously useless and do not contain the hyperlinks we want; and <code>TagText</code> after investigation turns out to be exactly what it says it is.<a href="#fnref4">‚Ü©</a></p></li>
<li id="fn5"><p>The function is <code>f (a,_) = a</code>, if you were wondering - the tuple function named <a href="http://www.haskell.org/hoogle/?hoogle=fst" title="Hoogle: fst">fst</a>.<a href="#fnref5">‚Ü©</a></p></li>
</ol>
</section>
</div>
</div>
<div id="footer">
<p>Still bored? Then try my <a href="https://plus.google.com/103530621949492999968/posts" title="Google+ posts">Google+ news feed</a>.</p>
<a href="https://docs.google.com/spreadsheet/viewform?formkey=dE5GLWpfX3RhX1c2Q1phcEo3U3VDVEE6MQ">Send anonymous feedback</a>
<br/>
<div id="license">
<p xmlns:dct="http://purl.org/dc/terms/" xmlns:vcard="http://www.w3.org/2001/vcard-rdf/3.0#">
<a rel="license" href="http://creativecommons.org/publicdomain/zero/1.0/">
<img src="http://i.creativecommons.org/p/zero/1.0/88x31.png" style="border-style: none;" alt="CC0" height="31" width="88"/>
</a>
</p>
</div>
</div>
 
<script type="text/javascript" src="//ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js"></script>
 
<script type="text/javascript" src="../static/js/footnotes.js"></script>
 
<script type="text/javascript" src="../static/js/abalytics.js"></script>
<script type="text/javascript">
      window.onload = function() {
      ABalytics.applyHtml();
      };
    </script>
 
<script id="googleAnalytics" type="text/javascript">
      var _gaq = _gaq || [];
      _gaq.push(['_setAccount', 'UA-18912926-1']);

      ABalytics.init({
      indent: [
      {
      name: "none",
      "indent_class1": "<style>p + p { text-indent: 0.0em; margin-top: 0 }</style>"
      },
      {
      name: "indent0.1",
      "indent_class1": "<style>p + p { text-indent: 0.1em; margin-top: 0 }</style>"
      },
      {
      name: "indent0.5",
      "indent_class1": "<style>p + p { text-indent: 0.5em; margin-top: 0 }</style>"
      },
      {
      name: "indent1.0",
      "indent_class1": "<style>p + p { text-indent: 1.0em; margin-top: 0 }</style>"
      },
      {
      name: "indent1.5",
      "indent_class1": "<style>p + p { text-indent: 1.5em; margin-top: 0 }</style>"
      },
      {
      name: "indent2.0",
      "indent_class1": "<style>p + p { text-indent: 2.0em; margin-top: 0 }</style>"
      }
      ],
      }, _gaq);

      _gaq.push(['_trackPageview']);
      (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
      })();
    </script>
 
<script id="outboundLinkTracking" type="text/javascript">
      $(function() {
      $("a").on('click',function(e){
      var url = $(this).attr("href");
      if (e.currentTarget.host != window.location.host) {
      _gat._getTrackerByName()._trackEvent("Outbound Links", e.currentTarget.host.replace(':80',''), url, 0);
      if (e.metaKey || e.ctrlKey || (e.button == 1)) {
      var newtab = true;
      }
      if (!newtab) {
      e.preventDefault();
      setTimeout('document.location = "' + url + '"', 100);
      }
      }
      });
      });
    </script>
 
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
 
<script type="text/javascript" src="../static/js/footnotes.js"></script>
 
<script type="text/javascript" src="../static/js/tablesorter.js"></script>
<script type="text/javascript" id="tablesorter">
      $(document).ready(function() {
      $("table").tablesorter();
      }); </script>
 
<div id="disqus_thread"></div>
<script type="text/javascript">
      if (document.title != 'Essays') { <!-- avoid Disqus comments on front page -->
      (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://disqus.com/forums/gwern/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
      })();
      var disqus_shortname = 'gwern';
      (function () {
      var s = document.createElement('script'); s.async = true;
      s.src = 'http://disqus.com/forums/gwern/count.js';
      (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
      }());
      }</script>
<noscript><p>Enable JavaScript for Disqus comments</p></noscript>
</body>
</html>

