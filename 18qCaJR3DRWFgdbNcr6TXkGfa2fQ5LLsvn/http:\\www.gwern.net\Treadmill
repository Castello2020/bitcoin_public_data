http://www.gwern.net/Treadmill
HTTP/1.1 200 OK
Server: cloudflare-nginx
Date: Thu, 24 Jul 2014 02:09:37 GMT
Content-Type: text/html; charset=utf-8
Connection: close
Set-Cookie: __cfduid=dc742a7a4ba3a707dfefc5ca981d2c5201406167777918; expires=Mon, 23-Dec-2019 23:50:00 GMT; path=/; domain=.gwern.net; HttpOnly
x-amz-id-2: K0JUiSGd5f/h2IPs452UqI79WRUcCN85yORR1az48NNaIOgOgjXDl2kshSqdtBUo
x-amz-request-id: 639D723A684815CF
x-amz-meta-s3cmd-attrs: uid:1000/gname:gwern/uname:gwern/gid:1000/mode:33152/mtime:1405188984/atime:1405188983/ctime:1405188984
Cache-Control: max-age=604800, public
Last-Modified: Sat, 12 Jul 2014 18:38:57 GMT
CF-RAY: 14ec93a3f2ae02b8-IAD
Content-Encoding: gzip

<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8"/>
<meta name="generator" content="hakyll"/>
<meta name="google-site-verification" content="BOhOQI1uMfsqu_DopVApovk1mJD5ZBLfan0s9go3phk"/>
<meta name="author" content="gwern"/>
<meta name="description" content="Notes relating to my use of a treadmill desk"/>
<meta name="dc.date.issued" content="19 June 2012"/>
<meta name="dcterms.modified" content="01 Jun 2014"/>
<title>Treadmill desk observations</title>
<link rel="stylesheet" type="text/css" href="./static/css/default.css"/>
<link href="./atom.xml" type="application/atom+xml" rel="alternate" title="Sitewide ATOM/RSS Feed"/>
<link rel="shortcut icon" type="image/x-icon" href="./static/img/favicon.ico"/>
</head>
<body>
 
<div class="indent_class1"></div>
<div id="main">
<div id="sidebar">
<div id="logo"><img alt="Logo: a Gothic/Fraktur blackletter capital G/𝕲" height="36" src="./images/logo.png" width="32"/></div>
<div id="sidebar-links">
<p>
<a href="./index" title="index: categorized list of articles">Home</a>
<a href="./About" title="Site ideals, source, content, traffic, examples, license">Site</a>
<a href="./Links" title="Who am I online, what have I done, what am I like? Contact information; sites I use; things I've worked on">Me</a>
</p>
<hr/>
<div id="sidebar-news">
<p>
<a href="./Changelog" title="What's new or updated">New:</a>
<a href="./atom.xml" type="application/atom+xml" rel="alternate" title="Sitewide ATOM/RSS Feed">RSS</a>
<a href="http://eepurl.com/Kc155" title="Monthly mailing list: signup form">MAIL</a>
</p>
<hr/>
</div>
<div id="cse-sitesearch">
<script>
            (function() {
            var cx = '009114923999563836576:dv0a4ndtmly';
            var gcse = document.createElement('script'); gcse.type = 'text/javascript'; gcse.async = true;
            gcse.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//www.google.com/cse/cse.js?cx=' + cx;
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(gcse, s);
            })();
          </script>
<div style="width:0px;overflow:hidden;height:0px;">
<gcse:search></gcse:search>
</div>
<form id="searchbox_009114923999563836576:dv0a4ndtmly">
<input value="009114923999563836576:dv0a4ndtmly" name="cx" type="hidden"/>
<input value="FORID:11" name="cof" type="hidden"/>
<input id="q" style name="q" size="5" type="text" placeholder="search"/>
</form>
</div>
</div>
<hr/>
<div id="metadata">
<div id="abstract"><em>Notes relating to my use of a treadmill desk</em></div>
<br/>
<div id="tags"><i><a href="./tags/experiments">experiments</a>, <a href="./tags/biology">biology</a>, <a href="./tags/psychology">psychology</a>, <a href="./tags/statistics">statistics</a></i></div>
<br/>
<div id="page-created">created:
<br/>
<i>19 June 2012</i></div>
<div id="last-modified">modified:
<br/>
<i>01 Jun 2014</i></div>
<br/>
<div id="version">status:
<br/>
<i>finished</i></div>
<br/>
<div id="epistemological-status"><a href="./About#belief-tags" title="Explanation of 'belief' metadata">belief:</a>
<br/>
<i>likely</i>
</div>
<hr/>
</div>
<div id="donations">
<div id="bitcoin-donation-address">
<a href="http://en.wikipedia.org/wiki/Bitcoin">฿</a>: 18qCaJR3DRWFgdbNcr6TXkGfa2fQ5LLsvn
</div>
<div id="paypal">
<form style="display: inline" action="https://www.paypal.com/cgi-bin/webscr" method="post" onClick="_gaq.push(['_trackEvent', 'Click', 'PayPalClicked', '']);">
<div class="form-type">
<input type="hidden" name="cmd" value="_s-xclick"/>
<input type="hidden" name="hosted_button_id" value="8GSLCWGCC6AF8"/>
<input type="image" src="http://www.paypalobjects.com/en_US/i/btn/btn_donate_SM.gif" name="submit" alt="Help support my writings!"/>
</div>
</form>
</div>
<div id="Gittip">
<script data-gittip-username="gwern" data-gittip-widget="button" src="//gttp.co/v1.js"></script>
</div>
</div>
</div>
 
<div id="adsense">
<a href="http://41j.com/ads/ad.html"><img alt="Advertisement for 'HTerm, The Graphical Terminal'" src="http://41j.com/ads/ad.png" height="90" width="728"></a>
</div>
<div id="header">
<h1>Treadmill desk observations</h1>
</div>
<div id="content">
<div id="TOC"><ul>
<li><a href="#sleep">Sleep</a></li>
<li><a href="#typing">Typing</a></li>
<li><a href="#treadmill-effect-on-spaced-repetition-performance-randomized-experiment">Treadmill effect on Spaced repetition performance: randomized experiment</a><ul>
<li><a href="#background">Background</a></li>
<li><a href="#method">Method</a></li>
<li><a href="#data">Data</a></li>
<li><a href="#analysis">Analysis</a><ul>
<li><a href="#exploratory">Exploratory</a></li>
<li><a href="#tests">Tests</a></li>
</ul></li>
<li><a href="#conclusion">Conclusion</a></li>
</ul></li>
</ul></div>
 
 
<section id="sleep" class="level1">
<h1>Sleep</h1>
<p>In June 2012, early in the experiment, my neighbors threw out a treadmill that turned out to be easily repaired and so I set up an improvised <a href="http://en.wikipedia.org/wiki/treadmill%20desk" title="Wikipedia: treadmill desk">treadmill desk</a> with my laptop and a spare board. I had read about them before, had since seen a number of negative reports about being sedentary or sitting, and my physical fitness had declined markedly since leaving university (with ready access to the gym, fencing club, and Taekwondo class), so it seemed like a good thing to do. The lowest setting on the treadmill (no incline, 1MPH) was initially fairly exhausting but I improved. I started with one mile a day and moved up in a few days to 3-4 miles a day (putting me at the high end of my daily steps as recorded by my pedometer, which annoyingly I lost just 2 days before finding the treadmill); for some reason, this seemed to affect my weight, which went from 218 pounds to 214 a week later and 213 the next day. I finetuned the treadmill desk for typing on my laptop by increasing the height of the board with book supports. My productivity suffered drastically the first days, and I was concerned it would rendered typing difficult, but my scores in my typing practice program (<a href="https://code.google.com/p/amphetype/">Amphetype</a>) did not seem to change very much when I tested them on all subsequent days that I used the treadmill. I suspect that my average WPM went down somewhat, though my statistical analysis indicated it fell slightly (see the <a href="#typing">typing section</a>). The gear on the treadmill itself began to loosen, which led to the rubber band slipping off the motor or the gear, and I had to stop for a few days while I figured out solutions. (The epoxy was a mistake as it required a ‘hardener’ I didn’t have; a thin nail couldn’t be hammered between the gear and treadmill bar as a shim; and I had to let the Gorilla Glue harden for a day before it performed admirably during the test run.) A few days later, the mat began slipping and just stopping, and I discovered that the gear was rotating freely on the treadmill bar - the friction and glue had apparently lost! I lost several days hoping it would dry. It did and seemed to work again, but to help deal with it, I lubricated the underside of the mat with WD-40. It seemed to work</p>
<p>My expectations are that the treadmill will increase how much I sleep, decrease sleep latency, and possibly have a small negative effect on productivity (which may be offset by an improvement in mood and less need to get a daily walk). Subjectively, whenever I use the treadmill, it feels like I can’t work on hard material like programming or statistics, and I need to sit down and be still to really focus; I wonder if it is because my head bobbles slightly as I walk, and if a VR solution like an <a href="http://en.wikipedia.org/wiki/Oculus%20Rift" title="Wikipedia: Oculus Rift">Oculus Rift</a> might fix the jiggling issue? (If the walking were intense aerobic fitness, I might expect an increase in cognitive abilities or various sorts, but it’s not, so I don’t expect any effect on Mnemosyne scores.)</p>
</section>
<section id="typing" class="level1">
<h1>Typing</h1>
<p>Fortunately, I had used Amphetype for typing practice for 3 years prior to finding the treadmill, so I could compare my daily treadmill typing sessions to a very long dataseries.</p>
<figure>
<img alt="WPM (top) and accuracy scores (bottom) plotted over time on a time-scaled X-axis with undamped values. The tight group at the far right is the week or two of typing practice while using a treadmill." height="613" src="./images/zeo/2012-amphetype.png" width="1120"/><figcaption>WPM (top) and accuracy scores (bottom) plotted over time on a time-scaled X-axis with undamped values. The tight group at the far right is the week or two of typing practice while using a treadmill.</figcaption>
</figure>
<p>The graph looks like WPM (but not Accuracy) may have been damaged, but it’s not clear at all: we should do statistics. Amphetype stores the graphed data in a <a href="http://en.wikipedia.org/wiki/SQLite" title="Wikipedia: SQLite">SQLite</a> database, which after a little tinkering I figured out how to extract the WPM &amp; Accuracy scores:</p>
<pre class="sourceCode Bash"><code class="sourceCode bash">$ <span class="kw">sqlite3</span> -batch gwern.db <span class="st">'SELECT w real, wpm real, accuracy real FROM result;'</span> <span class="kw">&gt;</span> ~/stats.txt</code></pre>
<p>Which gives a file like</p>
<pre><code>1233502576.01172|70.2471151325281|0.981412639405205
1233502634.48339|80.9762013034008|0.989159891598916
1233502677.26434|74.0623733171948|0.988326848249027
...</code></pre>
<p>The pipes are delimiters, which I replaced with commas (<code>tr '|' ','</code>). The first field is a date-stamp expressed in seconds since the <a href="http://en.wikipedia.org/wiki/Unix%20epoch" title="Wikipedia: Unix epoch">Unix epoch</a>; they can be converted to more readable dates like so:</p>
<pre class="sourceCode Bash"><code class="sourceCode bash">$ <span class="kw">date</span> --date <span class="st">'@1308320681.44771'</span>
<span class="kw">Fri</span> Jun 17 10:24:41 EDT 2011</code></pre>
<p>I went through the 2870 lines until I found the first treadmill session I did on June 16. After splitting, deleting the date-stamps, and adding a CSV header like <code>WPM,Accuracy</code>, I had had 2285 entries for <a href="./docs/2012-gwern-amphetype-before.csv">2012-gwern-amphetype-before.csv</a> and 585 for <a href="./docs/2012-gwern-amphetype-after.csv">2012-gwern-amphetype-after.csv</a>. Then it is easy to load the CSVs into R and test:</p>
<pre class="sourceCode R"><code class="sourceCode r">before &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;http://www.gwern.net/docs/2012-gwern-amphetype-before.csv&quot;</span>)
before$Treadmill &lt;-<span class="st"> </span><span class="dv">0</span>
after &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;http://www.gwern.net/docs/2012-gwern-amphetype-after.csv&quot;</span>)
after$Treadmill &lt;-<span class="st"> </span><span class="dv">1</span>
amphetype &lt;-<span class="st"> </span><span class="kw">rbind</span>(before,after)
l &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="kw">cbind</span>(WPM, Accuracy) ~<span class="st"> </span>Treadmill, <span class="dt">data=</span>amphetype)

<span class="kw">summary</span>(<span class="kw">manova</span>(l))
            Df Pillai approx F num Df den Df <span class="kw">Pr</span>(&gt;F)
Treadmill    <span class="dv">1</span> <span class="fl">0.0556</span>     <span class="fl">84.4</span>      <span class="dv">2</span>   <span class="dv">2867</span> &lt;<span class="fl">2e-16</span>

<span class="kw">summary</span>(l)
Response WPM :

Coefficients:
<span class="st">            </span>Estimate Std. Error t value <span class="kw">Pr</span>(&gt;<span class="er">|</span>t|)
(Intercept)   <span class="fl">82.343</span>      <span class="fl">0.195</span>   <span class="fl">422.2</span>   &lt;<span class="fl">2e-16</span>
Treadmill      <span class="fl">5.216</span>      <span class="fl">0.432</span>    <span class="fl">12.1</span>   &lt;<span class="fl">2e-16</span>

Response Accuracy :

Coefficients:
<span class="st">            </span>Estimate Std. Error t value <span class="kw">Pr</span>(&gt;<span class="er">|</span>t|)
(Intercept) <span class="fl">0.987517</span>   <span class="fl">0.000170</span> <span class="fl">5813.22</span>  &lt;<span class="st"> </span><span class="fl">2e-16</span>
Treadmill   <span class="fl">0.001610</span>   <span class="fl">0.000376</span>    <span class="fl">4.28</span>  <span class="fl">1.9e-05</span></code></pre>
<p>What? Using a treadmill made my average WPM go <em>up</em> 5 WPM? And my average accuracy increased 0.001%? And both are highly statistically-significant (not a surprise, given how many entries there were)? What’s going on - this is the exact opposite of expected! The key is the low mean of the <code>before</code> data: I type much faster than 82 WPM now, more like 90 or 100 WPM. What happened was that I spent 3 years practicing. Given that I was improving, it is wrong to compare the recent treadmill typing data against a low long-run average without any consideration of this trend of increasing WPM. What would be better would be to lop off the first half of the <code>before</code> data to get a fairer comparison with <code>after</code>, since I began to plateau around then. Redoing the tests:</p>
<pre class="sourceCode R"><code class="sourceCode r">secondHalf &lt;-<span class="st"> </span>amphetype[(<span class="kw">nrow</span>(amphetype)/<span class="dv">2</span>):<span class="kw">nrow</span>(amphetype),]
l2 &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="kw">cbind</span>(WPM, Accuracy) ~<span class="st"> </span>Treadmill, <span class="dt">data=</span>secondHalf)
<span class="kw">summary</span>(l2)

Coefficients:
<span class="st">            </span>Estimate Std. Error t value <span class="kw">Pr</span>(&gt;<span class="er">|</span>t|)
(Intercept)   <span class="fl">85.826</span>      <span class="fl">0.315</span>  <span class="fl">272.13</span>  &lt;<span class="st"> </span><span class="fl">2e-16</span>
Treadmill      <span class="fl">1.733</span>      <span class="fl">0.494</span>    <span class="fl">3.51</span>  <span class="fl">0.00047</span>


Response Accuracy :

Coefficients:
<span class="st">            </span>Estimate Std. Error t value <span class="kw">Pr</span>(&gt;<span class="er">|</span>t|)
(Intercept) <span class="fl">0.988951</span>   <span class="fl">0.000259</span> <span class="fl">3820.00</span>   &lt;<span class="fl">2e-16</span>
Treadmill   <span class="fl">0.000176</span>   <span class="fl">0.000406</span>    <span class="fl">0.43</span>     <span class="fl">0.66</span></code></pre>
<p>This is more reasonable: only a 2 WPM gain from the treadmill. 2 WPM could be explicable as just a placebo effect: me wanting to justify the time I’ve sunk into the treadmill and typing practice every day. It’s still a little surprising, but the result initially seems solider. (If we drop every score before 2000 instead of 1144, the difference continues to shrink but still favors the treadmill. We have to go to scores 2100-2285 before the treadmill starts to lose, but with 2200-2285 the treadmill wins!) Accuracy seems largely unaffected. Better yet, we can model the linear progress of my WPM over time and test for a variation that way:</p>
<pre class="sourceCode R"><code class="sourceCode r">amphetype$Nth &lt;-<span class="st"> </span><span class="dv">1</span>:<span class="kw">nrow</span>(amphetype)
<span class="kw">summary</span>(<span class="kw">lm</span>(<span class="kw">cbind</span>(WPM, Accuracy) ~<span class="st"> </span>Nth +<span class="st"> </span>Treadmill, <span class="dt">data=</span>amphetype))
Response WPM :

Coefficients:
<span class="st">            </span>Estimate Std. Error t value <span class="kw">Pr</span>(&gt;<span class="er">|</span>t|)
(Intercept) <span class="fl">77.06152</span>    <span class="fl">0.37071</span>  <span class="fl">207.88</span>   &lt;<span class="fl">2e-16</span>
Nth          <span class="fl">0.00462</span>    <span class="fl">0.00028</span>   <span class="fl">16.49</span>   &lt;<span class="fl">2e-16</span>
Treadmill   -<span class="fl">1.41533</span>    <span class="fl">0.57651</span>   -<span class="fl">2.45</span>    <span class="fl">0.014</span>

Response Accuracy :

Coefficients:
<span class="st">             </span>Estimate Std. Error t value <span class="kw">Pr</span>(&gt;<span class="er">|</span>t|)
(Intercept)  <span class="fl">9.86e-01</span>   <span class="fl">3.35e-04</span> <span class="fl">2938.81</span>  &lt;<span class="st"> </span><span class="fl">2e-16</span>
Nth          <span class="fl">1.63e-06</span>   <span class="fl">2.54e-07</span>    <span class="fl">6.44</span>  <span class="fl">1.4e-10</span>
Treadmill   -<span class="fl">7.34e-04</span>   <span class="fl">5.22e-04</span>   -<span class="fl">1.41</span>     <span class="fl">0.16</span></code></pre>
<p>This is more as expected: so walking on the treadmill cost me -1.5WPM in typing speed, and a day of practice correlates with +0.004WPM (and so a full month of practice would be worth 0.12WPM). Having reached diminishing returns, I decided to stop typing practice.</p>
</section>
<section id="treadmill-effect-on-spaced-repetition-performance-randomized-experiment" class="level1">
<h1>Treadmill effect on Spaced repetition performance: randomized experiment</h1>
<blockquote>
<p>It has been claimed that doing spaced repetition review while on a walking treadmill improves memory performance. I did a randomized experiment August 2013 - May 2014 and found that using a treadmill damaged my recall performance.</p>
</blockquote>
<section id="background" class="level2">
<h2>Background</h2>
 
<p><a href="http://blog.sethroberts.net/category/walking-and-learning/">Starting in 2010</a>, Seth Roberts claimed that he found his <a href="http://en.wikipedia.org/wiki/Anki%20%28software%29" title="Wikipedia: Anki (software)">Anki</a> flashcard reviews (for <a href="Spaced%20repetition">spaced repetition</a>) to be easier &amp; better when he did them while using his treadmill, and offers some just-so evolutionary psychology theorizing that walking may cue knowledge absorption in a “thirst for knowledge”. He doesn’t offer any hard data, but he does <a href="http://blog.sethroberts.net/2012/09/05/new-treadmill-catalyzes-learning-results/">quote some data</a> from a <a href="http://vimeo.com/40265872" title="Jeremy Howard - Language Acquisition Performance">2012 presentation by Jeremy Howard</a>, who claims a 5% review error-rate while walking and 8% while not-walking, and to be “40% faster [at learning]”; a near-halving of lower grades is certainly an effect to be reckoned with and well worthwhile.</p>
<p>An effect strikes me as plausible: flashcard review does not require fine motor skills or (too) difficult thinking, and the walking might well wake one up if nothing else. And it would be convenient if it were true, since spaced repetition on one’s treadmill would be two birds with one stone.</p>
<p>But on the other hand, the walking might be a distraction from the work of recall and damage real performance, much like how many students claim playing music while studying “helps them focus” which is dubious (eg <a href="./docs/dnb/2012-perham.pdf" title="Disliked Music can be Better for Performance than Liked Music">Perham &amp; Sykora 2012</a> found music damaged memory recall, and music you enjoyed was the worst). Consistent with this, my own experience with treadmills was that it impeded concentration. And I couldn’t help but notice Robert’s failure to present hard data: since Anki (like almost all spaced-repetition software), records detailed statistics about flashcard reviews in order to implement the scheduling algorithm, he had access to the data to show some objective performance measurements like whether days on the treadmill increase the average flashcard scores; all he had to do was record his treadmill use and then extract it, which wouldn’t take too long to show “a big effect” (a month or two would likely be enough). But as far as I know, he never made any use of his Anki data.</p>
<p>Having acquired a treadmill, and being a long-time user of Mnemosyne, this seems eminently testable! I simply randomize whether I do my daily Mnemosyne review before or after getting on the treadmill. (Unfortunately, I can think of no way to blind treadmill use, so randomization is it.)</p>
<p>One concern, prompted by the <a href="Lewis%20meditation">2013 Lewis meditation</a> results, is that there may be time-of-day effects on flashcard review; I tend to not use the treadmill in the morning (I am not a morning person), so if recall improved in the afternoon, then it might be conflated with the treadmill. I downloaded the <a href="https://groups.google.com/d/msg/mnemosyne-proj-users/tPHlkTFVX_4/oF61BF44iQkJ" title="Mnemosyne data set available">4GB public Mnemosyne dataset</a> (every Mnemosyne user is offered the option to anonymously submit statistical data about their flashcards) to try to analyze it and estimate fixed effects of time. The full dataset showed many such effects, so time variables will be included in the analysis.</p>
</section>
<section id="method" class="level2">
<h2>Method</h2>
<p>Each day I decided to do spaced repetition, I randomly flipped a bit (50-50) in Bash to determine whether I would do it seated or on my treadmill (which is set to 1mph), and recorded whether that day was treadmill-affected after review. This was done from August 2013 to May 2014. Eventually I noticed that the experiment was becoming a <a href="http://wiki.lesswrong.com/wiki/Trivial_inconvenience">trivial inconvenience</a> that was damaging my hard-earned spaced repetition habit, and ended the experiment. I didn’t do a formal power analysis, but my intuition was that this would be enough data to show an effect, especially if the effect was as large as claimed.</p>
<p>The endpoint is the grades given flashcards each day; analysis will be multilevel ordinal logistic regression.</p>
</section>
<section id="data" class="level2">
<h2>Data</h2>
<p>Extract the raw data from my Mnemosyne database:</p>
<pre class="sourceCode Bash"><code class="sourceCode bash">$ <span class="kw">sqlite3</span> -batch ~/.local/share/mnemosyne/default.db \
          <span class="st">&quot;SELECT timestamp,easiness,grade FROM log WHERE event_type==9;&quot;</span> <span class="kw">|</span> <span class="kw">\</span>
  <span class="kw">tr</span> <span class="st">&quot;|&quot;</span> <span class="st">&quot;,&quot;</span> \
  <span class="kw">&gt;</span> <span class="kw">gwern-mnemosyne.csv</span></code></pre>
<p>Processing:</p>
<pre class="sourceCode R"><code class="sourceCode r">## read into R
mnemosyne &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;gwern-mnemosyne.csv&quot;</span>, <span class="dt">header=</span><span class="ot">FALSE</span>,
                      <span class="dt">col.names =</span><span class="kw">c</span>(<span class="st">&quot;Timestamp&quot;</span>, <span class="st">&quot;Easiness&quot;</span>, <span class="st">&quot;Grade&quot;</span>),
                      <span class="dt">colClasses=</span><span class="kw">c</span>(<span class="st">&quot;integer&quot;</span>,   <span class="st">&quot;numeric&quot;</span>,  <span class="st">&quot;integer&quot;</span>))
mnemosyne$Timestamp &lt;-<span class="st"> </span><span class="kw">as.POSIXct</span>(mnemosyne$Timestamp, <span class="dt">origin =</span> <span class="st">&quot;1970-01-01&quot;</span>, <span class="dt">tz =</span> <span class="st">&quot;EST&quot;</span>)

## extract the temporal covariates from the timestamp
mnemosyne$WeekDay &lt;-<span class="st"> </span><span class="kw">as.factor</span>(<span class="kw">weekdays</span>(mnemosyne$Timestamp))
mnemosyne$Hour    &lt;-<span class="st"> </span><span class="kw">as.factor</span>(<span class="kw">as.numeric</span>(<span class="kw">format</span>(mnemosyne$Timestamp, <span class="st">&quot;%H&quot;</span>)))
mnemosyne$Date    &lt;-<span class="st"> </span><span class="kw">as.Date</span>(mnemosyne$Timestamp)

## select data from during the experiment
mnemosyneFormatted &lt;-<span class="st"> </span><span class="kw">with</span>(mnemosyne, <span class="kw">data.frame</span>(<span class="dt">Timestamp=</span>Timestamp, <span class="dt">Date=</span>Date, <span class="dt">WeekDay=</span>WeekDay,
                                                  <span class="dt">Hour=</span>Hour, <span class="dt">Easiness=</span>Easiness, <span class="dt">Grade=</span>Grade))
treadmill &lt;-<span class="st"> </span>mnemosyneFormatted[mnemosyneFormatted$Date &gt;<span class="st"> </span><span class="kw">as.Date</span>(<span class="st">&quot;2013-08-22&quot;</span>) &amp;
<span class="st">                                </span>mnemosyneFormatted$Date &lt;<span class="st"> </span><span class="kw">as.Date</span>(<span class="st">&quot;2014-06-01&quot;</span>),]

## code which days' review was done on the treadmill
treadmill$Treadmill &lt;-<span class="st"> </span><span class="ot">FALSE</span>
treadmillDates &lt;-<span class="st"> </span><span class="kw">as.Date</span>(<span class="kw">c</span>(<span class="st">&quot;2013-08-25&quot;</span>, <span class="st">&quot;2013-08-26&quot;</span>, <span class="st">&quot;2013-08-28&quot;</span>, <span class="st">&quot;2013-09-14&quot;</span>, <span class="st">&quot;2013-09-27&quot;</span>,
                            <span class="st">&quot;2013-10-14&quot;</span>, <span class="st">&quot;2013-11-09&quot;</span>, <span class="st">&quot;2013-11-10&quot;</span>, <span class="st">&quot;2013-11-14&quot;</span>, <span class="st">&quot;2013-11-29&quot;</span>,
                            <span class="st">&quot;2013-12-05&quot;</span>, <span class="st">&quot;2013-12-07&quot;</span>, <span class="st">&quot;2014-01-29&quot;</span>, <span class="st">&quot;2014-02-10&quot;</span>, <span class="st">&quot;2014-02-15&quot;</span>,
                            <span class="st">&quot;2014-02-25&quot;</span>, <span class="st">&quot;2014-02-28&quot;</span>, <span class="st">&quot;2014-03-04&quot;</span>, <span class="st">&quot;2014-03-05&quot;</span>, <span class="st">&quot;2014-03-07&quot;</span>,
                            <span class="st">&quot;2014-03-09&quot;</span>, <span class="st">&quot;2014-03-19&quot;</span>, <span class="st">&quot;2014-03-19&quot;</span>, <span class="st">&quot;2014-03-24&quot;</span>, <span class="st">&quot;2014-03-25&quot;</span>,
                            <span class="st">&quot;2014-03-26&quot;</span>, <span class="st">&quot;2014-04-03&quot;</span>, <span class="st">&quot;2014-04-22&quot;</span>, <span class="st">&quot;2014-05-01&quot;</span>, <span class="st">&quot;2014-05-05&quot;</span>,
                            <span class="st">&quot;2014-05-06&quot;</span>, <span class="st">&quot;2014-05-28&quot;</span>, <span class="st">&quot;2014-05-29&quot;</span>, <span class="st">&quot;2014-05-31&quot;</span>))
for (i in <span class="dv">1</span>:<span class="kw">length</span>(treadmillDates)) { treadmill[treadmill$Date==treadmillDates[i],]$Treadmill &lt;-<span class="st"> </span><span class="ot">TRUE</span>; }

## serialize clean CSV for analysis
<span class="kw">write.csv</span>(treadmill, <span class="st">&quot;2014-05-31-mnemosyne-treadmill.csv&quot;</span>, <span class="dt">row.names=</span><span class="ot">FALSE</span>)</code></pre>
</section>
<section id="analysis" class="level2">
<h2>Analysis</h2>
<section id="exploratory" class="level3">
<h3>Exploratory</h3>
<pre class="sourceCode R"><code class="sourceCode r">treadmill &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;http://www.gwern.net/docs/spacedrepetition/2014-05-31-mnemosyne-treadmill.csv&quot;</span>)
<span class="kw">summary</span>(treadmill)
<span class="co">#                Timestamp            Date           WeekDay          Hour         Easiness</span>
<span class="co">#  2013-11-26 19:24:44:   2   2013-09-25: 254   Friday   : 577   Min.   : 9.0   Min.   :1.30</span>
<span class="co">#  2013-11-26 22:22:12:   2   2014-02-10: 171   Monday   : 711   1st Qu.:15.0   1st Qu.:1.44</span>
<span class="co">#  2013-12-01 18:21:49:   2   2014-02-28: 163   Saturday : 856   Median :17.0   Median :1.93</span>
<span class="co">#  2013-12-01 18:22:04:   2   2013-11-09: 162   Sunday   : 869   Mean   :17.2   Mean   :1.87</span>
<span class="co">#  2013-08-23 22:56:28:   1   2013-11-14: 155   Thursday :1034   3rd Qu.:20.0   3rd Qu.:2.16</span>
<span class="co">#  2013-08-23 22:56:36:   1   2014-04-22: 145   Tuesday  :1021   Max.   :23.0   Max.   :3.00</span>
<span class="co">#  (Other)            :5843   (Other)   :4803   Wednesday: 785</span>
<span class="co">#      Grade      Treadmill</span>
<span class="co">#  Min.   :2.00   Mode :logical</span>
<span class="co">#  1st Qu.:4.00   FALSE:2695</span>
<span class="co">#  Median :4.00   TRUE :3158</span>
<span class="co">#  Mean   :3.78   NA's :0</span>
<span class="co">#  3rd Qu.:4.00</span>
<span class="co">#  Max.   :5.00</span>

## graphing all 5853 reviews is unreadable, so summarize by day &amp; throw out outliers
daily &lt;-<span class="st"> </span><span class="kw">aggregate</span>(Grade ~<span class="st"> </span>Date +<span class="st"> </span>Treadmill, treadmill, mean)
daily &lt;-<span class="st"> </span>daily[<span class="kw">order</span>(daily$Date),]
daily &lt;-<span class="st"> </span>daily[daily$Grade&gt;=<span class="dv">3</span> &amp;<span class="st"> </span>daily$Grade&lt;=<span class="dv">4</span>,]
<span class="kw">qplot</span>(Date, Grade, <span class="dt">color=</span>Treadmill, <span class="dt">size=</span><span class="kw">I</span>(<span class="dv">5</span>), <span class="dt">data=</span>daily)</code></pre>
<figure>
<img alt="Mnemosyne spaced-repetition flashcard reviews, averaged by day, colored by whether reviewed while using a walking treadmill or not" height="824" src="./images/spaced-repetition-2014-05-31-mnemosyne-treadmill-dailyaverage.png" width="1552"/><figcaption>Mnemosyne spaced-repetition flashcard reviews, averaged by day, colored by whether reviewed while using a walking treadmill or not</figcaption>
</figure>
</section>
<section id="tests" class="level3">
<h3>Tests</h3>
<p>Because there’s only 4 possible responses in the dataset (2/3/4/5) &amp; they don’t look like a normal distribution (even with <em>n</em>=5853), my analysis preference is for an <a href="http://en.wikipedia.org/wiki/Ordered%20logit" title="Wikipedia: Ordered logit">ordinal logistic regression</a> which captures that structure. Reviews are grouped by day, so I want a <a href="http://en.wikipedia.org/wiki/Multilevel%20model" title="Wikipedia: Multilevel model">multilevel</a> ordinal logistic regression to reflect that inherent structure. And because my earlier analysis of the ~50m response Mnemosyne dataset confirmed that there are meaningful hour-of-day and day-of-week effects, I’ll want to include those as covariates. (I was originally going to include card ID as a random-effects variable to reflect the easiness of each card and help reduce the unpredictability of grades; but the most any card had been reviewed during the experiment was 7 times, so the possible gain was limited, and when an analysis with card IDs as a variable took &gt;2 hours to run and still hadn’t finished, I decided to simply use Mnemosyne’s internal estimate of “easiness”.) I’ll also check with a U-test that any effect isn’t being completely driven by the covariates.</p>
<p>The best-fitting such model confirms that there’s an effect: it’s negative. The proportional odds effect on grades is -1.381 (-2.086 to -0.6755; <em>p</em>=0.00012) or, to use a multilevel linear model, a lower mean grade by 0.1 (-0.14732 to -0.02029).</p>
<pre class="sourceCode R"><code class="sourceCode r"><span class="kw">wilcox.test</span>(Grade ~<span class="st"> </span>Treadmill, <span class="dt">conf.int=</span><span class="ot">TRUE</span>, <span class="dt">data=</span>treadmill)
<span class="co">#</span>
<span class="co">#     Wilcoxon rank sum test with continuity correction</span>
<span class="co">#</span>
<span class="co"># data:  Grade by Treadmill</span>
<span class="co"># W = 4363353, p-value = 0.01656</span>
<span class="co"># alternative hypothesis: true location shift is not equal to 0</span>
<span class="co"># 95% confidence interval:</span>
<span class="co">#  -2.355e-05  5.387e-05</span>
<span class="co"># sample estimates:</span>
<span class="co"># difference in location</span>
<span class="co">#              4.155e-05</span>

<span class="kw">library</span>(ordinal)
c1  &lt;-<span class="st"> </span><span class="kw">clmm</span>(<span class="kw">ordered</span>(Grade) ~<span class="st"> </span>Treadmill +<span class="st"> </span>Easiness +<span class="st"> </span>(<span class="dv">1</span>|Date) +<span class="st"> </span>(<span class="dv">1</span>|WeekDay) +<span class="st"> </span>(<span class="dv">1</span>|Hour), <span class="dt">data=</span>treadmill)
c2  &lt;-<span class="st"> </span><span class="kw">clmm</span>(<span class="kw">ordered</span>(Grade) ~<span class="st"> </span>Treadmill +<span class="st"> </span>Easiness +<span class="st"> </span>(<span class="dv">1</span>|Date) +<span class="st"> </span>(<span class="dv">1</span>|WeekDay)           , <span class="dt">data=</span>treadmill)
c3  &lt;-<span class="st"> </span><span class="kw">clmm</span>(<span class="kw">ordered</span>(Grade) ~<span class="st"> </span>Treadmill +<span class="st"> </span>Easiness +<span class="st">            </span>(<span class="dv">1</span>|WeekDay) +<span class="st"> </span>(<span class="dv">1</span>|Hour), <span class="dt">data=</span>treadmill)
c4  &lt;-<span class="st"> </span><span class="kw">clmm</span>(<span class="kw">ordered</span>(Grade) ~<span class="st"> </span>Treadmill +<span class="st"> </span>Easiness +<span class="st"> </span>(<span class="dv">1</span>|Date)               +<span class="st"> </span>(<span class="dv">1</span>|Hour), <span class="dt">data=</span>treadmill)
c5  &lt;-<span class="st"> </span><span class="kw">clmm</span>(<span class="kw">ordered</span>(Grade) ~<span class="st"> </span>Treadmill +<span class="st"> </span>Easiness +<span class="st"> </span>(<span class="dv">1</span>|Date)                         , <span class="dt">data=</span>treadmill)
c6  &lt;-<span class="st"> </span><span class="kw">clmm</span>(<span class="kw">ordered</span>(Grade) ~<span class="st"> </span>Treadmill +<span class="st"> </span>Easiness +<span class="st">            </span>(<span class="dv">1</span>|WeekDay)           , <span class="dt">data=</span>treadmill)
c7  &lt;-<span class="st"> </span><span class="kw">clmm</span>(<span class="kw">ordered</span>(Grade) ~<span class="st"> </span>Treadmill +<span class="st"> </span>Easiness +<span class="st">                          </span>(<span class="dv">1</span>|Hour), <span class="dt">data=</span>treadmill)
c8  &lt;-<span class="st"> </span><span class="kw">clm</span>(<span class="kw">ordered</span>(Grade)  ~<span class="st"> </span>Treadmill +<span class="st"> </span>Easiness                                    , <span class="dt">data=</span>treadmill)
c9  &lt;-<span class="st"> </span><span class="kw">clm</span>(<span class="kw">ordered</span>(Grade)  ~<span class="st"> </span>Treadmill                                               , <span class="dt">data=</span>treadmill)
c10 &lt;-<span class="st"> </span><span class="kw">clm</span>(<span class="kw">ordered</span>(Grade)  ~<span class="st"> </span>Treadmill                                               , <span class="dt">data=</span>treadmill)
c11 &lt;-<span class="st"> </span><span class="kw">clm</span>(<span class="kw">ordered</span>(Grade)  ~<span class="st"> </span><span class="dv">1</span>                                                       , <span class="dt">data=</span>treadmill)
<span class="kw">anova</span>(c1,c2,c3,c4,c5,c6,c7,c8,c9,c10,c11)
<span class="co"># ...</span>
<span class="co">#     no.par  AIC logLik LR.stat df Pr(&gt;Chisq)</span>
<span class="co"># c11      3 8215  -4104</span>
<span class="co"># c9       4 8211  -4101    5.77  1      0.016</span>
<span class="co"># c10      4 8211  -4101    0.00  0</span>
<span class="co"># c8       5 6959  -3475 1253.46  1     &lt;2e-16</span>
<span class="co"># c5       6 6842  -3415  119.16  1     &lt;2e-16</span>
<span class="co"># c6       6 6951  -3470 -108.79  0</span>
<span class="co"># c7       6 6946  -3467    5.16  0</span>
<span class="co"># c2       7 6842  -3414  106.17  1     &lt;2e-16</span>
<span class="co"># c3       7 6939  -3462  -96.90  0</span>
<span class="co"># c4       7 6833  -3409  106.03  0</span>
<span class="co"># c1       8 6834  -3409    0.32  1      0.570</span>

<span class="kw">summary</span>(c4)
<span class="co"># ...</span>
<span class="co"># Random effects:</span>
<span class="co">#  Groups Name        Variance Std.Dev.</span>
<span class="co">#  Date   (Intercept) 2.008    1.417</span>
<span class="co">#  Hour   (Intercept) 0.179    0.423</span>
<span class="co"># Number of groups:  Date 97,  Hour 15</span>
<span class="co">#</span>
<span class="co"># Coefficients:</span>
<span class="co">#               Estimate Std. Error z value Pr(&gt;|z|)</span>
<span class="co"># TreadmillTRUE   -1.381      0.360   -3.84  0.00012</span>
<span class="co"># Easiness         3.365      0.121   27.73  &lt; 2e-16</span>
<span class="co">#</span>
<span class="co"># Threshold coefficients:</span>
<span class="co">#     Estimate Std. Error z value</span>
<span class="co"># 2|3    1.751      0.338    5.19</span>
<span class="co"># 3|4    2.842      0.338    8.41</span>
<span class="co"># 4|5    9.814      0.388   25.28</span>

## easier to interpret a linear model: how much does average grade fall on treadmill?
<span class="kw">library</span>(lme4)
l4 &lt;-<span class="st"> </span><span class="kw">lmer</span>(Grade ~<span class="st"> </span>Treadmill +<span class="st"> </span>Easiness +<span class="st"> </span>(<span class="dv">1</span>|Date) +<span class="st"> </span>(<span class="dv">1</span>|Hour), <span class="dt">data=</span>treadmill); <span class="kw">summary</span>(l4)
<span class="co"># ...</span>
<span class="co"># Fixed effects:</span>
<span class="co">#               Estimate Std. Error t value</span>
<span class="co"># (Intercept)     2.7003     0.0422    64.0</span>
<span class="co"># TreadmillTRUE  -0.0805     0.0296    -2.7</span>
<span class="co"># Easiness        0.6085     0.0180    33.8</span>

<span class="kw">confint</span>(c4)
<span class="co">#                2.5 %  97.5 %</span>
<span class="co"># 2|3            1.089  2.4124</span>
<span class="co"># 3|4            2.180  3.5047</span>
<span class="co"># 4|5            9.053 10.5749</span>
<span class="co"># TreadmillTRUE -2.086 -0.6755</span>
<span class="co"># Easiness       3.127  3.6032</span>

<span class="kw">confint</span>(l4)
<span class="co"># Computing profile confidence intervals ...</span>
<span class="co">#                  2.5 %   97.5 %</span>
<span class="co"># .sig01         0.06273  0.14300</span>
<span class="co"># .sig02         0.01809  0.08734</span>
<span class="co"># .sigma         0.54550  0.56598</span>
<span class="co"># (Intercept)    2.61418  2.78532</span>
<span class="co"># TreadmillTRUE -0.14732 -0.02029</span>
<span class="co"># Easiness       0.57313  0.64363</span></code></pre>
</section>
</section>
<section id="conclusion" class="level2">
<h2>Conclusion</h2>
<p>While the result seems highly likely to be true for me, I don’t know how well it might generalize to other people. For example, perhaps more fit people can use a treadmill without harm and the negative effect is due to the treadmill usage tiring &amp; distracting me; I try to walk 2 miles a day, but that’s not much compared to some people.</p>
<p>Given this harmful impact, I will avoid doing spaced repetition on my treadmill in the future, and given this &amp; the typing result, will relegate any computer+treadmill usage to non-intellectually-demanding work like watching movies.</p>
<!--
# Appendix: time-varying spaced repetition performance
## Personal

Extract all my data:

~~~{.Bash}
sqlite3 -batch ~/.local/share/mnemosyne/default.db "SELECT timestamp,object_id,easiness,grade FROM log WHERE event_type==9;" | tr '|' ',' > 2014-05-31-gwern-mnemosyne.csv
~~~

~~~{.R}
mnemosyne <- read.csv("2014-05-31-gwern-mnemosyne.csv", header=FALSE, col.names=c("Date", "ID", "Easiness", "Grade"), colClasses=c("integer", "factor", "numeric", "integer"))
mnemosyne$Date <- as.POSIXct(mnemosyne$Date, origin = "1970-01-01", tz = "UTC")
mnemosyne$Year <- as.factor(as.Date(mnemosyne$Date, "%Y"))
mnemosyne$Month <- as.factor(months(mnemosyne$Date))
mnemosyne$WeekDay <- as.factor(weekdays(mnemosyne$Date))
mnemosyne$Day    <- as.factor(as.Date(mnemosyne$Date))
mnemosyne$Hour <- as.factor(as.Date(mnemosyne$Date, "%H"))
mnemosyne <- mnemosyne[order(mnemosyne$ID),]

nrow(mnemosyne)
# [1] 141699

summary(mnemosyne)
#       Date                                   ID            Easiness        Grade
#  Min.   :2009-05-31 23:06:25.00   088b40ad.inv:    44   Min.   :1.30   Min.   :0.00
#  1st Qu.:2009-12-17 04:08:26.50   e8764710    :    40   1st Qu.:1.78   1st Qu.:3.00
#  Median :2010-08-04 16:41:04.00   27fc28b3    :    38   Median :2.05   Median :4.00
#  Mean   :2010-12-07 05:30:08.64   86b870ac    :    38   Mean   :1.99   Mean   :3.64
#  3rd Qu.:2011-08-25 02:38:16.50   1644a7c7    :    36   3rd Qu.:2.24   3rd Qu.:4.00
#  Max.   :2014-05-31 23:44:07.00   7b0e88b5    :    36   Max.   :3.29   Max.   :5.00
#                                   (Other)     :141467
#          Year             Month            WeekDay              Day                 Hour
#  2009-07-13:   779   July    :17729   Friday   :19942   2009-07-13:   779   2009-07-13:   779
#  2009-12-26:   767   August  :16296   Monday   :22064   2009-12-26:   767   2009-12-26:   767
#  2009-07-19:   717   December:13449   Saturday :16467   2009-07-19:   717   2009-07-19:   717
#  2009-07-22:   683   June    :13165   Sunday   :20894   2009-07-22:   683   2009-07-22:   683
#  2009-08-09:   653   January :12218   Thursday :20438   2009-08-09:   653   2009-08-09:   653
#  2009-12-27:   648   November:11023   Tuesday  :19911   2009-12-27:   648   2009-12-27:   648
#  (Other)   :137452   (Other) :57819   Wednesday:21983   (Other)   :137452   (Other)   :137452


library(ordinal)
c1 <- clm(ordered(Grade) ~ Hour + WeekDay + Month + Year + Easiness, data=mnemosyne); summary(c1)

Warning message:
(2) Model is nearly unidentifiable: very large eigenvalue
 - Rescale variables?
In addition: Absolute and relative convergence criteria were met
formula: ordered(Grade) ~ Hour + WeekDay + Month + Year + Easiness
data:    mnemosyne

 link  threshold nobs   logLik     AIC       niter max.grad cond.H
 logit flexible  141699 -122137.75 244369.51 8(0)  2.42e-07 2.0e+12

Coefficients:
                  Estimate Std. Error z value Pr(>|z|)
Hour1            -3.62e-02   4.16e-02   -0.87  0.38427
Hour2             6.39e-02   4.05e-02    1.58  0.11481
Hour3             1.41e-01   4.00e-02    3.51  0.00044
Hour4             3.60e-01   4.34e-02    8.28  < 2e-16
Hour5             1.11e-01   4.77e-02    2.33  0.01966
Hour6            -1.56e-01   5.13e-02   -3.04  0.00237
Hour7             2.68e-01   5.60e-02    4.79  1.7e-06
Hour8             2.46e-01   5.60e-02    4.40  1.1e-05
Hour9            -1.33e-02   5.68e-02   -0.23  0.81424
Hour10            2.47e-01   4.72e-02    5.23  1.7e-07
Hour11            3.92e-01   4.59e-02    8.55  < 2e-16
Hour12           -1.08e-01   7.70e-02   -1.40  0.16188
Hour13            1.34e-01   4.48e-02    2.99  0.00279
Hour14            1.84e-01   3.91e-02    4.71  2.5e-06
Hour15            1.35e-02   3.83e-02    0.35  0.72363
Hour16            6.32e-02   3.87e-02    1.63  0.10274
Hour17            2.20e-02   3.69e-02    0.60  0.55021
Hour18            8.62e-02   3.82e-02    2.26  0.02390
Hour19           -1.89e-01   4.09e-02   -4.62  3.9e-06
Hour20           -1.06e-01   4.05e-02   -2.61  0.00905
Hour21           -1.44e-02   4.06e-02   -0.36  0.72194
Hour22           -1.86e-01   4.59e-02   -4.06  4.9e-05
Hour23           -2.78e-02   4.12e-02   -0.67  0.49990
WeekDayMonday    -7.13e-03   2.19e-02   -0.33  0.74439
WeekDaySaturday  -4.45e-02   2.36e-02   -1.88  0.05969
WeekDaySunday    -2.94e-02   2.22e-02   -1.32  0.18527
WeekDayThursday   4.04e-02   2.25e-02    1.80  0.07180
WeekDayTuesday   -5.39e-02   2.24e-02   -2.40  0.01624
WeekDayWednesday  1.02e-03   2.19e-02    0.05  0.96275
MonthAugust      -2.49e-01   3.14e-02   -7.92  2.4e-15
MonthDecember    -2.68e-01   3.05e-02   -8.78  < 2e-16
MonthFebruary     2.43e-02   3.30e-02    0.74  0.46185
MonthJanuary     -1.48e-01   3.13e-02   -4.73  2.2e-06
MonthJuly        -2.43e-01   3.22e-02   -7.55  4.5e-14
MonthJune        -3.71e-01   3.01e-02  -12.36  < 2e-16
MonthMarch        6.60e-02   3.34e-02    1.98  0.04792
MonthMay         -2.04e-01   3.22e-02   -6.33  2.5e-10
MonthNovember    -5.09e-02   3.18e-02   -1.60  0.10867
MonthOctober      9.00e-02   3.33e-02    2.70  0.00695
MonthSeptember    1.48e-02   3.30e-02    0.45  0.65311
Year              8.20e-04   1.55e-05   53.03  < 2e-16
Easiness          1.51e+00   1.71e-02   88.03  < 2e-16

Threshold coefficients:
    Estimate Std. Error z value
0|1    6.003      0.339    17.7
1|2    9.845      0.245    40.1
2|3   13.129      0.243    53.9
3|4   13.967      0.244    57.3
4|5   18.751      0.248    75.7



# install.packages("lme4")
library(lme4)
lmr <- lmer(Grade ~ Hour + WeekDay + (1|ID), data=mnemosyne); lmr

lmr1 <- lmer(Grade ~ (1:ID) + (1|Hour:WeekDay) + (1|WeekDay), data=mnemosyne)
lmr2 <- lmer(Grade ~ (1:ID) + (1|WeekDay:Hour) + (1|Hour), data=mnemosyne)
lmr3 <- lmer(Grade ~ (1:ID) + (1|Hour) + (1|WeekDay), data=mnemosyne)
lmr4 <- lmer(Grade ~ (1:ID) + (1|WeekDay), data=mnemosyne)
lmr5 <- lmer(Grade ~ (1:ID) + (1|Hour), data=mnemosyne)
lmr6 <- lmer(Grade ~ (1|Hour) + (1|WeekDay), data=mnemosyne)
lmr7 <- lmer(Grade ~ (1|Hour), data=mnemosyne)
lmr8 <- lmer(Grade ~ (1|WeekDay), data=mnemosyne)
anova(lmr1, lmr2, lmr3, lmr4, lmr5, lmr6, lmr7, lmr8)
...
     Df    AIC    BIC  logLik deviance   Chisq Chi Df Pr(>Chisq)
lmr4  3 315209 315238 -157601   315203
lmr5  3 314817 314846 -157405   314811  391.60      0     <2e-16
lmr7  3 314817 314846 -157405   314811    0.00      0          1
lmr8  3 315209 315238 -157601   315203    0.00      0          1
lmr1  4 313076 313115 -156534   313068 2134.91      1     <2e-16
lmr2  4 313071 313111 -156532   313063    4.22      0     <2e-16
lmr3  4 314802 314841 -157397   314794    0.00      0          1
lmr6  4 314802 314841 -157397   314794    0.00      0          1

# lmr2 fits the best:
lmr; ranef(lmr2)
Linear mixed model fit by REML ['lmerMod']
Formula: Grade ~ (1:ID) + (1 | WeekDay:Hour) + (1 | Hour)
   Data: mnemosyne

REML criterion at convergence: 313070

Random effects:
 Groups       Name        Variance Std.Dev.
 WeekDay:Hour (Intercept) 0.02200  0.1483
 Hour         (Intercept) 0.00312  0.0559
 Residual                 0.58263  0.7633
Number of obs: 136006, groups: WeekDay:Hour, 168; Hour, 24

Fixed effects:
            Estimate Std. Error t value
(Intercept)   3.6009     0.0164     220
$`WeekDay:Hour`
             (Intercept)
Friday:0       -0.019139
Friday:1        0.066000
Friday:2        0.127930
Friday:3       -0.030641
Friday:4       -0.003555
Friday:5        0.050270
Friday:6       -0.069348
Friday:7        0.162819
Friday:8        0.111000
Friday:9       -0.095142
Friday:10      -0.302438
Friday:11      -0.109022
Friday:12       0.062432
Friday:13      -0.191936
Friday:14       0.080181
Friday:15       0.056169
Friday:16       0.019640
Friday:17       0.060872
Friday:18       0.121200
Friday:19       0.021702
Friday:20      -0.070333
Friday:21       0.010426
Friday:22       0.184549
Friday:23       0.034788
Monday:0       -0.050514
Monday:1       -0.028257
Monday:2        0.044377
Monday:3        0.039661
Monday:4        0.195395
Monday:5        0.084555
Monday:6        0.245055
Monday:7        0.012922
Monday:8       -0.026822
Monday:9        0.090738
Monday:10       0.058359
Monday:11       0.079431
Monday:12       0.078798
Monday:13      -0.065937
Monday:14      -0.008352
Monday:15      -0.071668
Monday:16      -0.112114
Monday:17       0.035863
Monday:18       0.073842
Monday:19       0.118506
Monday:20       0.072537
Monday:21      -0.018688
Monday:22      -0.281828
Monday:23       0.043099
Saturday:0      0.036154
Saturday:1     -0.068238
Saturday:2     -0.060102
Saturday:3      0.130476
Saturday:4      0.093435
Saturday:5      0.032539
Saturday:6     -1.030752
Saturday:7     -0.070630
Saturday:8     -0.200564
Saturday:9      0.063551
Saturday:10     0.110013
Saturday:11     0.004704
Saturday:12    -0.634920
Saturday:13     0.109141
Saturday:14    -0.031036
Saturday:15     0.083492
Saturday:16     0.058052
Saturday:17    -0.001440
Saturday:18     0.053168
Saturday:19    -0.129243
Saturday:20    -0.049725
Saturday:21     0.052595
Saturday:22     0.030970
Saturday:23     0.089661
Sunday:0        0.077668
Sunday:1        0.002151
Sunday:2        0.036547
Sunday:3       -0.101526
Sunday:4       -0.093471
Sunday:5       -0.285501
Sunday:6        0.219535
Sunday:7        0.043141
Sunday:8        0.120761
Sunday:9       -0.104879
Sunday:10      -0.044698
Sunday:11      -0.173190
Sunday:12       0.135313
Sunday:13       0.085895
Sunday:14       0.046830
Sunday:15      -0.027498
Sunday:16       0.028319
Sunday:17      -0.113491
Sunday:18       0.021524
Sunday:19       0.037930
Sunday:20       0.043320
Sunday:21      -0.069593
Sunday:22       0.074461
Sunday:23       0.059064
Thursday:0      0.097109
Thursday:1     -0.022386
Thursday:2     -0.035211
Thursday:3      0.100196
Thursday:4     -0.012246
Thursday:5     -0.124873
Thursday:6      0.269351
Thursday:7     -0.253772
Thursday:8      0.031430
Thursday:9     -0.044216
Thursday:10     0.025595
Thursday:11     0.144850
Thursday:12    -0.245026
Thursday:13     0.063981
Thursday:14     0.026730
Thursday:15     0.058664
Thursday:16     0.166390
Thursday:17     0.066198
Thursday:18     0.013504
Thursday:19    -0.157871
Thursday:20    -0.055170
Thursday:21     0.077850
Thursday:22    -0.030607
Thursday:23     0.026882
Tuesday:0      -0.175450
Tuesday:1       0.103698
Tuesday:2      -0.050102
Tuesday:3       0.037554
Tuesday:4       0.011223
Tuesday:5       0.057910
Tuesday:6      -0.155696
Tuesday:7      -0.039166
Tuesday:8       0.064975
Tuesday:9      -0.010484
Tuesday:10     -0.076896
Tuesday:11      0.064807
Tuesday:12     -0.005010
Tuesday:13     -0.079948
Tuesday:14      0.037390
Tuesday:15      0.075767
Tuesday:16      0.106249
Tuesday:17      0.071065
Tuesday:18      0.035418
Tuesday:19      0.022454
Tuesday:20      0.069751
Tuesday:21     -0.035432
Tuesday:22     -0.070137
Tuesday:23     -0.188515
Wednesday:0    -0.016837
Wednesday:1    -0.052541
Wednesday:2     0.031597
Wednesday:3    -0.016883
Wednesday:4     0.095349
Wednesday:5     0.082828
Wednesday:6    -0.385014
Wednesday:7     0.128185
Wednesday:8    -0.074648
Wednesday:9    -0.083151
Wednesday:10    0.195809
Wednesday:11    0.072926
Wednesday:12   -0.007923
Wednesday:13    0.058538
Wednesday:14   -0.035893
Wednesday:15   -0.073958
Wednesday:16    0.076137
Wednesday:17    0.128695
Wednesday:18    0.026047
Wednesday:19    0.091466
Wednesday:20    0.058831
Wednesday:21    0.068955
Wednesday:22   -0.017855
Wednesday:23    0.013263

$Hour
   (Intercept)
0   -7.240e-03
1    6.061e-05
2    1.349e-02
3    2.255e-02
4    4.061e-02
5   -1.452e-02
6   -1.287e-01
7   -2.342e-03
8    3.709e-03
9   -2.606e-02
10  -4.862e-03
11   1.199e-02
12  -8.748e-02
13  -2.877e-03
14   1.644e-02
15   1.433e-02
16   4.864e-02
17   3.517e-02
18   4.893e-02
19   7.016e-04
20   9.824e-03
21   1.222e-02
22  -1.568e-02
23   1.111e-02



effects <- ranef(lmr2)$`WeekDay:Hour`
lmr1DayHours <- data.frame(Day=sapply(strsplit(rownames(effects), ":"),  function (x) {x[1]}),
                           Hour=as.integer(sapply(strsplit(rownames(effects), ":"),  function (x) {x[2]})),
                           Effect=effects[1:nrow(effects),])
qplot(Day, Hour, color=Effect, data=lmr1DayHours) + scale_colour_gradient(low="black", high="white")

http://i.imgur.com/6wyR9QZ.png
-->
<!--

I extract the data as before:

    $ sqlite3 -batch ./mnemosyne-stats/logs.db "SELECT timestamp,object_id,grade FROM log WHERE event==9;" | tr '|' ',' > ~/mnemosyne-all.csv
    $ wc mnemosyne-all.csv
      47794669   47794669 1114023396 mnemosyne-all.csv
    $ R
    R> install.packages("biglm")

The `biglm` package offers an *incremental* linear model function: you can read in a million rows, 'add' them to a `biglm` object, read in another million rows and so on. Since I can fit 1 million rows in RAM but not 48 million rows, this works great:

    library(biglm)

    m <- file("mnemosyne-all.csv", open="rt")

    get <- function(filepath) {
        chunk <- read.csv(filepath, nrows=2000000, header=FALSE, col.names=c("Date", "ID", "Grade"), colClasses=c("integer", "factor", "numeric"))
        chunk$Date <- as.POSIXct(chunk$Date, origin = "1970-01-01", tz = "UTC")
        chunk$WeekDay <- as.factor(weekdays(chunk$Date))
        chunk$Hour <- as.factor(as.numeric(format(chunk$Date, "%H")))
        return(chunk)
        }

    frml <- Grade ~ Hour + WeekDay

    # create a seed to update with fresh data in the loop
    chunk1 <- get(m)
    bl <- biglm(frml, chunk1)

    while (isOpen(m)) {
        chunk <- get(m)
        bl <- update(bl, chunk)
    }
    summary(bl)
    closeAllConnections()

    ...
    Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) :
      contrasts can be applied only to factors with 2 or more levels
    Calls: update ... model.matrix -> model.matrix.default -> contrasts<-
    R> # It errors out because I didn't figure out how to handle reading to the end of the file
    R> summary(bl)
    Large data regression model: biglm(frml, chunk1)
    Sample size =  47794669
                     Coef (95%  CI) SE p
    (Intercept)       2.8  2.8  2.8  0 0
    Hour1             0.0  0.0  0.0  0 0
    Hour2             0.0  0.0  0.0  0 0
    Hour3            -0.1 -0.1  0.0  0 0
    Hour4            -0.1 -0.1 -0.1  0 0
    Hour5            -0.2 -0.2 -0.2  0 0
    Hour6            -0.3 -0.3 -0.3  0 0
    Hour7            -0.1 -0.1 -0.1  0 0
    Hour8             0.1  0.1  0.1  0 0
    Hour9             0.2  0.2  0.2  0 0
    Hour10            0.3  0.3  0.3  0 0
    Hour11            0.3  0.3  0.3  0 0
    Hour12            0.3  0.3  0.3  0 0
    Hour13            0.2  0.2  0.2  0 0
    Hour14            0.2  0.2  0.2  0 0
    Hour15            0.2  0.2  0.2  0 0
    Hour16            0.1  0.1  0.1  0 0
    Hour17            0.1  0.1  0.1  0 0
    Hour18            0.1  0.1  0.1  0 0
    Hour19            0.0  0.0  0.1  0 0
    Hour20            0.0  0.0  0.0  0 0
    Hour21            0.0  0.0  0.0  0 0
    Hour22            0.0  0.0  0.0  0 0
    Hour23            0.0  0.0  0.0  0 0
    WeekDayMonday     0.0  0.0  0.0  0 0
    WeekDaySaturday   0.0  0.0  0.0  0 0
    WeekDaySunday     0.0  0.0  0.0  0 0
    WeekDayThursday   0.0  0.0  0.0  0 0
    WeekDayTuesday    0.0  0.0  0.0  0 0
    WeekDayWednesday  0.0  0.0  0.0  0 0

But hopefully 47,794,669 (48m) flashcard reviews is enough. So, pulling out the interesting coefficients - all the weekdays drop out as irrelevant - we get:

    06            -0.3
    05            -0.2
    03            -0.1
    04            -0.1
    07            -0.1
    08             0.1
    16             0.1
    17             0.1
    18             0.1
    09             0.2
    13             0.2
    14             0.2
    15             0.2
    10             0.3
    11             0.3
    12             0.3

(We can ignore the p-values & confidence intervals, since at this sample scale, they're all going to be zero & point-values.) No apparent pattern when sorted by size, but the pattern jumps out when we graph by hour:

    plot(c(0,0,-0.1,-0.1,-0.2,-0.3,-0.1,0.1,0.2,0.3,0.3,0.3,0.2,0.2,0.2,0.1,0.1,0.1,0,0,0,0,0))

http://i.imgur.com/sum3toZ.png

We get a beautiful-looking circadian rhythm: peak performance at noon, crappy performance in early morning, declining performance over the day into evening. I'm actually impressed at the effect sizes here: if you compare reviewing at noon vs reviewing at 6 AM, that's a difference of 0.6 - on a 1-5 scale where most grades are a 3 or 4! If this is reflecting actual memory performance and not some sort of response bias varying by time (like being too pessimistic when you're up too early/late)

That's only about retrieval, though. I wonder if late at night (==near bedtime) would be best for subsequent recalls, but I'm not sure how to analyze that.

This doesn't tell us how hour & day may combine like in my previous multilevel model. So let's rerun with:

    frml <- Grade ~ Hour * WeekDay

This will use up ~4x more RAM while running, BTW, so you may need to reduce how many rows you tell `read.csv` to read in. The results:

    R> summary(bl)
    Large data regression model: biglm(frml, chunk1)
    Sample size =  47794669
                            Coef (95%  CI) SE   p
    (Intercept)              2.8  2.8  2.8  0 0.0
    Hour1                    0.0  0.0  0.0  0 0.0
    Hour2                    0.0  0.0  0.0  0 0.0
    Hour3                    0.0  0.0  0.0  0 0.0
    Hour4                   -0.1 -0.1 -0.1  0 0.0
    Hour5                   -0.2 -0.2 -0.2  0 0.0
    Hour6                   -0.3 -0.3 -0.3  0 0.0
    Hour7                    0.0  0.0  0.0  0 0.0
    Hour8                    0.1  0.1  0.1  0 0.0
    Hour9                    0.1  0.1  0.1  0 0.0
    Hour10                   0.3  0.3  0.3  0 0.0
    Hour11                   0.3  0.3  0.3  0 0.0
    Hour12                   0.3  0.3  0.3  0 0.0
    Hour13                   0.2  0.2  0.2  0 0.0
    Hour14                   0.2  0.2  0.2  0 0.0
    Hour15                   0.2  0.2  0.2  0 0.0
    Hour16                   0.1  0.1  0.1  0 0.0
    Hour17                   0.1  0.1  0.1  0 0.0
    Hour18                   0.1  0.1  0.1  0 0.0
    Hour19                   0.0  0.0  0.0  0 0.0
    Hour20                   0.1  0.1  0.1  0 0.0
    Hour21                   0.1  0.0  0.1  0 0.0
    Hour22                   0.1  0.1  0.1  0 0.0
    Hour23                   0.0  0.0  0.0  0 0.0
    WeekDayMonday            0.0  0.0  0.0  0 0.6
    WeekDaySaturday          0.1  0.0  0.1  0 0.0
    WeekDaySunday            0.0  0.0  0.0  0 0.0
    WeekDayThursday          0.1  0.0  0.1  0 0.0
    WeekDayTuesday           0.0  0.0  0.0  0 0.9
    WeekDayWednesday         0.1  0.1  0.1  0 0.0
    Hour1:WeekDayMonday      0.0  0.0  0.0  0 0.0
    Hour2:WeekDayMonday      0.0 -0.1  0.0  0 0.0
    Hour3:WeekDayMonday      0.0  0.0  0.0  0 0.0
    Hour4:WeekDayMonday      0.0  0.0  0.0  0 0.4
    Hour5:WeekDayMonday      0.0  0.0  0.0  0 0.0
    Hour6:WeekDayMonday      0.1  0.1  0.1  0 0.0
    Hour7:WeekDayMonday      0.0 -0.1  0.0  0 0.0
    Hour8:WeekDayMonday      0.1  0.1  0.2  0 0.0
    Hour9:WeekDayMonday      0.3  0.2  0.3  0 0.0
    Hour10:WeekDayMonday     0.1  0.1  0.1  0 0.0
    Hour11:WeekDayMonday     0.0  0.0  0.0  0 0.0
    Hour12:WeekDayMonday     0.0  0.0  0.0  0 0.0
    Hour13:WeekDayMonday     0.1  0.1  0.1  0 0.0
    Hour14:WeekDayMonday     0.0  0.0  0.1  0 0.0
    Hour15:WeekDayMonday     0.0  0.0  0.0  0 0.0
    Hour16:WeekDayMonday     0.1  0.1  0.1  0 0.0
    Hour17:WeekDayMonday     0.0  0.0  0.0  0 0.1
    Hour18:WeekDayMonday     0.1  0.0  0.1  0 0.0
    Hour19:WeekDayMonday     0.1  0.1  0.1  0 0.0
    Hour20:WeekDayMonday     0.1  0.0  0.1  0 0.0
    Hour21:WeekDayMonday     0.1  0.1  0.1  0 0.0
    Hour22:WeekDayMonday     0.0  0.0  0.0  0 0.0
    Hour23:WeekDayMonday     0.0  0.0  0.0  0 0.0
    Hour1:WeekDaySaturday   -0.1 -0.1 -0.1  0 0.0
    Hour2:WeekDaySaturday   -0.1 -0.1 -0.1  0 0.0
    Hour3:WeekDaySaturday   -0.1 -0.1 -0.1  0 0.0
    Hour4:WeekDaySaturday    0.0  0.0  0.0  0 0.3
    Hour5:WeekDaySaturday    0.0  0.0  0.0  0 0.0
    Hour6:WeekDaySaturday    0.1  0.1  0.1  0 0.0
    Hour7:WeekDaySaturday   -0.2 -0.2 -0.2  0 0.0
    Hour8:WeekDaySaturday    0.0  0.0  0.0  0 0.3
    Hour9:WeekDaySaturday   -0.1 -0.1 -0.1  0 0.0
    Hour10:WeekDaySaturday  -0.1 -0.1 -0.1  0 0.0
    Hour11:WeekDaySaturday  -0.1 -0.1 -0.1  0 0.0
    Hour12:WeekDaySaturday  -0.1 -0.1 -0.1  0 0.0
    Hour13:WeekDaySaturday   0.0  0.0  0.0  0 0.0
    Hour14:WeekDaySaturday   0.0  0.0  0.1  0 0.0
    Hour15:WeekDaySaturday   0.0  0.0  0.0  0 0.1
    Hour16:WeekDaySaturday   0.0  0.0  0.0  0 0.0
    Hour17:WeekDaySaturday   0.0  0.0  0.0  0 0.9
    Hour18:WeekDaySaturday   0.0  0.0  0.0  0 0.4
    Hour19:WeekDaySaturday   0.0  0.0  0.0  0 0.0
    Hour20:WeekDaySaturday  -0.1 -0.1 -0.1  0 0.0
    Hour21:WeekDaySaturday  -0.1 -0.1 -0.1  0 0.0
    Hour22:WeekDaySaturday  -0.1 -0.1 -0.1  0 0.0
    Hour23:WeekDaySaturday  -0.1 -0.1 -0.1  0 0.0
    Hour1:WeekDaySunday     -0.1 -0.1  0.0  0 0.0
    Hour2:WeekDaySunday      0.0  0.0  0.0  0 0.0
    Hour3:WeekDaySunday      0.0  0.0  0.0  0 0.1
    Hour4:WeekDaySunday      0.0  0.0  0.0  0 0.0
    Hour5:WeekDaySunday      0.0  0.0  0.0  0 0.0
    Hour6:WeekDaySunday      0.1  0.1  0.1  0 0.0
    Hour7:WeekDaySunday     -0.1 -0.1 -0.1  0 0.0
    Hour8:WeekDaySunday      0.0  0.0  0.0  0 0.1
    Hour9:WeekDaySunday      0.1  0.0  0.1  0 0.0
    Hour10:WeekDaySunday     0.0  0.0  0.1  0 0.0
    Hour11:WeekDaySunday    -0.1 -0.1 -0.1  0 0.0
    Hour12:WeekDaySunday     0.0 -0.1  0.0  0 0.0
    Hour13:WeekDaySunday     0.0  0.0  0.0  0 0.0
    Hour14:WeekDaySunday     0.1  0.1  0.1  0 0.0
    Hour15:WeekDaySunday     0.1  0.1  0.1  0 0.0
    Hour16:WeekDaySunday     0.1  0.1  0.1  0 0.0
    Hour17:WeekDaySunday     0.0  0.0  0.0  0 0.0
    Hour18:WeekDaySunday     0.0  0.0  0.0  0 0.1
    Hour19:WeekDaySunday     0.1  0.0  0.1  0 0.0
    Hour20:WeekDaySunday     0.0  0.0  0.0  0 0.0
    Hour21:WeekDaySunday    -0.1 -0.1  0.0  0 0.0
    Hour22:WeekDaySunday    -0.1 -0.1 -0.1  0 0.0
    Hour23:WeekDaySunday     0.0  0.0  0.0  0 0.0
    Hour1:WeekDayThursday   -0.1 -0.1  0.0  0 0.0
    Hour2:WeekDayThursday   -0.1 -0.1 -0.1  0 0.0
    Hour3:WeekDayThursday   -0.1 -0.1  0.0  0 0.0
    Hour4:WeekDayThursday    0.0  0.0  0.0  0 0.0
    Hour5:WeekDayThursday   -0.1 -0.1  0.0  0 0.0
    Hour6:WeekDayThursday    0.0 -0.1  0.0  0 0.0
    Hour7:WeekDayThursday   -0.1 -0.2 -0.1  0 0.0
    Hour8:WeekDayThursday    0.1  0.0  0.1  0 0.0
    Hour9:WeekDayThursday    0.0  0.0  0.0  0 0.0
    Hour10:WeekDayThursday   0.0  0.0  0.0  0 0.1
    Hour11:WeekDayThursday   0.0 -0.1  0.0  0 0.0
    Hour12:WeekDayThursday   0.0 -0.1  0.0  0 0.0
    Hour13:WeekDayThursday   0.0  0.0  0.0  0 0.8
    Hour14:WeekDayThursday   0.0  0.0  0.0  0 0.0
    Hour15:WeekDayThursday   0.0  0.0  0.0  0 0.0
    Hour16:WeekDayThursday   0.0  0.0  0.0  0 0.0
    Hour17:WeekDayThursday   0.0  0.0  0.0  0 0.4
    Hour18:WeekDayThursday   0.0 -0.1  0.0  0 0.0
    Hour19:WeekDayThursday   0.0  0.0  0.0  0 0.0
    Hour20:WeekDayThursday  -0.1 -0.1  0.0  0 0.0
    Hour21:WeekDayThursday   0.0 -0.1  0.0  0 0.0
    Hour22:WeekDayThursday  -0.1 -0.1 -0.1  0 0.0
    Hour23:WeekDayThursday  -0.1 -0.1 -0.1  0 0.0
    Hour1:WeekDayTuesday     0.0  0.0  0.0  0 0.0
    Hour2:WeekDayTuesday     0.0  0.0  0.0  0 0.2
    Hour3:WeekDayTuesday     0.0 -0.1  0.0  0 0.0
    Hour4:WeekDayTuesday     0.0  0.0  0.0  0 0.0
    Hour5:WeekDayTuesday     0.0  0.0  0.0  0 0.1
    Hour6:WeekDayTuesday     0.1  0.1  0.1  0 0.0
    Hour7:WeekDayTuesday     0.1  0.1  0.1  0 0.0
    Hour8:WeekDayTuesday     0.1  0.1  0.2  0 0.0
    Hour9:WeekDayTuesday     0.1  0.1  0.1  0 0.0
    Hour10:WeekDayTuesday    0.0  0.0  0.0  0 0.6
    Hour11:WeekDayTuesday    0.0  0.0  0.0  0 0.0
    Hour12:WeekDayTuesday    0.0  0.0  0.0  0 0.0
    Hour13:WeekDayTuesday    0.1  0.1  0.1  0 0.0
    Hour14:WeekDayTuesday    0.0  0.0  0.0  0 0.0
    Hour15:WeekDayTuesday    0.0  0.0  0.0  0 0.3
    Hour16:WeekDayTuesday    0.0  0.0  0.0  0 0.0
    Hour17:WeekDayTuesday    0.0  0.0  0.0  0 0.5
    Hour18:WeekDayTuesday    0.0  0.0  0.0  0 0.6
    Hour19:WeekDayTuesday    0.1  0.0  0.1  0 0.0
    Hour20:WeekDayTuesday    0.0  0.0  0.0  0 0.5
    Hour21:WeekDayTuesday    0.0  0.0  0.0  0 0.8
    Hour22:WeekDayTuesday    0.0  0.0  0.0  0 0.0
    Hour23:WeekDayTuesday    0.0  0.0  0.1  0 0.0
    Hour1:WeekDayWednesday  -0.1 -0.1 -0.1  0 0.0
    Hour2:WeekDayWednesday  -0.1 -0.1 -0.1  0 0.0
    Hour3:WeekDayWednesday  -0.1 -0.1 -0.1  0 0.0
    Hour4:WeekDayWednesday  -0.1 -0.1 -0.1  0 0.0
    Hour5:WeekDayWednesday  -0.1 -0.1  0.0  0 0.0
    Hour6:WeekDayWednesday  -0.1 -0.2 -0.1  0 0.0
    Hour7:WeekDayWednesday  -0.2 -0.2 -0.2  0 0.0
    Hour8:WeekDayWednesday   0.0 -0.1  0.0  0 0.0
    Hour9:WeekDayWednesday   0.0  0.0  0.0  0 0.2
    Hour10:WeekDayWednesday  0.0 -0.1  0.0  0 0.0
    Hour11:WeekDayWednesday  0.0 -0.1  0.0  0 0.0
    Hour12:WeekDayWednesday -0.1 -0.1 -0.1  0 0.0
    Hour13:WeekDayWednesday  0.0 -0.1  0.0  0 0.0
    Hour14:WeekDayWednesday -0.1 -0.1  0.0  0 0.0
    Hour15:WeekDayWednesday -0.1 -0.1  0.0  0 0.0
    Hour16:WeekDayWednesday  0.0  0.0  0.0  0 0.0
    Hour17:WeekDayWednesday -0.1 -0.1 -0.1  0 0.0
    Hour18:WeekDayWednesday -0.1 -0.1 -0.1  0 0.0
    Hour19:WeekDayWednesday -0.1 -0.1 -0.1  0 0.0
    Hour20:WeekDayWednesday -0.1 -0.1 -0.1  0 0.0
    Hour21:WeekDayWednesday -0.1 -0.1 -0.1  0 0.0
    Hour22:WeekDayWednesday -0.1 -0.1 -0.1  0 0.0
    Hour23:WeekDayWednesday -0.1 -0.1  0.0  0 0.0

So, we get very similar values as before for the hours of the day on their own. This time, we actually do get day of week effects for Wednesday, Thursday, and Saturday:

                            Coef
    WeekDaySaturday          0.1
    WeekDayThursday          0.1
    WeekDayWednesday         0.1

And we get a pile of interactions:

    Hour6:WeekDayMonday      0.1
    Hour8:WeekDayMonday      0.1
    Hour9:WeekDayMonday      0.3
    Hour10:WeekDayMonday     0.1
    Hour13:WeekDayMonday     0.1
    Hour16:WeekDayMonday     0.1
    Hour18:WeekDayMonday     0.1
    Hour19:WeekDayMonday     0.1
    Hour20:WeekDayMonday     0.1
    Hour21:WeekDayMonday     0.1

    Hour6:WeekDayTuesday     0.1
    Hour7:WeekDayTuesday     0.1
    Hour8:WeekDayTuesday     0.1
    Hour9:WeekDayTuesday     0.1
    Hour13:WeekDayTuesday    0.1
    Hour19:WeekDayTuesday    0.1

    Hour1:WeekDayWednesday  -0.1
    Hour2:WeekDayWednesday  -0.1
    Hour3:WeekDayWednesday  -0.1
    Hour4:WeekDayWednesday  -0.1
    Hour5:WeekDayWednesday  -0.1
    Hour6:WeekDayWednesday  -0.1
    Hour7:WeekDayWednesday  -0.2
    Hour12:WeekDayWednesday -0.1
    Hour14:WeekDayWednesday -0.1
    Hour15:WeekDayWednesday -0.1
    Hour17:WeekDayWednesday -0.1
    Hour18:WeekDayWednesday -0.1
    Hour19:WeekDayWednesday -0.1
    Hour20:WeekDayWednesday -0.1
    Hour21:WeekDayWednesday -0.1
    Hour22:WeekDayWednesday -0.1
    Hour23:WeekDayWednesday -0.1

    Hour1:WeekDayThursday   -0.1
    Hour2:WeekDayThursday   -0.1
    Hour3:WeekDayThursday   -0.1
    Hour5:WeekDayThursday   -0.1
    Hour7:WeekDayThursday   -0.1
    Hour8:WeekDayThursday    0.1
    Hour20:WeekDayThursday  -0.1
    Hour22:WeekDayThursday  -0.1
    Hour23:WeekDayThursday  -0.1

    Hour1:WeekDaySaturday   -0.1
    Hour2:WeekDaySaturday   -0.1
    Hour3:WeekDaySaturday   -0.1
    Hour6:WeekDaySaturday    0.1
    Hour7:WeekDaySaturday   -0.2
    Hour9:WeekDaySaturday   -0.1
    Hour10:WeekDaySaturday  -0.1
    Hour11:WeekDaySaturday  -0.1
    Hour12:WeekDaySaturday  -0.1
    Hour20:WeekDaySaturday  -0.1
    Hour21:WeekDaySaturday  -0.1
    Hour22:WeekDaySaturday  -0.1
    Hour23:WeekDaySaturday  -0.1

    Hour1:WeekDaySunday     -0.1
    Hour6:WeekDaySunday      0.1
    Hour7:WeekDaySunday     -0.1
    Hour9:WeekDaySunday      0.1
    Hour11:WeekDaySunday    -0.1
    Hour14:WeekDaySunday     0.1
    Hour15:WeekDaySunday     0.1
    Hour16:WeekDaySunday     0.1
    Hour19:WeekDaySunday     0.1
    Hour21:WeekDaySunday    -0.1
    Hour22:WeekDaySunday    -0.1

I don't really understand these estimates. For example, why would 6 AM be terrible in general, but be helpful on Sundays?
-->
</section>
</section>
</div>
</div>
<div id="footer">
<p>Still bored? Then try my <a href="https://plus.google.com/103530621949492999968/posts" title="Google+ posts">Google+ news feed</a>.</p>
<a href="https://docs.google.com/spreadsheet/viewform?formkey=dE5GLWpfX3RhX1c2Q1phcEo3U3VDVEE6MQ">Send anonymous feedback</a>
<br/>
<div id="license">
<p xmlns:dct="http://purl.org/dc/terms/" xmlns:vcard="http://www.w3.org/2001/vcard-rdf/3.0#">
<a rel="license" href="http://creativecommons.org/publicdomain/zero/1.0/">
<img src="http://i.creativecommons.org/p/zero/1.0/88x31.png" style="border-style: none;" alt="CC0" height="31" width="88"/>
</a>
</p>
</div>
</div>
 
<script type="text/javascript" src="//ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js"></script>
 
<script type="text/javascript" src="./static/js/footnotes.js"></script>
 
<script type="text/javascript" src="./static/js/abalytics.js"></script>
<script type="text/javascript">
      window.onload = function() {
      ABalytics.applyHtml();
      };
    </script>
 
<script id="googleAnalytics" type="text/javascript">
      var _gaq = _gaq || [];
      _gaq.push(['_setAccount', 'UA-18912926-1']);

      ABalytics.init({
      indent: [
      {
      name: "none",
      "indent_class1": "<style>p + p { text-indent: 0.0em; margin-top: 0 }</style>"
      },
      {
      name: "indent0.1",
      "indent_class1": "<style>p + p { text-indent: 0.1em; margin-top: 0 }</style>"
      },
      {
      name: "indent0.5",
      "indent_class1": "<style>p + p { text-indent: 0.5em; margin-top: 0 }</style>"
      },
      {
      name: "indent1.0",
      "indent_class1": "<style>p + p { text-indent: 1.0em; margin-top: 0 }</style>"
      },
      {
      name: "indent1.5",
      "indent_class1": "<style>p + p { text-indent: 1.5em; margin-top: 0 }</style>"
      },
      {
      name: "indent2.0",
      "indent_class1": "<style>p + p { text-indent: 2.0em; margin-top: 0 }</style>"
      }
      ],
      }, _gaq);

      _gaq.push(['_trackPageview']);
      (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
      })();
    </script>
 
<script id="outboundLinkTracking" type="text/javascript">
      $(function() {
      $("a").on('click',function(e){
      var url = $(this).attr("href");
      if (e.currentTarget.host != window.location.host) {
      _gat._getTrackerByName()._trackEvent("Outbound Links", e.currentTarget.host.replace(':80',''), url, 0);
      if (e.metaKey || e.ctrlKey || (e.button == 1)) {
      var newtab = true;
      }
      if (!newtab) {
      e.preventDefault();
      setTimeout('document.location = "' + url + '"', 100);
      }
      }
      });
      });
    </script>
 
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
 
<script type="text/javascript" src="./static/js/footnotes.js"></script>
 
<script type="text/javascript" src="./static/js/tablesorter.js"></script>
<script type="text/javascript" id="tablesorter">
      $(document).ready(function() {
      $("table").tablesorter();
      }); </script>
 
<div id="disqus_thread"></div>
<script type="text/javascript">
      if (document.title != 'Essays') { <!-- avoid Disqus comments on front page -->
      (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://disqus.com/forums/gwern/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
      })();
      var disqus_shortname = 'gwern';
      (function () {
      var s = document.createElement('script'); s.async = true;
      s.src = 'http://disqus.com/forums/gwern/count.js';
      (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
      }());
      }</script>
<noscript><p>Enable JavaScript for Disqus comments</p></noscript>
</body>
</html>

